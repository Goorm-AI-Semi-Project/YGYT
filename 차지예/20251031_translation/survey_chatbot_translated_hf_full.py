
# survey_chatbot_translated_hf_full.py
import os, json
import gradio as gr

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

try:
    from openai import OpenAI
    _env_key = os.getenv("OPENAI_API_KEY")
    if _env_key:
        client = OpenAI(api_key=_env_key)
        API_ERROR = None
    else:
        client = None
        API_ERROR = "OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
except Exception as e:
    client = None
    API_ERROR = str(e)

from huggingface_translate import HFTranslator
from glossary import enforce_glossary_en
from polite_post_edit import PolitePostEditor
from quality_checks import profile_completeness, enforce_keywords_in_summary

TRANS = HFTranslator("Helsinki-NLP/opus-mt-ko-en")
POST_EDITOR = PolitePostEditor(use_llm=False)

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ë§¤ìš° ì¹œì ˆí•˜ê³  ì§€ëŠ¥ì ì¸ í•œêµ­ ì—¬í–‰ ë„ìš°ë¯¸ ì±—ë´‡ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©°, 12ê°€ì§€ í•„ìˆ˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ JSON í”„ë¡œí•„ì„ ì™„ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

[ìˆ˜ì§‘í•´ì•¼ í•  12ê°œ í•­ëª© ìŠ¤í‚¤ë§ˆ]
1.  age: (ì˜ˆ: "10ëŒ€", "20ëŒ€", "30ëŒ€"...)
2.  gender: (ì˜ˆ: "ë‚¨", "ì—¬", "ê¸°íƒ€")
3.  nationality: (ì˜ˆ: "ë¯¸êµ­", "ì¼ë³¸", "ì¤‘êµ­")
4.  travel_type: (ì˜ˆ: "ê°€ì¡±", "í˜¼ì", "ì¹œêµ¬", "ì—°ì¸")
5.  party_size: (ì˜ˆ: 1, 2, 4...)
6.  can_wait: (ì›¨ì´íŒ… ê°€ëŠ¥ ì—¬ë¶€, ì˜ˆ: "O", "X")
7.  budget: (ì˜ˆì‚° ìˆ˜ì¤€, ì˜ˆ: "ì €", "ì¤‘", "ê³ ")
8.  spicy_ok: (ë§¤ìš´ ìŒì‹ ê°€ëŠ¥ ì—¬ë¶€, ì˜ˆ: "O", "X")
9.  is_vegetarian: (ì±„ì‹ ì—¬ë¶€, ì˜ˆ: "O", "X")
10. avoid_ingredients: (ì ˆëŒ€ ë¶ˆê°€ ì‹ì¬ë£Œ, ì˜ˆ: "ë¼ì§€ê³ ê¸°", "ê²¬ê³¼ë¥˜", "ì—†ìŒ")
11. like_ingredients: (ì¢‹ì•„í•˜ëŠ” ì‹ì¬ë£Œ, ì˜ˆ: "ë‹­ê³ ê¸°", "í•´ì‚°ë¬¼", "ì•¼ì±„")
12. food_category: (ì„ í˜¸ ìŒì‹ ë¶„ë¥˜, ì˜ˆ: "í•œì‹", "ì¼ì‹", "ë””ì €íŠ¸", "ìƒê´€ì—†ìŒ")

[ëŒ€í™” ê·œì¹™]
1.  ëŒ€í™”ëŠ” ë‹¹ì‹ ì´ ë¨¼ì € ì‹œì‘í•©ë‹ˆë‹¤. í™˜ì˜ ì¸ì‚¬ì™€ í•¨ê»˜ ì²« ì§ˆë¬¸(ì˜ˆ: ì—°ë ¹ëŒ€)ì„ í•˜ì„¸ìš”.
2.  í•­ìƒ í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸í•˜ì„¸ìš”.
3.  ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ [í˜„ì¬ í”„ë¡œí•„]ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. (í•œ ë²ˆì— ì—¬ëŸ¬ ì •ë³´ê°€ ë“¤ì–´ì˜¤ë©´ ëª¨ë‘ ì—…ë°ì´íŠ¸)
4.  ì—…ë°ì´íŠ¸ëœ í”„ë¡œí•„ì„ í™•ì¸í•˜ê³ , ì•„ì§ 'null'ì´ê±°ë‚˜ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ í•­ëª© ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.
5.  ëª¨ë“  12ê°œ í•­ëª©ì´ ìˆ˜ì§‘ë˜ë©´, "ì„¤ë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤."ë¼ëŠ” ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ë” ì´ìƒ ì§ˆë¬¸í•˜ì§€ ë§ˆì„¸ìš”.
6.  ë§¤ìš° ì¹œì ˆí•˜ê³  ê³µê°í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.

[í•„ìˆ˜ ì¶œë ¥ í¬ë§·]
ë‹¹ì‹ ì€ *ë°˜ë“œì‹œ* ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
{
  "updated_profile": {
    "age": "20ëŒ€",
    "gender": "ë‚¨",
    "nationality": null,
    "travel_type": null,
    "party_size": null,
    "can_wait": null,
    "budget": null,
    "spicy_ok": null,
    "is_vegetarian": null,
    "avoid_ingredients": null,
    "like_ingredients": null,
    "food_category": null
  },
  "bot_response": "ì•„, 20ëŒ€ ë‚¨ì„±ì´ì‹œêµ°ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤. í˜¹ì‹œ êµ­ì ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?"
}
"""

PROFILE_TEMPLATE = {
  "age": None, "gender": None, "nationality": None, "travel_type": None,
  "party_size": None, "can_wait": None, "budget": None, "spicy_ok": None,
  "is_vegetarian": None, "avoid_ingredients": None, "like_ingredients": None,
  "food_category": None
}

def _translate_ko_to_en(text: str) -> str:
    en = TRANS.translate(text)
    en = enforce_glossary_en(en)
    en = POST_EDITOR.rewrite(en)
    return en

def _no_key_banner():
    tip = (
        "OpenAI key not set. Add a .env file with\n"
        "OPENAI_API_KEY=sk-...\n"
        "or export it in your shell before running."
    )
    return f"âš ï¸ {_translate_ko_to_en('ì‹œìŠ¤í…œ ì„¤ì • ì˜¤ë¥˜: OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.')}\n{tip}"

def generate_profile_summary(profile_data):
  if client is None:
    return "\n\n(" + _translate_ko_to_en("í”„ë¡œí•„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (LLM ë¯¸ì„¤ì •)") + ")"
  profile_str = json.dumps(profile_data, indent=2, ensure_ascii=False)
  summary_system_prompt = """
  ë‹¹ì‹ ì€ JSON í”„ë¡œí•„ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ, ê·¸ ì‚¬ëŒì˜ ì…ì¥ì—ì„œ ìì‹ ì„ ì†Œê°œí•˜ëŠ” 'êµ¬ì–´ì²´' í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê¸€ì“°ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§¤ìš° ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ”..." í•˜ê³  ì‹œì‘í•˜ëŠ” 1ì¸ì¹­ ìê¸°ì†Œê°œ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
  [ê·œì¹™]
  1. 1ì¸ì¹­ ì‹œì ("ì €ëŠ”", "ì œê°€")ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
  2. ë”±ë”±í•œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ, í•˜ë‚˜ì˜ ì—°ê²°ëœ ë¬¸ë‹¨ìœ¼ë¡œ ë§Œë“œì„¸ìš”.
  3. ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ë˜, ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥ì— ë…¹ì—¬ë‚´ì„¸ìš”.
  4. 'party_size'ì™€ 'travel_type'ì„ ë¬¶ì–´ì„œ í‘œí˜„í•˜ì„¸ìš”.
  5. 'budget'ì€ "ê°€ì„±ë¹„ ìˆëŠ”", "ì ë‹¹í•œ", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´" ë“±ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.
  6. 'can_wait'ëŠ” "ë§›ì§‘ì´ë¼ë©´ ì¤„ ì„œëŠ” ê²ƒë„ ê´œì°®ì•„ìš”" ë“±ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.
  """
  user_prompt = f"""
  [ì‚¬ìš©ì í”„ë¡œí•„ JSON]
  {profile_str}
  ìœ„ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ê·œì¹™ì— ë§ê²Œ ìê¸°ì†Œê°œ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
  """
  try:
    resp = client.chat.completions.create(
      model="gpt-4o",
      messages=[
        {"role": "system", "content": summary_system_prompt},
        {"role": "user", "content": user_prompt}
      ],
      temperature=0.7
    )
    summary_ko = resp.choices[0].message.content
    summary_en = _translate_ko_to_en(summary_ko)
    summary_en = enforce_keywords_in_summary(summary_en, profile_data)
    return f"\n\n---\n\n### ğŸ¤– " + _translate_ko_to_en("AIê°€ íŒŒì•…í•œ Charlieë‹˜ì˜ í”„ë¡œí•„") + f"\n\n{summary_en}"
  except Exception as e:
    return "\n\n(" + _translate_ko_to_en("í”„ë¡œí•„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") + f" {e}" + ")"

def call_gpt4o(chat_messages, current_profile):
  if client is None:
    return _no_key_banner(), current_profile
  system_message_with_profile = f"""
  {SYSTEM_PROMPT}

  [í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í”„ë¡œí•„]
  {json.dumps(current_profile, indent=2, ensure_ascii=False)}

  [ëŒ€í™” ê¸°ë¡]
  (ëŒ€í™” ê¸°ë¡ì€ ì•„ë˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤)
  """
  messages = [{"role": "system", "content": system_message_with_profile}]
  messages.extend(chat_messages)
  try:
    response = client.chat.completions.create(
      model="gpt-4o",
      messages=messages,
      response_format={"type": "json_object"},
      temperature=0.7
    )
    data = json.loads(response.choices[0].message.content)
    bot_message_ko = data.get("bot_response", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    updated_profile = data.get("updated_profile", current_profile)
    bot_message_en = _translate_ko_to_en(bot_message_ko)
    return bot_message_en, updated_profile
  except Exception as e:
    return _translate_ko_to_en("ì£„ì†¡í•©ë‹ˆë‹¤. ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:") + f" {e}", current_profile

def start_chat():
  initial_profile = PROFILE_TEMPLATE.copy()
  bot_message_en, updated_profile = call_gpt4o([], initial_profile)
  gradio_history = [(None, bot_message_en)]
  llm_history = [{"role": "assistant", "content": bot_message_en}]
  return gradio_history, llm_history, updated_profile, False

def chat_survey(message, gradio_history, llm_history, current_profile, is_completed):
  llm_history.append({"role": "user", "content": message})
  bot_message_en, updated_profile = call_gpt4o(llm_history, current_profile)
  llm_history.append({"role": "assistant", "content": bot_message_en})

  final_bot_message = bot_message_en
  profile_is_complete = all(v is not None for v in updated_profile.values())
  if profile_is_complete and not is_completed:
    gr.Info("Profile complete! Generating a friendly summary...")
    summary_text = generate_profile_summary(updated_profile)
    final_bot_message = f"{bot_message_en}\n{summary_text}"
    is_completed = True

  gradio_history.append((message, final_bot_message))
  return gradio_history, llm_history, updated_profile, is_completed

with gr.Blocks(theme=gr.themes.Soft()) as demo:
  title = "ğŸ¤– " + _translate_ko_to_en("GPT-4o ê¸°ë°˜ ìì—°ì–´ ì„œë² ì´ ì±—ë´‡ (ìš”ì•½ ê¸°ëŠ¥)")
  subtitle = _translate_ko_to_en("AIê°€ 12ê°€ì§€ í”„ë¡œí•„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì™„ë£Œë˜ë©´ êµ¬ì–´ì²´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")

  if API_ERROR:
    gr.Markdown(f"> {_translate_ko_to_en('ì£¼ì˜: ')}{_translate_ko_to_en(API_ERROR)}")

  gr.Markdown(f"# {title}")
  gr.Markdown(subtitle)

  llm_history_state = gr.State(value=[])
  profile_state = gr.State(value=PROFILE_TEMPLATE.copy())
  is_completed_state = gr.State(value=False)

  chatbot = gr.Chatbot(label=_translate_ko_to_en("ì„œë² ì´ ì±—ë´‡"), height=600, show_copy_button=True)
  msg_textbox = gr.Textbox(label=_translate_ko_to_en("ë‹µë³€ ì…ë ¥"), placeholder=_translate_ko_to_en("ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”..."))

  demo.load(fn=start_chat, inputs=None, outputs=[chatbot, llm_history_state, profile_state, is_completed_state])

  msg_textbox.submit(
    fn=chat_survey,
    inputs=[msg_textbox, chatbot, llm_history_state, profile_state, is_completed_state],
    outputs=[chatbot, llm_history_state, profile_state, is_completed_state]
  )
  msg_textbox.submit(lambda: "", inputs=None, outputs=msg_textbox)

if __name__ == "__main__":
  if API_ERROR:
    print(f"!!! Warning: {API_ERROR}")
    print("!!! Check .env or export OPENAI_API_KEY=sk-... before running.")
  demo.launch()
