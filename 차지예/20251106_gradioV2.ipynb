{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'restaurant_summaries_output_ALL.csv'ì—ì„œ ê°€ê²Œ DB ë¡œë“œ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ê²Œ DB 7713ê°œ ë¡œë“œ ì™„ë£Œ.\n",
      "'20251017_TOTAL_MENU.csv'ì—ì„œ ë©”ë‰´ DB ë¡œë“œ ì¤‘...\n",
      "ë©”ë‰´ DB 54625ê°œ ë¡œë“œ ì™„ë£Œ (ê·¸ë£¹í™” ì™„ë£Œ).\n",
      "'recommendation_results_with_ratings.csv'ì—ì„œ 500ëª… í‰ê°€ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "  > ì‹ë‹¹(restaurant_id)ë³„ 'ì¶”ì²œ', 'ë¯¸ì¶”ì²œ' ì¹´ìš´íŠ¸ ì§‘ê³„ ì¤‘...\n",
      "  > 500ëª… í‰ê°€ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 428ê°œ ì‹ë‹¹\n",
      "\n",
      "--- 2ë‹¨ê³„: VectorDB êµ¬ì¶•/ë¡œë“œ ì‹œì‘ ---\n",
      "  > SentenceTransformer ëª¨ë¸ ('distiluse-base-multilingual-cased-v1')ì„ ì „ì—­ 'sentence_embedder'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n",
      "'./restaurant_db' ê²½ë¡œì—ì„œ Persistent DB í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...\n",
      "\n",
      "[1/2] ê¸°ì¡´ 'restaurants' ì»¬ë ‰ì…˜ ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\n",
      "  > 'restaurants' ë¡œë“œ ì™„ë£Œ: 7713ê°œ\n",
      "\n",
      "[2/2] ê¸°ì¡´ 'mock_profiles' ì»¬ë ‰ì…˜ ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\n",
      "  > 'mock_profiles' ë¡œë“œ ì™„ë£Œ: 500ê°œ\n",
      "--- 2ë‹¨ê³„: VectorDB 2ê°œ ì»¬ë ‰ì…˜ ë¡œë“œ/êµ¬ì¶• ì™„ë£Œ ---\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas chromadb openai gradio\n",
    "# !pip install python-dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time \n",
    "import ast\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import openai\n",
    "import random\n",
    "import gradio as gr\n",
    "from urllib.parse import urlparse, quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- 2/4: Global Variables (ì „ì—­ ë³€ìˆ˜ ë° ì„¤ì •) ---\n",
    "RESTAURANT_DB_FILE = \"restaurant_summaries_output_ALL.csv\"\n",
    "MENU_DB_FILE = \"20251017_TOTAL_MENU.csv\"\n",
    "DB_PERSISTENT_PATH = \"./restaurant_db\"\n",
    "\n",
    "# í”„ë¡œí•„ DB\n",
    "PROFILE_DB_FILE = \"user_profiles_for_hybrid_search.csv\"\n",
    "RESTAURANT_COLLECTION_NAME = \"restaurants\"\n",
    "PROFILE_COLLECTION_NAME = \"mock_profiles\"\n",
    "\n",
    "# Gradioê°€ ì‚¬ìš©í•  ì „ì—­ DB ë³€ìˆ˜\n",
    "df_restaurants = None\n",
    "df_menus = None\n",
    "collection = None\n",
    "profile_collection = None\n",
    "menu_groups = None\n",
    "\n",
    "# 500ëª… í‰ê°€ ë°ì´í„° ì €ì¥ìš© ì „ì—­ ë³€ìˆ˜\n",
    "df_all_user_ratings = None \n",
    "df_restaurant_ratings_summary = None \n",
    "\n",
    "# DB ì¬êµ¬ì¶• ì„¤ì •\n",
    "CLEAR_DB_AND_REBUILD = False\n",
    "\n",
    "# ìœ ì‚¬ ì‚¬ìš©ì ì¶”ì²œìš© ì „ì—­ ë³€ìˆ˜\n",
    "sentence_embedder = None\n",
    "\n",
    "# LLM API ì„¤ì •\n",
    "GPT_API_NAME = \"gpt-4.1-mini\" \n",
    "try:\n",
    "  client = openai.OpenAI() \n",
    "  if not client.api_key:\n",
    "    client.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not client.api_key:\n",
    "      raise openai.OpenAIError(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "  print(f\"API í‚¤ ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "  exit()\n",
    "\n",
    "# --- 2. (ë©”ì¸) ì±—ë´‡ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ---\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "ë‹¹ì‹ ì€ ë§¤ìš° ì¹œì ˆí•˜ê³  ì§€ëŠ¥ì ì¸ í•œêµ­ ì—¬í–‰ ë„ìš°ë¯¸ ì±—ë´‡ì…ë‹ˆë‹¤.\n",
    "ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©°, 13ê°€ì§€ í•„ìˆ˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ JSON í”„ë¡œí•„ì„ ì™„ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "[ìˆ˜ì§‘í•´ì•¼ í•  13ê°œ í•­ëª© ìŠ¤í‚¤ë§ˆ]\n",
    "0.  name: (ì‚¬ìš©ìì˜ ì´ë¦„, ì˜ˆ: \"Lucas Fernandez\", \"Soojin Kim\")\n",
    "1.  age: (ì˜ˆ: \"10ëŒ€\", \"20ëŒ€\", \"30ëŒ€\"...)\n",
    "2.  gender: (ì˜ˆ: \"ë‚¨\", \"ì—¬\", \"ê¸°íƒ€\")\n",
    "3.  nationality: (ì˜ˆ: \"ë¯¸êµ­\", \"ì¼ë³¸\", \"ì¤‘êµ­\")\n",
    "4.  travel_type: (ì˜ˆ: \"ê°€ì¡±\", \"í˜¼ì\", \"ì¹œêµ¬\", \"ì—°ì¸\")\n",
    "5.  party_size: (ì˜ˆ: 1, 2, 4...)\n",
    "6.  can_wait: (ì›¨ì´íŒ… ê°€ëŠ¥ ì—¬ë¶€, ì˜ˆ: \"O\", \"X\")\n",
    "7.  budget: (ì˜ˆì‚° ìˆ˜ì¤€, ì˜ˆ: \"ì €\", \"ì¤‘\", \"ê³ \")\n",
    "8.  spicy_ok: (ë§¤ìš´ ìŒì‹ ê°€ëŠ¥ ì—¬ë¶€, ì˜ˆ: \"O\", \"X\")\n",
    "9.  is_vegetarian: (ì±„ì‹ ì—¬ë¶€, ì˜ˆ: \"O\", \"X\")\n",
    "10. avoid_ingredients: (ì ˆëŒ€ ë¶ˆê°€ ì‹ì¬ë£Œ, ì˜ˆ: \"ë¼ì§€ê³ ê¸°\", \"ê²¬ê³¼ë¥˜\", \"ì—†ìŒ\")\n",
    "11. like_ingredients: (ì¢‹ì•„í•˜ëŠ” ì‹ì¬ë£Œ, ì˜ˆ: \"ë‹­ê³ ê¸°\", \"í•´ì‚°ë¬¼\", \"ì•¼ì±„\")\n",
    "12. food_category: (ì„ í˜¸ ìŒì‹ ë¶„ë¥˜, ì˜ˆ: \"í•œì‹\", \"ì¼ì‹\", \"ë””ì €íŠ¸\", \"ìƒê´€ì—†ìŒ\")\n",
    "\n",
    "[ëŒ€í™” ê·œì¹™]\n",
    "1.  ëŒ€í™”ëŠ” ë‹¹ì‹ ì´ ë¨¼ì € ì‹œì‘í•©ë‹ˆë‹¤. í™˜ì˜ ì¸ì‚¬ì™€ í•¨ê»˜ ì²« ì§ˆë¬¸(ì˜ˆ: ì„±í•¨)ì„ í•˜ì„¸ìš”.\n",
    "2.  í•­ìƒ í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸í•˜ì„¸ìš”.\n",
    "3.  ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ [í˜„ì¬ í”„ë¡œí•„]ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "4.  ì—…ë°ì´íŠ¸ëœ í”„ë¡œí•„ì„ í™•ì¸í•˜ê³ , ì•„ì§ 'null'ì´ê±°ë‚˜ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ í•­ëª© ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.\n",
    "5.  ëª¨ë“  13ê°œ í•­ëª©ì´ ìˆ˜ì§‘ë˜ë©´, \"ì„¤ë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤.\"ë¼ëŠ” ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ë” ì´ìƒ ì§ˆë¬¸í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "6.  ë§¤ìš° ì¹œì ˆí•˜ê³  ê³µê°í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.\n",
    "\n",
    "[í•„ìˆ˜ ì¶œë ¥ í¬ë§·]\n",
    "ë‹¹ì‹ ì€ *ë°˜ë“œì‹œ* ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "{\n",
    "  \"updated_profile\": {\n",
    "    \"name\": \"Lucas Fernandez\", \n",
    "    \"age\": \"20ëŒ€\",\n",
    "    \"gender\": \"ë‚¨\",\n",
    "    \"nationality\": null,\n",
    "    // ... (13ê°œ í•­ëª© ëª¨ë‘ í¬í•¨) ...\n",
    "  },\n",
    "  \"bot_response\": \"Lucasë‹˜ì´ì‹œêµ°ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤. í˜¹ì‹œ ì—°ë ¹ëŒ€ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# (13ê°œ í•­ëª© í…œí”Œë¦¿)\n",
    "PROFILE_TEMPLATE = {\n",
    "  \"name\": None, \"age\": None, \"gender\": None, \"nationality\": None, \n",
    "  \"travel_type\": None, \"party_size\": None, \"can_wait\": None, \n",
    "  \"budget\": None, \"spicy_ok\": None, \"is_vegetarian\": None, \n",
    "  \"avoid_ingredients\": None, \"like_ingredients\": None, \"food_category\": None\n",
    "}\n",
    "\n",
    "# --- 3/4: í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---\n",
    "\n",
    "def load_app_data(store_path, menu_path):\n",
    "  \"\"\"\n",
    "  ì•± ì‹¤í–‰ì— í•„ìš”í•œ ëª¨ë“  CSV íŒŒì¼ì„ ë¡œë“œí•˜ì—¬\n",
    "  2ê°œì˜ ì „ì—­ DataFrameì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "  \"\"\"\n",
    "  global df_restaurants, df_menus, menu_groups\n",
    "  \n",
    "  try:\n",
    "    print(f\"'{store_path}'ì—ì„œ ê°€ê²Œ DB ë¡œë“œ ì¤‘...\")\n",
    "    df_restaurants = pd.read_csv(store_path)\n",
    "    df_restaurants['id'] = df_restaurants['id'].astype(str)\n",
    "    df_restaurants = df_restaurants.set_index('id')\n",
    "    print(f\"ê°€ê²Œ DB {len(df_restaurants)}ê°œ ë¡œë“œ ì™„ë£Œ.\")\n",
    "    \n",
    "    print(f\"'{menu_path}'ì—ì„œ ë©”ë‰´ DB ë¡œë“œ ì¤‘...\")\n",
    "    df_menus = pd.read_csv(menu_path)\n",
    "    df_menus['ì‹ë‹¹ID'] = df_menus['ì‹ë‹¹ID'].astype(str)\n",
    "    menu_groups = df_menus.groupby('ì‹ë‹¹ID')\n",
    "    print(f\"ë©”ë‰´ DB {len(df_menus)}ê°œ ë¡œë“œ ì™„ë£Œ (ê·¸ë£¹í™” ì™„ë£Œ).\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "  except FileNotFoundError as e:\n",
    "    print(f\"[ì˜¤ë¥˜] í•„ìˆ˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    return False\n",
    "  except Exception as e:\n",
    "    print(f\"[ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    return False\n",
    "\n",
    "def load_and_prepare_data(csv_path):\n",
    "  \"\"\"\n",
    "  restaurant_summaries_output...csv íŒŒì¼ì„ ë¡œë“œí•˜ê³ \n",
    "  'ë©”íƒ€ë°ì´í„°' ì»¬ëŸ¼ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "  \"\"\"\n",
    "  print(f\"'{csv_path}' íŒŒì¼ ë¡œë“œ ì¤‘...\")\n",
    "  try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "  except FileNotFoundError:\n",
    "    print(f\"[ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}\")\n",
    "    return None\n",
    "\n",
    "  def safe_convert_to_dict(x):\n",
    "    if pd.isna(x) or x == '{}' or x == '':\n",
    "      return {}\n",
    "    try:\n",
    "      return ast.literal_eval(x)\n",
    "    except Exception as e:\n",
    "      print(f\"ë©”íƒ€ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e} \\në°ì´í„°: {x}\")\n",
    "      return {\"error\": \"parsing_failed\"}\n",
    "\n",
    "  print(\"ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ ì¤‘...\")\n",
    "  df['ë©”íƒ€ë°ì´í„°'] = df['ë©”íƒ€ë°ì´í„°'].apply(safe_convert_to_dict)\n",
    "  df['RAGí…ìŠ¤íŠ¸'] = df['RAGí…ìŠ¤íŠ¸'].fillna('')\n",
    "  \n",
    "  print(f\"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df)}ê°œ\")\n",
    "  return df\n",
    "\n",
    "def build_vector_db(store_csv_path, profile_csv_path, clear_db=False):\n",
    "  \"\"\"\n",
    "  ë ˆìŠ¤í† ë‘ + í”„ë¡œí•„ìš© ChromaDB 2ê°œ ì»¬ë ‰ì…˜ ìƒì„±/ë¡œë“œ\n",
    "  \"\"\"\n",
    "  global collection, profile_collection, sentence_embedder\n",
    "  \n",
    "  print(\"\\n--- 2ë‹¨ê³„: VectorDB êµ¬ì¶•/ë¡œë“œ ì‹œì‘ ---\")\n",
    "  \n",
    "  model_name = \"distiluse-base-multilingual-cased-v1\"\n",
    "  sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=model_name\n",
    "  )\n",
    "  sentence_embedder = sentence_transformer_ef._model\n",
    "  print(f\"  > SentenceTransformer ëª¨ë¸ ('{model_name}')ì„ ì „ì—­ 'sentence_embedder'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "  \n",
    "  print(f\"'{DB_PERSISTENT_PATH}' ê²½ë¡œì—ì„œ Persistent DB í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...\")\n",
    "  client = chromadb.PersistentClient(path=DB_PERSISTENT_PATH)\n",
    "\n",
    "  if clear_db:\n",
    "    print(f\"[ê²½ê³ ] CLEAR_DB_AND_REBUILD=True. ì»¬ë ‰ì…˜ 2ê°œ(restaurants, mock_profiles)ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.\")\n",
    "    try:\n",
    "      client.delete_collection(name=RESTAURANT_COLLECTION_NAME)\n",
    "      print(f\"  > '{RESTAURANT_COLLECTION_NAME}' ì‚­ì œ ì™„ë£Œ.\")\n",
    "    except Exception as e:\n",
    "      print(f\"  > '{RESTAURANT_COLLECTION_NAME}' ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}\")\n",
    "    try:\n",
    "      client.delete_collection(name=PROFILE_COLLECTION_NAME)\n",
    "      print(f\"  > '{PROFILE_COLLECTION_NAME}' ì‚­ì œ ì™„ë£Œ.\")\n",
    "    except Exception as e:\n",
    "      print(f\"  > '{PROFILE_COLLECTION_NAME}' ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}\")\n",
    "\n",
    "  # --- 1. ë ˆìŠ¤í† ë‘ ì»¬ë ‰ì…˜ ---\n",
    "  try:\n",
    "    print(f\"\\n[1/2] ê¸°ì¡´ '{RESTAURANT_COLLECTION_NAME}' ì»¬ë ‰ì…˜ ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "    collection = client.get_collection(\n",
    "      name=RESTAURANT_COLLECTION_NAME,\n",
    "      embedding_function=sentence_transformer_ef\n",
    "    )\n",
    "    print(f\"  > 'restaurants' ë¡œë“œ ì™„ë£Œ: {collection.count()}ê°œ\")\n",
    "  except Exception as e:\n",
    "    print(f\"  > 'restaurants' ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìœ : {e})\")\n",
    "    print(\"  > ìƒˆ 'restaurants' ì»¬ë ‰ì…˜ì„ ìƒì„±í•˜ê³  ë°ì´í„° ì ì¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    df_for_embedding = load_and_prepare_data(store_csv_path)\n",
    "    if df_for_embedding is None:\n",
    "      print(\"[ì˜¤ë¥˜] 'restaurants' DB ì ì¬ë¥¼ ìœ„í•œ ì›ë³¸ CSV ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "      return False\n",
    "\n",
    "    try:\n",
    "      collection = client.create_collection(\n",
    "        name=RESTAURANT_COLLECTION_NAME,\n",
    "        embedding_function=sentence_transformer_ef\n",
    "      )\n",
    "    except Exception as e:\n",
    "      print(f\"[ì˜¤ë¥˜] 'restaurants' ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "      return False\n",
    "\n",
    "    documents_list = df_for_embedding['RAGí…ìŠ¤íŠ¸'].tolist()\n",
    "    metadatas_list = df_for_embedding['ë©”íƒ€ë°ì´í„°'].tolist() \n",
    "    ids_list = df_for_embedding['id'].astype(str).tolist()\n",
    "\n",
    "    print(\"  > 'restaurants' ë©”íƒ€ë°ì´í„° ë³€í™˜ ì¤‘...\")\n",
    "    processed_metadatas = []\n",
    "    for metadata_dict in metadatas_list:\n",
    "      processed_meta_item = {}\n",
    "      for key, value in metadata_dict.items():\n",
    "        if value is None:\n",
    "          processed_meta_item[key] = \"\" \n",
    "        elif isinstance(value, list):\n",
    "          processed_meta_item[key] = \",\".join(map(str, value))\n",
    "        else:\n",
    "          processed_meta_item[key] = value\n",
    "      processed_metadatas.append(processed_meta_item)\n",
    "\n",
    "    print(f\"  > 'restaurants' DBì— {len(ids_list)}ê°œ ì ì¬ ì¤‘ (ë°°ì¹˜)...\")\n",
    "    BATCH_SIZE = 5000\n",
    "    for i in range(0, len(ids_list), BATCH_SIZE):\n",
    "      end_i = min(i + BATCH_SIZE, len(ids_list))\n",
    "      collection.add(\n",
    "        documents=documents_list[i:end_i],\n",
    "        metadatas=processed_metadatas[i:end_i],\n",
    "        ids=ids_list[i:end_i]\n",
    "      )\n",
    "    print(f\"  > 'restaurants' ì‹ ê·œ êµ¬ì¶• ì™„ë£Œ: {collection.count()}ê°œ\")\n",
    "\n",
    "  # --- 2. í”„ë¡œí•„ ì»¬ë ‰ì…˜ ---\n",
    "  try:\n",
    "    print(f\"\\n[2/2] ê¸°ì¡´ '{PROFILE_COLLECTION_NAME}' ì»¬ë ‰ì…˜ ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "    profile_collection = client.get_collection(\n",
    "      name=PROFILE_COLLECTION_NAME,\n",
    "      embedding_function=sentence_transformer_ef\n",
    "    )\n",
    "    print(f\"  > 'mock_profiles' ë¡œë“œ ì™„ë£Œ: {profile_collection.count()}ê°œ\")\n",
    "  except Exception as e:\n",
    "    print(f\"  > 'mock_profiles' ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìœ : {e})\")\n",
    "    print(\"  > ìƒˆ 'mock_profiles' ì»¬ë ‰ì…˜ì„ ìƒì„±í•˜ê³  ë°ì´í„° ì ì¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    try:\n",
    "      df_profiles = pd.read_csv(profile_csv_path)\n",
    "      df_profiles = df_profiles.dropna(subset=['rag_query_text', 'user_id'])\n",
    "      print(f\"  > '{profile_csv_path}' íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df_profiles)}ê°œ í”„ë¡œí•„\")\n",
    "    except FileNotFoundError:\n",
    "      print(f\"[ì˜¤ë¥˜] '{profile_csv_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "      return False\n",
    "    except Exception as e:\n",
    "      print(f\"[ì˜¤ë¥˜] í”„ë¡œí•„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "      return False\n",
    "\n",
    "    try:\n",
    "      profile_collection = client.create_collection(\n",
    "        name=PROFILE_COLLECTION_NAME,\n",
    "        embedding_function=sentence_transformer_ef\n",
    "      )\n",
    "    except Exception as e:\n",
    "      print(f\"[ì˜¤ë¥˜] 'mock_profiles' ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "      return False\n",
    "\n",
    "    profile_docs = df_profiles['rag_query_text'].tolist()\n",
    "    profile_ids = df_profiles['user_id'].astype(str).tolist()\n",
    "    profile_metas = [{'user_id': uid} for uid in profile_ids]\n",
    "\n",
    "    print(f\"  > 'mock_profiles' DBì— {len(profile_ids)}ê°œ ì ì¬ ì¤‘...\")\n",
    "    profile_collection.add(\n",
    "      documents=profile_docs,\n",
    "      metadatas=profile_metas,\n",
    "      ids=profile_ids\n",
    "    )\n",
    "    print(f\"  > 'mock_profiles' ì‹ ê·œ êµ¬ì¶• ì™„ë£Œ: {profile_collection.count()}ê°œ\")\n",
    "\n",
    "  print(f\"--- 2ë‹¨ê³„: VectorDB 2ê°œ ì»¬ë ‰ì…˜ ë¡œë“œ/êµ¬ì¶• ì™„ë£Œ ---\")\n",
    "  return True\n",
    "\n",
    "def call_gpt4o(chat_messages, current_profile):\n",
    "  \"\"\"gpt-4.1-mini API í˜¸ì¶œ + JSON íŒŒì‹±\"\"\"\n",
    "  \n",
    "  system_message_with_profile = f\"\"\"\n",
    "  {SYSTEM_PROMPT}\n",
    "  [í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í”„ë¡œí•„]\n",
    "  {json.dumps(current_profile, indent=2, ensure_ascii=False)}\n",
    "  [ëŒ€í™” ê¸°ë¡]\n",
    "  (ëŒ€í™” ê¸°ë¡ì€ ì•„ë˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤)\n",
    "  \"\"\"\n",
    "  \n",
    "  messages_for_api = [\n",
    "    {\"role\": \"system\", \"content\": system_message_with_profile}\n",
    "  ]\n",
    "  messages_for_api.extend(chat_messages)\n",
    "\n",
    "  try:\n",
    "    response = client.chat.completions.create(\n",
    "      model=GPT_API_NAME,\n",
    "      messages=messages_for_api,\n",
    "      response_format={\"type\": \"json_object\"}, \n",
    "      temperature=0.7\n",
    "    )\n",
    "    \n",
    "    response_content = response.choices[0].message.content\n",
    "    response_data = json.loads(response_content)\n",
    "    \n",
    "    bot_message = response_data.get(\"bot_response\", \"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    updated_profile = response_data.get(\"updated_profile\", current_profile)\n",
    "    \n",
    "    return bot_message, updated_profile\n",
    "    \n",
    "  except Exception as e:\n",
    "    print(f\"API í˜¸ì¶œ ë˜ëŠ” JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "    error_message = f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
    "    return error_message, current_profile\n",
    "\n",
    "def start_chat():\n",
    "  \"\"\"\n",
    "  ì±„íŒ…ë°©ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ ì‹¤í–‰.\n",
    "  gpt-4.1-minië¥¼ í˜¸ì¶œí•˜ì—¬ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ë°›ëŠ”ë‹¤.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    initial_profile = PROFILE_TEMPLATE.copy()\n",
    "    \n",
    "    bot_message, updated_profile = call_gpt4o(\n",
    "      chat_messages=[], \n",
    "      current_profile=initial_profile\n",
    "    )\n",
    "    \n",
    "    gradio_history = [{\"role\": \"assistant\", \"content\": bot_message}]\n",
    "    llm_history = [{\"role\": \"assistant\", \"content\": bot_message}]\n",
    "    \n",
    "    # user_profile_row_stateëŠ” ì•„ì§ ì—†ìŒ\n",
    "    return gradio_history, llm_history, updated_profile, False, None\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"start_chatì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "    error_msg = f\"ì±—ë´‡ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤): {e}\"\n",
    "    return [{\"role\": \"assistant\", \"content\": error_msg}], [], PROFILE_TEMPLATE.copy(), False, None\n",
    "\n",
    "def generate_profile_summary(profile_data):\n",
    "  \"\"\"\n",
    "  ì™„ì„±ëœ í”„ë¡œí•„(JSON)ì„ ë°›ì•„,\n",
    "  (1) Gradio ì±„íŒ…ìš© ë©”ì‹œì§€, (2) CSV ì €ì¥ìš© ì›ë³¸ ìš”ì•½ë¬¸ í…ìŠ¤íŠ¸ ë°˜í™˜\n",
    "  \"\"\"\n",
    "  profile_str = json.dumps(profile_data, indent=2, ensure_ascii=False)\n",
    "  \n",
    "  summary_system_prompt = \"\"\"\n",
    "  ë‹¹ì‹ ì€ JSON í”„ë¡œí•„ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ, ê·¸ ì‚¬ëŒì˜ ì…ì¥ì—ì„œ ìì‹ ì„ ì†Œê°œí•˜ëŠ” 'êµ¬ì–´ì²´' í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê¸€ì“°ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "  [ê·œì¹™]\n",
    "  1. (í•„ìˆ˜) JSONì˜ 'name' í•„ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” [name]ì…ë‹ˆë‹¤.\"ë¡œ ë¬¸ì¥ì„ ì‹œì‘í•˜ì„¸ìš”.\n",
    "  2. ë”±ë”±í•œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ, í•˜ë‚˜ì˜ ì—°ê²°ëœ ë¬¸ë‹¨ìœ¼ë¡œ ë§Œë“œì„¸ìš”.\n",
    "  3. ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ë˜, ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥ì— ë…¹ì—¬ë‚´ì„¸ìš”.\n",
    "  4. 'party_size'ì™€ 'travel_type'ì„ ë¬¶ì–´ì„œ í‘œí˜„í•˜ì„¸ìš”.\n",
    "  5. 'budget'ì€ \"ê°€ì„±ë¹„ ìˆëŠ”(ì €ë ´í•œ)\", \"ì ë‹¹í•œ\", \"ê³ ê¸‰ìŠ¤ëŸ¬ìš´\" ë“±ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.\n",
    "  \"\"\"\n",
    "  \n",
    "  user_prompt = f\"\"\"\n",
    "  [ì‚¬ìš©ì í”„ë¡œí•„ JSON]\n",
    "  {profile_str}\n",
    "  ìœ„ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ê·œì¹™ì— ë§ê²Œ ìê¸°ì†Œê°œ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "  \"\"\"\n",
    "  \n",
    "  try:\n",
    "    response = client.chat.completions.create(\n",
    "      model=GPT_API_NAME,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": summary_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ],\n",
    "      temperature=0.7\n",
    "    )\n",
    "    \n",
    "    raw_summary_text = response.choices[0].message.content\n",
    "    name = profile_data.get('name', 'ì‚¬ìš©ì')\n",
    "    chat_message_html = f\"\\n\\n---\\n\\n### ğŸ¤– AIê°€ íŒŒì•…í•œ {name}ë‹˜ì˜ í”„ë¡œí•„\\n\\n{raw_summary_text}\"\n",
    "    \n",
    "    return chat_message_html, raw_summary_text\n",
    "  \n",
    "  except Exception as e:\n",
    "    print(f\"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "    error_html = \"\\n\\n(í”„ë¡œí•„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)\"\n",
    "    error_text = \"(í”„ë¡œí•„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)\"\n",
    "    return error_html, error_text\n",
    "\n",
    "def create_filter_metadata(profile_data):\n",
    "  \"\"\"\n",
    "  13ê°œ í•­ëª© í”„ë¡œí•„ â†’ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš© 6ê°œ í•„í„°\n",
    "  \"\"\"\n",
    "  filter_dict = {\n",
    "    \"budget_range\": profile_data.get('budget', 'N/A'),\n",
    "    \"spicy_available\": profile_data.get('spicy_ok', 'N/A'),\n",
    "    \"vegetarian_options\": profile_data.get('is_vegetarian', 'N/A'),\n",
    "    \"main_ingredients_list\": profile_data.get('like_ingredients', 'N/A'),\n",
    "    \"suitable_for\": profile_data.get('travel_type', 'N/A'),\n",
    "    \"food_category\": profile_data.get('food_category', 'N/A')\n",
    "  }\n",
    "  return filter_dict\n",
    "\n",
    "def generate_rag_query(user_profile_summary):\n",
    "  \"\"\"\n",
    "  ìê¸°ì†Œê°œ ìš”ì•½ë¬¸ â†’ RAGìš© ì§§ì€ í•µì‹¬ ì¿¼ë¦¬\n",
    "  \"\"\"\n",
    "  print(\"  > [RAG] LLMì„ í˜¸ì¶œí•˜ì—¬ 'ë¶„ìœ„ê¸°/ì„±í–¥' ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤...\")\n",
    "  \n",
    "  system_prompt = \"\"\"\n",
    "  ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê¸´ ìê¸°ì†Œê°œ í…ìŠ¤íŠ¸ë¥¼, ë ˆìŠ¤í† ë‘ ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ\n",
    "  'ì§§ê³  í•µì‹¬ì ì¸ ì¿¼ë¦¬ ë¬¸ì¥'ìœ¼ë¡œ ì¬ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "  1. ê°œì¸ ì‹ ìƒ ì •ë³´ ì œê±°\n",
    "  2. ì˜ˆì‚°/ë§¤ìš´ ì •ë„/ì¬ë£Œ ê°™ì€ íŒ©íŠ¸ ì œê±°\n",
    "  3. ë¶„ìœ„ê¸°/ìƒí™©/ê²½í—˜/ì„±í–¥ë§Œ ë‚¨ê¸°ê¸°\n",
    "  \"\"\"\n",
    "  \n",
    "  user_prompt = f\"\"\"\n",
    "  [ì‚¬ìš©ì ìê¸°ì†Œê°œ]\n",
    "  {user_profile_summary}\n",
    "  \n",
    "  [ì¬ì‘ì„±ëœ ì¿¼ë¦¬]\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    response = client.chat.completions.create(\n",
    "      model=GPT_API_NAME,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ],\n",
    "      temperature=0.2\n",
    "    )\n",
    "    rewritten_query = response.choices[0].message.content.strip().replace('\"', '')\n",
    "    return rewritten_query\n",
    "  except Exception as e:\n",
    "    print(f\"  > [ì˜¤ë¥˜] ì¿¼ë¦¬ ì¬ì‘ì„± ì‹¤íŒ¨: {e}\")\n",
    "    return user_profile_summary[:150]\n",
    "\n",
    "def build_filters_from_profile(user_filter_dict):\n",
    "  \"\"\"\n",
    "  ì‚¬ìš©ì í•„í„° dict â†’ ChromaDB where í•„í„°\n",
    "  \"\"\"\n",
    "  db_pre_filter_list = [] \n",
    "  \n",
    "  DB_FILTER_KEYS = ['budget_range', 'spicy_available', 'vegetarian_options']\n",
    "\n",
    "  for key, value in user_filter_dict.items():\n",
    "    if value == 'N/A' or not value: \n",
    "      continue\n",
    "      \n",
    "    if key == 'food_category':\n",
    "      db_pre_filter_list.append({\"high_level_category\": value})\n",
    "    elif key in DB_FILTER_KEYS:\n",
    "      db_pre_filter_list.append({key: value})\n",
    "      \n",
    "  db_pre_filter = {\"$and\": db_pre_filter_list} if db_pre_filter_list else {}\n",
    "  \n",
    "  return db_pre_filter\n",
    "\n",
    "def format_restaurant_markdown(store_id_str, rank_prefix=\"ì¶”ì²œ\", rank_index=1):\n",
    "  \"\"\"\n",
    "  ë‹¨ì¼ ì‹ë‹¹ Markdown ë¬¸ìì—´ ìƒì„± (ì´ë¯¸ì§€/ë§í¬/ë©”ë‰´ í¬í•¨)\n",
    "  \"\"\"\n",
    "  global df_restaurants, menu_groups, df_restaurant_ratings_summary\n",
    "  \n",
    "  try:\n",
    "    store_info = df_restaurants.loc[store_id_str]\n",
    "    store_name = store_info['ê°€ê²Œ']\n",
    "    store_address = store_info['ì£¼ì†Œ']\n",
    "    store_intro = store_info['ì†Œê°œ']\n",
    "    store_image_url = store_info.get('ì´ë¯¸ì§€URL', '') \n",
    "    \n",
    "    detail_url = store_info.get('ìƒì„¸URL', '')\n",
    "    store_y = store_info.get('Yì¢Œí‘œ', '')\n",
    "    store_x = store_info.get('Xì¢Œí‘œ', '')\n",
    "    \n",
    "    try:\n",
    "      store_category = store_info.get('high_level_category', 'N/A')\n",
    "    except KeyError:\n",
    "      store_category = 'N/A' \n",
    "\n",
    "    social_proof_string = \"\" \n",
    "    if df_restaurant_ratings_summary is not None and not df_restaurant_ratings_summary.empty:\n",
    "      try:\n",
    "        rating_info = df_restaurant_ratings_summary[\n",
    "          df_restaurant_ratings_summary['restaurant_id'] == store_id_str\n",
    "        ]\n",
    "        if not rating_info.empty:\n",
    "          recommend_count = rating_info['ì¶”ì²œ'].iloc[0]\n",
    "          non_recommend_count = rating_info['ë¯¸ì¶”ì²œ'].iloc[0]\n",
    "          social_proof_string = (\n",
    "            f\"**ë‹¤ë¥¸ ì‚¬ìš©ì í‰ê°€:** ğŸ‘ {recommend_count}ëª… / ğŸ‘ {non_recommend_count}ëª…\\n\\n\"\n",
    "          )\n",
    "      except Exception as e:\n",
    "        print(f\"[ì„œì‹ ì˜¤ë¥˜] ID {store_id_str} í‰ê°€ ì¹´ìš´íŠ¸ ì¡°íšŒ: {e}\")\n",
    "\n",
    "    image_md_string = \"\"\n",
    "    no_image_filename = \"img_restaruant_no_image.png\"\n",
    "    if pd.notna(store_image_url) and store_image_url:\n",
    "      path = urlparse(store_image_url).path\n",
    "      filename = os.path.basename(path)\n",
    "      if filename != no_image_filename:\n",
    "        image_md_string = f\"![{store_name} ì´ë¯¸ì§€]({store_image_url})\\n\\n\"\n",
    "        \n",
    "    detail_link_md = \"\"\n",
    "    if pd.notna(detail_url) and detail_url:\n",
    "      detail_link_md = f'<a href=\"{detail_url}\" target=\"_blank\">ê°€ê²Œ ìƒì„¸ì •ë³´</a>'\n",
    "\n",
    "    map_link_md = \"\"\n",
    "    if pd.notna(store_y) and pd.notna(store_x) and store_y and store_x:\n",
    "      store_name_encoded = quote(store_name)\n",
    "      kakao_map_url = f\"https://map.kakao.com/?q={store_name_encoded}&map_type=TYPE_MAP&rq={store_y},{store_x}\"\n",
    "      map_link_md = f'<a href=\"{kakao_map_url}\" target=\"_blank\">ì¹´ì¹´ì˜¤ë§µ ê¸¸ì°¾ê¸°</a>'\n",
    "\n",
    "    links_md = \"\"\n",
    "    if detail_link_md and map_link_md:\n",
    "      links_md = f\"{detail_link_md} | {map_link_md}\\n\\n\"\n",
    "    elif detail_link_md:\n",
    "      links_md = f\"{detail_link_md}\\n\\n\"\n",
    "    elif map_link_md:\n",
    "      links_md = f\"{map_link_md}\\n\\n\"\n",
    "\n",
    "    menu_str = \"\"\n",
    "    try:\n",
    "      menus_df = menu_groups.get_group(store_id_str)\n",
    "      rep_menus = menus_df[menus_df['ëŒ€í‘œì—¬ë¶€'] == 'Y'].head(3)\n",
    "      if rep_menus.empty:\n",
    "        rep_menus = menus_df.head(3)\n",
    "      for _, menu_row in rep_menus.iterrows():\n",
    "        menu_str += f\"* {menu_row['ë©”ë‰´']} ({menu_row['ê°€ê²©ì›ë¬¸']})\\n\"\n",
    "      if not menu_str:\n",
    "        menu_str = \"* (ë©”ë‰´ ì •ë³´ ì—†ìŒ)\\n\"\n",
    "    except KeyError:\n",
    "      menu_str = \"* (ë©”ë‰´ ì •ë³´ ì—†ìŒ)\\n\"\n",
    "\n",
    "    output_md = (\n",
    "      f\"**[{rank_prefix} {rank_index}] {store_name}**\\n\\n\"\n",
    "      f\"{image_md_string}\"\n",
    "      f\"{social_proof_string}\"\n",
    "      f\"{links_md}\"\n",
    "      f\"**ìœ„ì¹˜:** {store_address}\\n\\n\"\n",
    "      f\"**ì†Œê°œ:** {store_intro}\\n\\n\"\n",
    "      f\"**ìŒì‹ì¢…ë¥˜:** {store_category}\\n\\n\"\n",
    "      f\"**ì£¼ìš”ë©”ë‰´:**\\n{menu_str}\\n\"\n",
    "      f\"\\n---\\n\\n\"\n",
    "    )\n",
    "    return output_md\n",
    "    \n",
    "  except KeyError as ke:\n",
    "     print(f\"[ì„œì‹ ì˜¤ë¥˜] ID {store_id_str} (KeyError): {ke}\")\n",
    "     return f\"**[{rank_prefix} {rank_index}] ID: {store_id_str}** (ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨)\\n\\n---\\n\\n\"\n",
    "  except Exception as inner_e:\n",
    "     print(f\"[ì„œì‹ ì˜¤ë¥˜] ID {store_id_str} (Exception): {inner_e}\")\n",
    "     return f\"**[{rank_prefix} {rank_index}] ID: {store_id_str}** (ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨)\\n\\n---\\n\\n\"\n",
    "\n",
    "def get_similar_user_recommendations(\n",
    "    live_rag_query_text, \n",
    "    primary_reco_ids, \n",
    "    max_similar_users=1, \n",
    "    max_new_recos=2\n",
    "  ):\n",
    "  \"\"\"\n",
    "  ìœ ì‚¬ ì‚¬ìš©ì ì¶”ì²œ í—¬í¼\n",
    "  \"\"\"\n",
    "  global profile_collection, df_all_user_ratings\n",
    "  \n",
    "  if profile_collection is None:\n",
    "    print(\"[ìœ ì‚¬ ì¶”ì²œ] 'profile_collection'ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return \"\"\n",
    "    \n",
    "  if df_all_user_ratings is None:\n",
    "    print(\"[ìœ ì‚¬ ì¶”ì²œ] 'df_all_user_ratings'ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return \"\"\n",
    "\n",
    "  try:\n",
    "    results = profile_collection.query(\n",
    "      query_texts=[live_rag_query_text],\n",
    "      n_results=max_similar_users\n",
    "    )\n",
    "    \n",
    "    if not results.get('ids', [[]])[0]:\n",
    "      print(\"[ìœ ì‚¬ ì¶”ì²œ] ìœ ì‚¬í•œ ì‚¬ìš©ìë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "      return \"\"\n",
    "      \n",
    "    similar_user_ids = [meta['user_id'] for meta in results['metadatas'][0]]\n",
    "    print(f\"[ìœ ì‚¬ ì¶”ì²œ] ì°¾ì€ ìœ ì‚¬ ì‚¬ìš©ì: {similar_user_ids}\")\n",
    "\n",
    "    similar_user_likes = df_all_user_ratings[\n",
    "      (df_all_user_ratings['user_id'].isin(similar_user_ids)) &\n",
    "      (df_all_user_ratings['ì‚¬ìš©ìí‰ê°€'] == 'ì¶”ì²œ')\n",
    "    ]\n",
    "    \n",
    "    if similar_user_likes.empty:\n",
    "      print(\"[ìœ ì‚¬ ì¶”ì²œ] ìœ ì‚¬ ì‚¬ìš©ìê°€ 'ì¶”ì²œ'í•œ ì‹ë‹¹ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "      return \"\"\n",
    "\n",
    "    new_recommendations = []\n",
    "    for store_id in similar_user_likes['restaurant_id'].astype(str):\n",
    "      if store_id not in primary_reco_ids and store_id not in new_recommendations:\n",
    "        new_recommendations.append(store_id)\n",
    "        \n",
    "    if not new_recommendations:\n",
    "      print(\"[ìœ ì‚¬ ì¶”ì²œ] ê²¹ì¹˜ì§€ ì•ŠëŠ” ì¶”ê°€ ì¶”ì²œ ì‹ë‹¹ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "      return \"\"\n",
    "      \n",
    "    output_secondary_string = (\n",
    "      f\"\\n\\n---\\n\\n\"\n",
    "      f\"### ğŸ¤– Charlieë‹˜ê³¼ ë¹„ìŠ·í•œ ì‚¬ìš©ìê°€ ì¶”ì²œí•œ ì‹ë‹¹\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    recos_to_show = new_recommendations[:max_new_recos]\n",
    "    print(f\"[ìœ ì‚¬ ì¶”ì²œ] ì¶”ê°€í•  ì‹ë‹¹: {recos_to_show}\")\n",
    "    \n",
    "    for i, store_id in enumerate(recos_to_show):\n",
    "      output_secondary_string += format_restaurant_markdown(\n",
    "        store_id, \n",
    "        rank_prefix=\"ìœ ì‚¬ ì¶”ì²œ\", \n",
    "        rank_index=i+1\n",
    "      )\n",
    "      \n",
    "    return output_secondary_string\n",
    "    \n",
    "  except Exception as e:\n",
    "    print(f\"[ì˜¤ë¥˜] ìœ ì‚¬ ì‚¬ìš©ì ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def run_hybrid_search_with_scoring(user_profile_row, n_results=5):\n",
    "  \"\"\"\n",
    "  RAG + ì ìˆ˜ì œ ê²€ìƒ‰ í›„ ìƒìœ„ n_resultsê°œ ì¶”ì²œ\n",
    "  \"\"\"\n",
    "  print(\"\\n--- 3ë‹¨ê³„: RAG + ì ìˆ˜ì œ(Scoring) ê²€ìƒ‰ ì‹œì‘ ---\")\n",
    "  \n",
    "  try:\n",
    "    user_original_summary = user_profile_row['rag_query_text']\n",
    "    user_filter_dict = ast.literal_eval(user_profile_row['filter_metadata_json'])\n",
    "  except Exception as e:\n",
    "    print(f\"[ì˜¤ë¥˜] ì‚¬ìš©ì í”„ë¡œí•„ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "    return \"(ì˜¤ë¥˜: ì‚¬ìš©ì í”„ë¡œí•„ íŒŒì‹± ì‹¤íŒ¨)\"\n",
    "\n",
    "  user_rag_query = generate_rag_query(user_original_summary)\n",
    "  db_pre_filter = build_filters_from_profile(user_filter_dict)\n",
    "  python_post_filter = {key: val.split(',') for key, val in user_filter_dict.items() \n",
    "                        if key in ['main_ingredients_list', 'suitable_for'] and val != 'N/A' and val}\n",
    "  \n",
    "  REQUEST_N_RESULTS = 50\n",
    "\n",
    "  print(f\"í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì: {user_profile_row['name']} ({user_profile_row['user_id']})\")\n",
    "  print(f\"RAG ì¿¼ë¦¬ (ì¬ì‘ì„±ë¨): '{user_rag_query}'\")\n",
    "  print(f\"DB 1ì°¨ í•„í„° (ChromaDB): {db_pre_filter}\")\n",
    "  print(f\"Python 2ì°¨ í•„í„° (ì ìˆ˜ ê³„ì‚°ìš©): {python_post_filter}\")\n",
    "\n",
    "  try:\n",
    "    print(f\"\\n--- 1ë‹¨ê³„: RAG + 1ì°¨ í•„í„° ê²€ìƒ‰ | Top {REQUEST_N_RESULTS}ê°œ ì°¾ê¸° ---\")\n",
    "    \n",
    "    if db_pre_filter: \n",
    "      results = collection.query(\n",
    "        query_texts=[user_rag_query],\n",
    "        n_results=REQUEST_N_RESULTS,\n",
    "        where=db_pre_filter\n",
    "      )\n",
    "    else: \n",
    "      results = collection.query(\n",
    "        query_texts=[user_rag_query],\n",
    "        n_results=REQUEST_N_RESULTS\n",
    "      )\n",
    "    \n",
    "    print(f\"--- 1ì°¨ ê²€ìƒ‰ ì™„ë£Œ: {len(results['ids'][0])}ê°œ í›„ë³´ ë°˜í™˜ ---\")\n",
    "    \n",
    "    if not results.get('ids', [[]])[0]:\n",
    "      print(\"  > [í•„í„° ì™„í™”] 1ì°¨ í•„í„° ê²°ê³¼ 0ê±´. RAG-Only(í•„í„° ì—†ìŒ)ë¡œ ì¬ì‹œë„...\")\n",
    "      results = collection.query(\n",
    "        query_texts=[user_rag_query],\n",
    "        n_results=REQUEST_N_RESULTS\n",
    "      )\n",
    "      print(f\"  > RAG-Only ê²€ìƒ‰ ì™„ë£Œ: {len(results['ids'][0])}ê°œ í›„ë³´ ë°˜í™˜\")\n",
    "      if not results.get('ids', [[]])[0]:\n",
    "        print(\"RAG-Only ê²€ìƒ‰ ê²°ê³¼ë„ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return \"\\n\\n(ê²€ìƒ‰ ê²°ê³¼: 1ì°¨ í•„í„° ë° RAG-Only ê²€ìƒ‰ ëª¨ë‘ 0ê±´)\"\n",
    "        \n",
    "    final_results_with_score = []\n",
    "    print(\"\\n--- 2ë‹¨ê³„: ì ìˆ˜(Scoring) ê³„ì‚° ì‹œì‘ (1ì°¨ í›„ë³´ ëŒ€ìƒ) ---\")\n",
    "    \n",
    "    for i in range(len(results['ids'][0])):\n",
    "      store_id = results['ids'][0][i]\n",
    "      rag_distance = results['distances'][0][i] \n",
    "      metadata = results['metadatas'][0][i]\n",
    "      \n",
    "      filter_score = 0\n",
    "      \n",
    "      if user_filter_dict.get('food_category') == metadata.get('high_level_category'):\n",
    "        filter_score += 3\n",
    "      if user_filter_dict.get('budget_range') == metadata.get('budget_range'):\n",
    "        filter_score += 2\n",
    "      if user_filter_dict.get('spicy_available') == metadata.get('spicy_available'):\n",
    "        filter_score += 2\n",
    "      if user_filter_dict.get('vegetarian_options') == metadata.get('vegetarian_options'):\n",
    "        filter_score += 2\n",
    "\n",
    "      if 'suitable_for' in python_post_filter:\n",
    "        if all(req in metadata.get('suitable_for', '') for req in python_post_filter['suitable_for']): \n",
    "          filter_score += 1\n",
    "      if 'main_ingredients_list' in python_post_filter:\n",
    "        if any(req in metadata.get('main_ingredients_list', '') for req in python_post_filter['main_ingredients_list']): \n",
    "          filter_score += 1\n",
    "\n",
    "      final_results_with_score.append({\n",
    "        \"id\": store_id,\n",
    "        \"rag_distance\": rag_distance, \n",
    "        \"filter_score\": filter_score, \n",
    "        \"metadata\": metadata\n",
    "      })\n",
    "    \n",
    "    final_results = sorted(\n",
    "      final_results_with_score, \n",
    "      key=lambda x: (-x['filter_score'], x['rag_distance']), \n",
    "    )[:n_results]\n",
    "    \n",
    "    print(\"\\n--- 3ë‹¨ê³„: ìµœì¢… RAG + ì ìˆ˜ì œ ë­í‚¹ ê²°ê³¼ (ê¸°ë³¸ ì¶”ì²œ) ---\")\n",
    "    if not final_results:\n",
    "      return \"\\n\\n(ê²€ìƒ‰ ê²°ê³¼: 1/2ì°¨ í•„í„°ë¥¼ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì‹ë‹¹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.)\"\n",
    "\n",
    "    output_string = \"\\n\\n---\\n\\n### ğŸ¤– Charlieë‹˜ì„ ìœ„í•œ ë§ì¶¤ ì‹ë‹¹ ì¶”ì²œ!\\n\\n\"\n",
    "    primary_reco_ids = set()\n",
    "\n",
    "    for i, item in enumerate(final_results):\n",
    "      store_id_str = item['id']\n",
    "      primary_reco_ids.add(store_id_str)\n",
    "      output_string += format_restaurant_markdown(\n",
    "        store_id_str, \n",
    "        rank_prefix=\"ì¶”ì²œ\", \n",
    "        rank_index=i+1\n",
    "      )\n",
    "      \n",
    "    try:\n",
    "      print(\"\\n--- 4ë‹¨ê³„: ìœ ì‚¬ ì‚¬ìš©ì ê¸°ë°˜ ì¶”ê°€ ì¶”ì²œ ê²€ìƒ‰ ---\")\n",
    "      secondary_reco_string = get_similar_user_recommendations(\n",
    "        user_original_summary,\n",
    "        primary_reco_ids\n",
    "      )\n",
    "      if secondary_reco_string:\n",
    "        output_string += secondary_reco_string\n",
    "    except Exception as e:\n",
    "      print(f\"[ê²½ê³ ] ìœ ì‚¬ ì‚¬ìš©ì ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"\\n[ì˜¤ë¥˜] ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    return f\"\\n\\n(ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e})\"\n",
    "  \n",
    "  return output_string\n",
    "\n",
    "# --- Top-K ë³€ê²½ ì‹œ ì¶”ì²œ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ ---\n",
    "\n",
    "def update_recommendations_with_topk(topk_value, user_profile_row_state):\n",
    "  \"\"\"\n",
    "  Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì‹œ: ê¸°ì¡´ user_profile_row_state ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ Nê°œ ë‹¤ì‹œ ì¶”ì²œ\n",
    "  \"\"\"\n",
    "  if user_profile_row_state is None:\n",
    "    return gr.update(\n",
    "      value=\"ë¨¼ì € í”„ë¡œí•„ ì„¤ë¬¸ì„ ì™„ë£Œí•˜ë©´ ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.\",\n",
    "      visible=False\n",
    "    )\n",
    "\n",
    "  k = int(topk_value) if topk_value is not None else 5\n",
    "  reco_md = run_hybrid_search_with_scoring(\n",
    "    user_profile_row_state,\n",
    "    n_results=k\n",
    "  )\n",
    "  return gr.update(value=reco_md, visible=True)\n",
    "\n",
    "# --- ë©”ì¸ ì±—ë´‡ í•¨ìˆ˜ (Top-K, user_profile_row_state ì—°ë™) ---\n",
    "\n",
    "def chat_survey(\n",
    "    message,\n",
    "    gradio_history,\n",
    "    llm_history,\n",
    "    current_profile,\n",
    "    is_completed,\n",
    "    topk_value,\n",
    "    user_profile_row_state\n",
    "  ):\n",
    "  \"\"\"\n",
    "  ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•  ë•Œë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ í•¨ìˆ˜.\n",
    "  í”„ë¡œí•„ì´ ì™„ì„±ë˜ë©´ Top-K ê°’ì— ë§ì¶° ì¶”ì²œ ì‹¤í–‰.\n",
    "  \"\"\"\n",
    "  \n",
    "  gradio_history.append({\"role\": \"user\", \"content\": message})\n",
    "  llm_history.append({\"role\": \"user\", \"content\": message})\n",
    "  \n",
    "  try:\n",
    "    bot_message, updated_profile = call_gpt4o(llm_history, current_profile)\n",
    "  except Exception as e:\n",
    "    print(f\"chat_surveyì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "    error_msg = f\"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
    "    gradio_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "    return (\n",
    "      gradio_history,\n",
    "      llm_history,\n",
    "      current_profile,\n",
    "      is_completed,\n",
    "      gr.update(),\n",
    "      user_profile_row_state\n",
    "    )\n",
    "\n",
    "  llm_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "\n",
    "  final_bot_message = bot_message\n",
    "  recommendation_string = gr.update() \n",
    "  \n",
    "  profile_is_complete = all(v is not None for v in updated_profile.values())\n",
    "  \n",
    "  if profile_is_complete and not is_completed:\n",
    "    print(\"--- í”„ë¡œí•„ ì™„ì„±! ìš”ì•½ ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤. ---\")\n",
    "    gr.Info(\"í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! AIê°€ ìš”ì•½ ë° ì‹ë‹¹ ì¶”ì²œì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    chat_message_html, raw_summary_text = generate_profile_summary(updated_profile)\n",
    "    filter_dict = create_filter_metadata(updated_profile)\n",
    "    filter_metadata_json = json.dumps(filter_dict, ensure_ascii=False)\n",
    "    \n",
    "    user_profile_row = {\n",
    "      \"name\": updated_profile.get(\"name\", \"N/A\"),\n",
    "      \"user_id\": \"live_user\",\n",
    "      \"rag_query_text\": raw_summary_text,\n",
    "      \"filter_metadata_json\": filter_metadata_json\n",
    "    }\n",
    "\n",
    "    k = int(topk_value) if topk_value is not None else 5\n",
    "\n",
    "    if 'collection' in globals() and 'df_restaurants' in globals():\n",
    "      reco_md = run_hybrid_search_with_scoring(\n",
    "        user_profile_row,\n",
    "        n_results=k\n",
    "      )\n",
    "      recommendation_string = gr.update(value=reco_md, visible=True)\n",
    "    else:\n",
    "      recommendation_string = gr.update(\n",
    "        value=\"\\n\\n[ì˜¤ë¥˜] DBê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì¶”ì²œì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "        visible=True\n",
    "      )\n",
    "    \n",
    "    user_profile_row_state = user_profile_row\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš© ë°ì´í„° ìƒì„± ì™„ë£Œ] \")\n",
    "    print(f\"\\n[1] name:\\n{user_profile_row['name']}\")\n",
    "    print(f\"\\n[3] filter_metadata_json:\\n{filter_metadata_json}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    final_bot_message = f\"{bot_message}\\n{chat_message_html}\\n\\nğŸ‘‡ ì•„ë˜ì—ì„œ ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”! ğŸ‘‡\"\n",
    "    is_completed = True \n",
    "    print(json.dumps(updated_profile, indent=2, ensure_ascii=False))\n",
    "\n",
    "  gradio_history.append({\"role\": \"assistant\", \"content\": final_bot_message})\n",
    "  \n",
    "  return (\n",
    "    gradio_history,\n",
    "    llm_history,\n",
    "    updated_profile,\n",
    "    is_completed,\n",
    "    recommendation_string,\n",
    "    user_profile_row_state\n",
    "  )\n",
    "\n",
    "# --- 8. DB ë° ë°ì´í„° ì „ì—­ ë¡œë“œ ---\n",
    "\n",
    "MOCK_USER_RATINGS_FILE = \"recommendation_results_with_ratings.csv\"\n",
    "\n",
    "try:\n",
    "  data_loaded_ok = load_app_data(RESTAURANT_DB_FILE, MENU_DB_FILE)\n",
    "  \n",
    "  ratings_loaded_ok = False\n",
    "  if data_loaded_ok:\n",
    "    try:\n",
    "      print(f\"'{MOCK_USER_RATINGS_FILE}'ì—ì„œ 500ëª… í‰ê°€ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "      global df_all_user_ratings, df_restaurant_ratings_summary\n",
    "      df_all_user_ratings = pd.read_csv(MOCK_USER_RATINGS_FILE)\n",
    "      \n",
    "      if 'restaurant_id' in df_all_user_ratings.columns:\n",
    "        df_all_user_ratings['restaurant_id'] = df_all_user_ratings['restaurant_id'].apply(str)\n",
    "      else:\n",
    "        print(\"[ê²½ê³ ] 'restaurant_id' ì»¬ëŸ¼ì´ 500ëª… í‰ê°€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        raise KeyError(\"'restaurant_id' ì»¬ëŸ¼ ëˆ„ë½\")\n",
    "      \n",
    "      if 'user_id' in df_all_user_ratings.columns:\n",
    "        df_all_user_ratings['user_id'] = df_all_user_ratings['user_id'].apply(str)\n",
    "      else:\n",
    "        print(\"[ê²½ê³ ] 'user_id' ì»¬ëŸ¼ì´ 500ëª… í‰ê°€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        raise KeyError(\"'user_id' ì»¬ëŸ¼ ëˆ„ë½\")\n",
    "\n",
    "      print(\"  > ì‹ë‹¹(restaurant_id)ë³„ 'ì¶”ì²œ', 'ë¯¸ì¶”ì²œ' ì¹´ìš´íŠ¸ ì§‘ê³„ ì¤‘...\")\n",
    "      \n",
    "      valid_ratings = df_all_user_ratings[\n",
    "        df_all_user_ratings['ì‚¬ìš©ìí‰ê°€'].isin(['ì¶”ì²œ', 'ë¯¸ì¶”ì²œ'])\n",
    "      ]\n",
    "      \n",
    "      ratings_crosstab = pd.crosstab(\n",
    "        valid_ratings['restaurant_id'], \n",
    "        valid_ratings['ì‚¬ìš©ìí‰ê°€']\n",
    "      )\n",
    "      \n",
    "      if 'ì¶”ì²œ' not in ratings_crosstab.columns:\n",
    "        ratings_crosstab['ì¶”ì²œ'] = 0\n",
    "      if 'ë¯¸ì¶”ì²œ' not in ratings_crosstab.columns:\n",
    "        ratings_crosstab['ë¯¸ì¶”ì²œ'] = 0\n",
    "        \n",
    "      df_restaurant_ratings_summary = ratings_crosstab[['ì¶”ì²œ', 'ë¯¸ì¶”ì²œ']].reset_index()\n",
    "      \n",
    "      print(f\"  > 500ëª… í‰ê°€ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: {len(df_restaurant_ratings_summary)}ê°œ ì‹ë‹¹\")\n",
    "      ratings_loaded_ok = True\n",
    "      \n",
    "    except FileNotFoundError:\n",
    "      print(f\"[ê²½ê³ ] {MOCK_USER_RATINGS_FILE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í‰ê°€ ì¹´ìš´íŠ¸ ê¸°ëŠ¥ ë¹„í™œì„±í™”)\")\n",
    "      ratings_loaded_ok = True \n",
    "    except Exception as e:\n",
    "      print(f\"[ê²½ê³ ] 500ëª… í‰ê°€ ë°ì´í„° ë¡œë“œ/ì§‘ê³„ ì¤‘ ì˜¤ë¥˜: {e} (í‰ê°€ ì¹´ìš´íŠ¸ ê¸°ëŠ¥ ë¹„í™œì„±í™”)\")\n",
    "      ratings_loaded_ok = True\n",
    "\n",
    "  db_load_ok = build_vector_db(\n",
    "    RESTAURANT_DB_FILE,\n",
    "    PROFILE_DB_FILE,\n",
    "    clear_db=CLEAR_DB_AND_REBUILD\n",
    "  )\n",
    "  \n",
    "  if not data_loaded_ok or not db_load_ok:\n",
    "     print(\"[ì¹˜ëª…ì  ì˜¤ë¥˜] DB ë˜ëŠ” ê°€ê²Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. Gradioë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "     exit() \n",
    "    \n",
    "except Exception as e:\n",
    "  print(f\"[ì¹˜ëª…ì  ì˜¤ë¥˜] DB ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}\")\n",
    "  exit()\n",
    "\n",
    "# --- 9. Gradio UI ì¸í„°í˜ì´ìŠ¤ ë¹Œë“œ ---\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "  gr.Markdown(\"#ê¸¸ë”°ë¼ ë§›ë”°ë¼\")\n",
    "  gr.Markdown(\"AIê°€ 13ê°€ì§€ í”„ë¡œí•„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì™„ë£Œë˜ë©´ ë§ì¶¤ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤.\")\n",
    "\n",
    "  # ì–¸ì–´ ì„¤ì • ì˜ì—­ (ì•„ì§ ê¸°ëŠ¥ë§Œ í‹€)\n",
    "  with gr.Group():\n",
    "    gr.Markdown(\"### ğŸŒ ì–¸ì–´ ì„¤ì •\")\n",
    "    with gr.Row():\n",
    "      lang_radio = gr.Radio(\n",
    "        [\"í•œêµ­ì–´ KR\", \"English US\", \"æ—¥æœ¬èª JP\", \"ä¸­æ–‡ CN\"],\n",
    "        label=\"ì‚¬ìš© ì–¸ì–´ ì„ íƒ\",\n",
    "        value=\"í•œêµ­ì–´ KR\",\n",
    "        interactive=True\n",
    "      )\n",
    "\n",
    "  # ìƒíƒœ(State) ë³€ìˆ˜ë“¤\n",
    "  llm_history_state = gr.State(value=[])\n",
    "  profile_state = gr.State(value=PROFILE_TEMPLATE.copy())\n",
    "  is_completed_state = gr.State(value=False)\n",
    "  user_profile_row_state = gr.State(value=None)\n",
    "\n",
    "  with gr.Tabs():\n",
    "    # [íƒ­ 1] ìŒì‹ íƒìƒ‰\n",
    "    with gr.TabItem(\"ğŸ½ ìŒì‹ íƒìƒ‰\"):\n",
    "      with gr.Column():\n",
    "        chatbot = gr.Chatbot(\n",
    "          label=\"ì„œë² ì´ ì±—ë´‡\",\n",
    "          height=700,\n",
    "          show_copy_button=True,\n",
    "          type=\"messages\",\n",
    "        )\n",
    "\n",
    "        msg_textbox = gr.Textbox(\n",
    "          label=\"ë‹µë³€ ì…ë ¥\",\n",
    "          placeholder=\"ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...\",\n",
    "        )\n",
    "\n",
    "        # ì±—ë´‡ ì•„ë˜ì— ë§ì¶¤ ì¶”ì²œ ê²°ê³¼ íƒ­\n",
    "        with gr.Tabs():\n",
    "          with gr.TabItem(\"ğŸŒŸ ë§ì¶¤ ì¶”ì²œ ê²°ê³¼\"):\n",
    "            topk_slider = gr.Slider(\n",
    "              minimum=1,\n",
    "              maximum=30,\n",
    "              value=5,\n",
    "              step=1,\n",
    "              label=\"í‘œì‹œ ê°œìˆ˜ (Top-K)\",\n",
    "            )\n",
    "            recommendation_output = gr.Markdown(\n",
    "              label=\"ì¶”ì²œ ê²°ê³¼\",\n",
    "              value=\"...í”„ë¡œí•„ ì„¤ë¬¸ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤...\",\n",
    "              visible=False,\n",
    "            )\n",
    "\n",
    "    # [íƒ­ 2] ì„¤ì •\n",
    "    with gr.TabItem(\"âš™ï¸ ì„¤ì •\"):\n",
    "      with gr.Column():\n",
    "        gr.Markdown(\"### âš™ï¸ ì•± ì„¤ì • (ì˜ˆì‹œ)\")\n",
    "        gr.Markdown(\n",
    "          \"- ì´ íƒ­ì—ëŠ” ë‚˜ì¤‘ì— ë²¡í„° DB ë¦¬ì…‹, ë””ë²„ê·¸ ì˜µì…˜, ëª¨ë¸ ì„ íƒ ë“±ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\"\n",
    "          \"- í˜„ì¬ëŠ” UI í‹€ë§Œ ë§Œë“¤ì–´ ë‘” ìƒíƒœì…ë‹ˆë‹¤.\"\n",
    "        )\n",
    "        rebuild_btn = gr.Button(\"ğŸ” ë²¡í„° DB ë‹¤ì‹œ ë¹Œë“œ (ì˜ˆì‹œ)\")\n",
    "        debug_checkbox = gr.Checkbox(label=\"ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (ì˜ˆì‹œ)\", value=False)\n",
    "\n",
    "  # ì´ˆê¸° ë¡œë“œ\n",
    "  demo.load(\n",
    "    fn=start_chat,\n",
    "    inputs=None,\n",
    "    outputs=[chatbot, llm_history_state, profile_state, is_completed_state, user_profile_row_state],\n",
    "  )\n",
    "\n",
    "  # ë©”ì‹œì§€ ì „ì†¡\n",
    "  msg_textbox.submit(\n",
    "    fn=chat_survey,\n",
    "    inputs=[\n",
    "      msg_textbox,\n",
    "      chatbot,\n",
    "      llm_history_state,\n",
    "      profile_state,\n",
    "      is_completed_state,\n",
    "      topk_slider,\n",
    "      user_profile_row_state,\n",
    "    ],\n",
    "    outputs=[\n",
    "      chatbot,\n",
    "      llm_history_state,\n",
    "      profile_state,\n",
    "      is_completed_state,\n",
    "      recommendation_output,\n",
    "      user_profile_row_state,\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  # Enter í›„ ì…ë ¥ì°½ ë¹„ìš°ê¸°\n",
    "  msg_textbox.submit(lambda: \"\", inputs=None, outputs=msg_textbox)\n",
    "\n",
    "  # Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì‹œ ì¶”ì²œ ì¬ê³„ì‚°\n",
    "  topk_slider.change(\n",
    "    fn=update_recommendations_with_topk,\n",
    "    inputs=[topk_slider, user_profile_row_state],\n",
    "    outputs=recommendation_output,\n",
    "  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- í”„ë¡œí•„ ì™„ì„±! ìš”ì•½ ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤. ---\n",
      "\n",
      "--- 3ë‹¨ê³„: RAG + ì ìˆ˜ì œ(Scoring) ê²€ìƒ‰ ì‹œì‘ ---\n",
      "  > [RAG] LLMì„ í˜¸ì¶œí•˜ì—¬ 'ë¶„ìœ„ê¸°/ì„±í–¥' ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì: Chloe (live_user)\n",
      "RAG ì¿¼ë¦¬ (ì¬ì‘ì„±ë¨): 'ì—°ì¸ê³¼ í•¨ê»˜ í¸ì•ˆí•˜ê³  ë¹ ë¥´ê²Œ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ìŒì‹ê³¼ í•´ì‚°ë¬¼ ì¤‘ì‹¬ì˜ ë¶„ìœ„ê¸°'\n",
      "DB 1ì°¨ í•„í„° (ChromaDB): {'$and': [{'budget_range': 'ì¤‘'}, {'spicy_available': 'O'}, {'vegetarian_options': 'X'}, {'high_level_category': 'ìƒê´€ì—†ìŒ'}]}\n",
      "Python 2ì°¨ í•„í„° (ì ìˆ˜ ê³„ì‚°ìš©): {'main_ingredients_list': ['í•´ì‚°ë¬¼'], 'suitable_for': ['ì—°ì¸']}\n",
      "\n",
      "--- 1ë‹¨ê³„: RAG + 1ì°¨ í•„í„° ê²€ìƒ‰ | Top 50ê°œ ì°¾ê¸° ---\n",
      "--- 1ì°¨ ê²€ìƒ‰ ì™„ë£Œ: 0ê°œ í›„ë³´ ë°˜í™˜ ---\n",
      "  > [í•„í„° ì™„í™”] 1ì°¨ í•„í„° ê²°ê³¼ 0ê±´. RAG-Only(í•„í„° ì—†ìŒ)ë¡œ ì¬ì‹œë„...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > RAG-Only ê²€ìƒ‰ ì™„ë£Œ: 50ê°œ í›„ë³´ ë°˜í™˜\n",
      "\n",
      "--- 2ë‹¨ê³„: ì ìˆ˜(Scoring) ê³„ì‚° ì‹œì‘ (1ì°¨ í›„ë³´ ëŒ€ìƒ) ---\n",
      "\n",
      "--- 3ë‹¨ê³„: ìµœì¢… RAG + ì ìˆ˜ì œ ë­í‚¹ ê²°ê³¼ (ê¸°ë³¸ ì¶”ì²œ) ---\n",
      "\n",
      "--- 4ë‹¨ê³„: ìœ ì‚¬ ì‚¬ìš©ì ê¸°ë°˜ ì¶”ê°€ ì¶”ì²œ ê²€ìƒ‰ ---\n",
      "[ìœ ì‚¬ ì¶”ì²œ] ì°¾ì€ ìœ ì‚¬ ì‚¬ìš©ì: ['user_0288']\n",
      "[ìœ ì‚¬ ì¶”ì²œ] ì¶”ê°€í•  ì‹ë‹¹: ['21046', '31371']\n",
      "\n",
      "======================================================================\n",
      " [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš© ë°ì´í„° ìƒì„± ì™„ë£Œ] \n",
      "\n",
      "[1] name:\n",
      "Chloe\n",
      "\n",
      "[3] filter_metadata_json:\n",
      "{\"budget_range\": \"ì¤‘\", \"spicy_available\": \"O\", \"vegetarian_options\": \"X\", \"main_ingredients_list\": \"í•´ì‚°ë¬¼\", \"suitable_for\": \"ì—°ì¸\", \"food_category\": \"ìƒê´€ì—†ìŒ\"}\n",
      "======================================================================\n",
      "\n",
      "{\n",
      "  \"name\": \"Chloe\",\n",
      "  \"age\": \"20ëŒ€\",\n",
      "  \"gender\": \"ì—¬\",\n",
      "  \"nationality\": \"í”„ë‘ìŠ¤\",\n",
      "  \"travel_type\": \"ì—°ì¸\",\n",
      "  \"party_size\": 2,\n",
      "  \"can_wait\": \"X\",\n",
      "  \"budget\": \"ì¤‘\",\n",
      "  \"spicy_ok\": \"O\",\n",
      "  \"is_vegetarian\": \"X\",\n",
      "  \"avoid_ingredients\": \"ì—†ìŒ\",\n",
      "  \"like_ingredients\": \"í•´ì‚°ë¬¼\",\n",
      "  \"food_category\": \"ìƒê´€ì—†ìŒ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- 10. ì•± ì‹¤í–‰ ---\n",
    "if __name__ == \"__main__\":\n",
    "  if 'collection' not in globals() or 'df_restaurants' not in globals() or 'df_menus' not in globals():\n",
    "     print(\"[ì¢…ë£Œ] DBê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "  else:\n",
    "     print(\"Gradio ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "     demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7863\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
