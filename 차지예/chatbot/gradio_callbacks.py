
import gradio as gr
import json
import pandas as pd
import httpx
from typing import Dict, Any, List, Tuple

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
import config
import llm_utils
import search_logic
import data_loader
from API import final_scorer
from API.final_scorer import GraphHopperDownError

# ğŸ”¹ ë²ˆì—­ / i18n ëª¨ë“ˆ
import translator
from i18n_texts import t


# =========================
# ê³µí†µ í—¬í¼
# =========================

CARD_SEPARATOR = "\n---\n\n"  # ì¹´ë“œ êµ¬ë¶„ìš© ì„¸í¼ë ˆì´í„°


def _build_reco_md_from_df(df: pd.DataFrame, top_k: int = 5, prefix: str = "ìµœì¢… ì¶”ì²œ") -> str:
    """final_scorer ê²°ê³¼ DataFrame -> ì¹´ë“œí˜• markdownìœ¼ë¡œ ë³€í™˜"""
    blocks: List[str] = []
    if "id" in df.columns:
        df = df.set_index("id")
    for i, (store_id, row) in enumerate(df.head(top_k).iterrows(), start=1):
        block = search_logic.format_restaurant_markdown(
            store_id_str=str(store_id),
            rank_prefix=prefix,
            rank_index=i,
        )
        blocks.append(block.strip())
    return CARD_SEPARATOR.join(blocks)


def _build_reco_md_from_ids(store_ids, top_k: int = 5, prefix: str = "RAG ì¶”ì²œ") -> str:
    """1ë‹¨ê³„ RAGë¡œ ë½‘ì€ ì‹ë‹¹ id ë¦¬ìŠ¤íŠ¸ -> ì¹´ë“œí˜• markdownìœ¼ë¡œ ë³€í™˜"""
    blocks = []
    for i, store_id in enumerate(list(store_ids)[:top_k], start=1):
        block = search_logic.format_restaurant_markdown(
            store_id_str=str(store_id),
            rank_prefix=prefix,
            rank_index=i,
        )
        blocks.append(block.strip())
    return CARD_SEPARATOR.join(blocks)


def budget_mapper(budget_str: str) -> List[str]:
    """'ì €', 'ì¤‘', 'ê³ 'ë¥¼ ìµœì¢… ìŠ¤ì½”ì–´ëŸ¬ê°€ ì•Œì•„ë“£ëŠ” ê°€ê²©ëŒ€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if budget_str == "ì €":
        return ["$", "$$"]
    elif budget_str == "ì¤‘":
        return ["$$", "$$$"]
    elif budget_str == "ê³ ":
        return ["$$$", "$$$$"]
    else:
        return ["$", "$$", "$$$", "$$$$"]


LOCATION_COORDS = {  # ì¢Œí‘œ ë³€í™˜ í—¬í¼ (ë°ëª¨ìš©)
    "ëª…ë™ì—­": "37.5630,126.9830",
    "í™ëŒ€ì…êµ¬ì—­": "37.5570,126.9244",
    "ê°•ë‚¨ì—­": "37.4980,127.0276",
    "ì„œìš¸ì—­": "37.5547,126.9704",
    "ì„œìš¸ì‹œì²­": "37.5665, 126.9780",
    "ì‹œì²­ì—­": "37.5658,126.9772",
}


def get_start_location_coords(location_name: str) -> str:
    return LOCATION_COORDS.get(location_name, "37.5630,126.9830")


# =========================
# Gradio ì½œë°±
# =========================

def start_chat(selected_lang: str = "ko") -> Tuple[List[Dict], List[Dict], Dict, bool, Dict, gr.update]:
    """
    ì±„íŒ…ë°©ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ ì‹¤í–‰.
    - GPTì—ê²Œ ì²« ì§ˆë¬¸ì„ ì‹œí‚¤ì§€ ì•Šê³ , i18n ê³ ì • ë¬¸êµ¬(first_question) ì‚¬ìš©
    - í™”ë©´ì—ëŠ” selected_langìœ¼ë¡œ, LLM ë‚´ë¶€ëŠ” koë¡œ ì €ì¥
    """
    user_lang = selected_lang or "ko"

    try:
        initial_profile = config.PROFILE_TEMPLATE.copy()

        # 1) ì²« ì§ˆë¬¸(í•œêµ­ì–´ ê³ ì •) - i18n ì‚¬ì „ ì‚¬ìš©
        first_msg_ko = t("first_question", "ko")

        # 2) í™”ë©´ì—” ì„ íƒ ì–¸ì–´ë¡œ
        first_msg_display = t("first_question", user_lang)

        # 3) UI íˆìŠ¤í† ë¦¬(ì‚¬ìš©ì ì–¸ì–´) / LLM íˆìŠ¤í† ë¦¬(í•œêµ­ì–´)
        gradio_history = [{"role": "assistant", "content": first_msg_display}]
        llm_history = [{"role": "assistant", "content": first_msg_ko}]

        # 4) ì¶”ì²œ ì˜ì—­ placeholderë„ ì–¸ì–´ë³„
        initial_user_profile_row: Dict[str, Any] = {}
        initial_reco_state = gr.update(
            value=t("initial_reco_placeholder", user_lang),
            visible=False,
        )

        return (
            gradio_history,
            llm_history,
            initial_profile,
            False,
            initial_user_profile_row,
            initial_reco_state,
        )

    except Exception as e:
        print(f"start_chatì—ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        error_msg = f"ì±—ë´‡ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (í™˜ê²½ ì„¤ì • ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤): {e}"

        initial_user_profile_row = {}
        error_reco_state = gr.update(value="ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨...", visible=True)

        return (
            [{"role": "assistant", "content": error_msg}],
            [],
            config.PROFILE_TEMPLATE.copy(),
            False,
            initial_user_profile_row,
            error_reco_state,
        )


async def _run_recommendation_flow(
    profile_data: dict,
    http_client: httpx.AsyncClient,
    graphhopper_url: str,
    top_k: int,
    user_lang: str = "ko",
) -> Tuple[gr.update, Dict]:
    """
    1ë‹¨ê³„ RAG -> 2ë‹¨ê³„ final_scorer ì‹¤í–‰ (Fallback í¬í•¨)
    ê²°ê³¼ ë§ˆí¬ë‹¤ìš´ì€ ë§ˆì§€ë§‰ì— user_langì— ë§ê²Œ ë²ˆì—­í•œë‹¤.
    """
    final_user_profile_row: Dict[str, Any] = {}

    try:
        # --- 1ë‹¨ê³„: RAG + í•„í„° ë©”íƒ€ë°ì´í„° ìƒì„± ---
        profile_summary = llm_utils.generate_profile_summary_text_only(profile_data)

        filter_dict = search_logic.create_filter_metadata(profile_data)
        filter_metadata_json = json.dumps(filter_dict, ensure_ascii=False)

        user_profile_row = {
            "name": profile_data.get("name", "N/A"),
            "user_id": "live_user",
            "rag_query_text": profile_summary,
            "filter_metadata_json": filter_metadata_json,
            "final_candidate_ids": [],
            "final_scored_df": None,
        }

        candidate_ids = search_logic.get_rag_candidate_ids(
            user_profile_row, n_results=config.RAG_REQUEST_N_RESULTS
        )

        if not candidate_ids:
            warn_ko = "1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”."
            warn = translator.translate_text(warn_ko, "ko", user_lang) if user_lang != "ko" else warn_ko
            gr.Warning(warn)
            return (
                gr.update(value=warn, visible=True),
                final_user_profile_row,
            )

        user_profile_row["final_candidate_ids"] = candidate_ids

        # --- 2ë‹¨ê³„: final_scorer ì‹œë„ ---
        try:
            candidate_df = data_loader.get_restaurants_by_ids(candidate_ids)
            if candidate_df.empty:
                raise Exception("1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")

            user_start_coords = get_start_location_coords(
                profile_data.get("start_location")
            )
            user_price_prefs = budget_mapper(profile_data.get("budget"))

            final_scored_df = await final_scorer.calculate_final_scores_async(
                candidate_df=candidate_df,
                user_start_location=user_start_coords,
                user_price_prefs=user_price_prefs,
                async_http_client=http_client,
                graphhopper_url=graphhopper_url,
            )

            user_profile_row["final_scored_df"] = final_scored_df.reset_index().to_dict("records")
            output_md_ko = _build_reco_md_from_df(final_scored_df, top_k=top_k, prefix="ìµœì¢… ì¶”ì²œ")

        except GraphHopperDownError as e:
            warn_ko = "âš ï¸ ëšœë²…ì´ ì ìˆ˜ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
            warn = translator.translate_text(warn_ko, "ko", user_lang) if user_lang != "ko" else warn_ko
            gr.Warning(warn)
            output_md_ko = _build_reco_md_from_ids(candidate_ids, top_k=top_k, prefix="RAG ì¶”ì²œ")

        final_user_profile_row = user_profile_row

        output_md = translator.translate_text(output_md_ko, "ko", user_lang) if user_lang != "ko" else output_md_ko
        return gr.update(value=output_md, visible=True), final_user_profile_row

    except Exception as e:
        err_ko = f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì„¸ë¶€ì •ë³´: {e})"
        err = translator.translate_text(err_ko, "ko", user_lang) if user_lang != "ko" else err_ko
        gr.Error(err)
        return (gr.update(value=err, visible=True), final_user_profile_row)


async def chat_survey(
    message: str,
    gradio_history: List[Dict],
    llm_history: List[Dict],
    current_profile: Dict,
    is_completed: bool,
    topk_value: int,
    user_profile_row_state: Dict,
    http_client: httpx.AsyncClient,
    graphhopper_url: str,
    selected_lang: str,
) -> Tuple[List[Dict], List[Dict], Dict, bool, gr.update, Dict]:
    """
    ì‚¬ìš©ì ì…ë ¥ë§ˆë‹¤ í˜¸ì¶œ.
    - GPTëŠ” í•œêµ­ì–´ë¡œë§Œ ëŒ€í™”
    - í™”ë©´ì—ëŠ” ì„ íƒ ì–¸ì–´ë¡œ ë²ˆì—­ëœ ë‹µë³€ í‘œì‹œ
    """
    user_lang = selected_lang or "ko"

    # 1) UI ê¸°ë¡: ì‚¬ìš©ì ì›ë¬¸ ê·¸ëŒ€ë¡œ
    gradio_history.append({"role": "user", "content": message})

    # 2) GPT ê¸°ë¡: í•œêµ­ì–´ ë²„ì „ìœ¼ë¡œ
    internal_user_text = message if user_lang == "ko" else translator.translate_text(message, user_lang, "ko")
    llm_history.append({"role": "user", "content": internal_user_text})

    # 3) GPT í˜¸ì¶œ
    try:
        bot_internal_message, updated_profile = llm_utils.call_gpt4o(
            llm_history,
            current_profile,
        )
    except Exception as e:
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        gradio_history.append({"role": "assistant", "content": error_msg})
        return (
            gradio_history,
            llm_history,
            current_profile,
            is_completed,
            gr.update(),
            user_profile_row_state,
        )

    # 4) ì‚¬ìš©ì ì–¸ì–´ë¡œ ë²ˆì—­
    bot_message_for_user = bot_internal_message if user_lang == "ko" else translator.translate_text(
        bot_internal_message, "ko", user_lang
    )

    # LLM íˆìŠ¤í† ë¦¬(í•œêµ­ì–´) ì—…ë°ì´íŠ¸
    llm_history.append({"role": "assistant", "content": bot_internal_message})

    # 5) í”„ë¡œí•„ ì™„ì„± ì—¬ë¶€
    profile_is_complete = all(v is not None for v in updated_profile.values())

    final_bot_message_for_user = bot_message_for_user
    recommendation_output = gr.update()
    new_user_profile_row_state = user_profile_row_state

    # 6) í”„ë¡œí•„ì´ ì™„ì„±ë˜ë©´ ì¶”ì²œ ì‹¤í–‰
    if profile_is_complete and not is_completed:
        profile_html = llm_utils.generate_profile_summary_html(updated_profile)

        recommendation_output, new_user_profile_row_state = await _run_recommendation_flow(
            updated_profile,
            http_client,
            graphhopper_url,
            top_k=topk_value,
            user_lang=user_lang,
        )

        suffix = t("profile_complete_suffix", user_lang)
        final_bot_message_for_user = f"{bot_message_for_user}\n{profile_html}{suffix}"
        is_completed = True

    # 7) UIì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ê¸°ë¡
    gradio_history.append({"role": "assistant", "content": final_bot_message_for_user})

    return (
        gradio_history,
        llm_history,
        updated_profile,
        is_completed,
        recommendation_output,
        new_user_profile_row_state,
    )


def update_recommendations_with_topk(
    topk_value: int,
    user_profile_row_state: Dict,
    user_lang: str = "ko",
):
    """
    Top-K ë³€ê²½ ë•Œ stateë§Œìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ì¬ìƒì„±.
    ìµœì¢… ì¶œë ¥ì€ user_langì— ë§ê²Œ ë²ˆì—­.
    """
    if not user_profile_row_state:
        msg_ko = "...í”„ë¡œí•„ì„ ë¨¼ì € ì™„ì„±í•´ì£¼ì„¸ìš”..."
        msg = translator.translate_text(msg_ko, "ko", user_lang) if user_lang != "ko" else msg_ko
        return gr.update(value=msg, visible=True)

    try:
        if user_profile_row_state.get("final_scored_df"):
            df = pd.DataFrame(user_profile_row_state["final_scored_df"])
            md_ko = _build_reco_md_from_df(df, top_k=topk_value, prefix="ìµœì¢… ì¶”ì²œ")
        elif user_profile_row_state.get("final_candidate_ids"):
            ids = user_profile_row_state["final_candidate_ids"]
            md_ko = _build_reco_md_from_ids(ids, top_k=topk_value, prefix="RAG ì¶”ì²œ")
        else:
            md_ko = "ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (State ë¹„ì–´ìˆìŒ)"

        md = translator.translate_text(md_ko, "ko", user_lang) if user_lang != "ko" else md_ko
        return gr.update(value=md, visible=True)

    except Exception as e:
        err_ko = f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}"
        err = translator.translate_text(err_ko, "ko", user_lang) if user_lang != "ko" else err_ko
        return gr.update(value=err, visible=True)
