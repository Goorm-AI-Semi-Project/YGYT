import gradio as gr
import json
import pandas as pd
import httpx
from typing import Dict, Any, List, Tuple

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
import config
import llm_utils
import search_logic
import data_loader
# (final_scorerì—ì„œ GraphHopperDownErrorë„ ì„í¬íŠ¸)
from API import final_scorer
from API.final_scorer import GraphHopperDownError

# --- í—¬í¼ ---

def budget_mapper(budget_str: str) -> List[str]:
    """'ì €', 'ì¤‘', 'ê³ 'ë¥¼ 'final_scorer'ê°€ ì•Œì•„ë“£ëŠ” ['$', '$$']ë¡œ ë³€í™˜"""
    if budget_str == 'ì €':
        return ['$', '$$']
    elif budget_str == 'ì¤‘':
        return ['$$', '$$$']
    elif budget_str == 'ê³ ':
        return ['$$$', '$$$$']
    else:
        return ['$', '$$', '$$$', '$$$$'] # (N/Aì˜ ê²½ìš° ì „ì²´)

# (ì¢Œí‘œ ë³€í™˜ í—¬í¼)
# (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì´ ë¶€ë¶„ì„ DBë‚˜ APIë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤)
LOCATION_COORDS = {
    "ëª…ë™ì—­": "37.5630,126.9830",
    "í™ëŒ€ì…êµ¬ì—­": "37.5570,126.9244",
    "ê°•ë‚¨ì—­": "37.4980,127.0276",
    "ì„œìš¸ì—­": "37.5547,126.9704",
    "ì„œìš¸ì‹œì²­": "37.5665, 126.9780", # (Chloe í”„ë¡œí•„ ëŒ€ì‘)
    "ì‹œì²­ì—­": "37.5658,126.9772",
}

def get_start_location_coords(location_name: str) -> str:
    """ê°„ë‹¨í•œ ì¥ì†Œ ì´ë¦„ì„ ì¢Œí‘œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    # (ì¼ì¹˜í•˜ëŠ” ì—­ ì´ë¦„ì´ ì—†ìœ¼ë©´ 'ëª…ë™ì—­' ì¢Œí‘œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©)
    return LOCATION_COORDS.get(location_name, "37.5630,126.9830") 

# --- Gradio ì½œë°± ---

def start_chat() -> Tuple[List[Dict], List[Dict], Dict, bool, Dict, gr.update]: 
    """
    (ìˆ˜ì •ë¨: 6ê°œ ë°˜í™˜)
    ì±„íŒ…ë°©ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ ì‹¤í–‰.
    (ValueError: 6 needed, 5 returned ì˜¤ë¥˜ í•´ê²°)
    """
    try:
        initial_profile = config.PROFILE_TEMPLATE.copy()
        
        bot_message, updated_profile = llm_utils.call_gpt4o(
            chat_messages=[], 
            current_profile=initial_profile
        )
        
        gradio_history = [{"role": "assistant", "content": bot_message}]
        llm_history = [{"role": "assistant", "content": bot_message}]
        
        # (5ë²ˆì§¸: user_profile_row_state ì´ˆê¸°ê°’)
        initial_user_profile_row = {} # (None ëŒ€ì‹  ë¹ˆ ë”•ì…”ë„ˆë¦¬)
        
        # (6ë²ˆì§¸: recommendation_output ì´ˆê¸°ê°’)
        initial_reco_state = gr.update(
            value="...í”„ë¡œí•„ ì„¤ë¬¸ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤...",
            visible=False 
        )
        
        return gradio_history, llm_history, updated_profile, False, initial_user_profile_row, initial_reco_state 

    except Exception as e:
        print(f"start_chatì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = f"ì±—ë´‡ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤): {e}"
        
        initial_user_profile_row = {}
        error_reco_state = gr.update(
            value="ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨...", 
            visible=True
        )
        
        return [{"role": "assistant", "content": error_msg}], [], config.PROFILE_TEMPLATE.copy(), False, initial_user_profile_row, error_reco_state 

async def _run_recommendation_flow(
    profile_data: dict, 
    http_client: httpx.AsyncClient, 
    graphhopper_url: str,
    top_k: int # (â˜… topk_valueë¥¼ top_kë¡œ ë°›ìŒ)
) -> Tuple[gr.update, Dict]:
    """ 
    (ì‹ ê·œ í—¬í¼ í•¨ìˆ˜)
    1ë‹¨ê³„ RAG -> 2ë‹¨ê³„ final_scorer ì‹¤í–‰ (Fallback í¬í•¨) 
    (user_profile_rowë„ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •)
    """
    
    final_user_profile_row = {}
    
    try:
        # --- 1ë‹¨ê³„: RAG + ì ìˆ˜ì œ í›„ë³´êµ° ìƒì„± ---
        print("--- 1ë‹¨ê³„: RAG + ì ìˆ˜ì œ í›„ë³´êµ° ìƒì„± ì‹œì‘ ---")
        gr.Info("--- 1ë‹¨ê³„: 1ì°¨ RAG í›„ë³´êµ° ìƒì„± ì¤‘... ---")
        
        profile_summary = llm_utils.generate_profile_summary_text_only(profile_data)
        
        # (AttributeError: 'llm_utils' has no 'create_filter_metadata' í•´ê²°)
        filter_dict = search_logic.create_filter_metadata(profile_data)
        filter_metadata_json = json.dumps(filter_dict, ensure_ascii=False)
        
        user_profile_row = {
            "name": profile_data.get("name", "N/A"),
            "user_id": "live_user",
            "rag_query_text": profile_summary,
            "filter_metadata_json": filter_metadata_json,
            "final_candidate_ids": [],
            "final_scored_df": None,
        }
        
        candidate_ids = search_logic.get_rag_candidate_ids(
            user_profile_row,
            n_results=config.RAG_REQUEST_N_RESULTS
        )
        
        if not candidate_ids:
            print("[ì˜¤ë¥˜] 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼, í›„ë³´êµ° 0ê°œ.")
            gr.Warning("1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”.")
            return gr.update(value="1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”."), final_user_profile_row

        print(f"--- 1ë‹¨ê³„ RAG ì™„ë£Œ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
        user_profile_row["final_candidate_ids"] = candidate_ids 

        # --- [ 2ë‹¨ê³„ Fallback ë¡œì§ ì‹œì‘ ] ---
        try:
            # --- 2ë‹¨ê³„ (A): final_scorer (ëšœë²…ì´ ì ìˆ˜) ì‹¤í–‰ ---
            print(f"--- 2ë‹¨ê³„: final_scorer ì‹¤í–‰ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
            gr.Info(f"--- 2ë‹¨ê³„: {len(candidate_ids)}ê°œ í›„ë³´ 'ëšœë²…ì´ ì ìˆ˜' ê³„ì‚° ì¤‘... (API í˜¸ì¶œ) ---")
            
            candidate_df = data_loader.get_restaurants_by_ids(candidate_ids)
            
            if candidate_df.empty:
                 print("[ì˜¤ë¥˜] 1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")
                 raise Exception("1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")

            user_start_coords = get_start_location_coords(profile_data.get('start_location'))
            user_price_prefs = budget_mapper(profile_data.get('budget'))
            
            final_scored_df = await final_scorer.calculate_final_scores_async(
                candidate_df=candidate_df,
                user_start_location=user_start_coords,
                user_price_prefs=user_price_prefs,
                async_http_client=http_client,
                graphhopper_url=graphhopper_url
            )
            
            # (DataFrameì€ JSON ì§ë ¬í™” ë¶ˆê°€ -> to_dict)
            user_profile_row["final_scored_df"] = final_scored_df.to_dict('records')
            
            print("--- 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ í¬ë§·íŒ… (2ë‹¨ê³„ ê¸°ì¤€) ---")
            gr.Info("--- 3ë‹¨ê³„: 'ëšœë²…ì´ ì ìˆ˜' í¬í•¨ ìµœì¢… ì¶”ì²œ ìƒì„± ì¤‘... ---")
            
            top_k_df = final_scored_df.head(top_k) # (â˜… top_k ì‚¬ìš©)
            output_md = "### ğŸ¤– 'ëšœë²…ì´ ì ìˆ˜' í¬í•¨ ìµœì¢… ì¶”ì²œ!\n\n"
            
            for i, (store_id, row) in enumerate(top_k_df.iterrows()):
                output_md += search_logic.format_restaurant_markdown(
                    store_id_str=store_id, 
                    rank_prefix="ìµœì¢… ì¶”ì²œ", 
                    rank_index=i+1
                )
                output_md += (
                    f"*(Debug: Final={row['final_score']:.2f} | "
                    f"Travel={row['score_travel']:.2f} | "
                    f"Friend={row['score_friendliness']:.2f})*\n\n---\n\n"
                )

        except GraphHopperDownError as e:
            # --- 2ë‹¨ê³„ (B): Fallback (1ë‹¨ê³„ RAG ê²°ê³¼ ì‚¬ìš©) ---
            print(f"[ê²½ê³ ] 2ë‹¨ê³„ final_scorer ì‹¤íŒ¨: {e}. 1ë‹¨ê³„ RAG ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            gr.Warning("âš ï¸ ëšœë²…ì´ ì ìˆ˜ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            
            output_md = (
                "### ğŸ¤– 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼\n"
                "(ëšœë²…ì´ ì ìˆ˜ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•Šì•„, 'ëšœë²…ì´ ì ìˆ˜'ê°€ ë°˜ì˜ë˜ì§€ ì•Šì€ 1ë‹¨ê³„ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.)\n\n"
            )
            
            top_k_ids = candidate_ids[:top_k] # (â˜… top_k ì‚¬ìš©)
            
            for i, store_id in enumerate(top_k_ids):
                output_md += search_logic.format_restaurant_markdown(
                    store_id_str=store_id, 
                    rank_prefix="RAG ì¶”ì²œ", 
                    rank_index=i+1
                )
                output_md += "\n---\n\n"
                
        # --- [ Fallback ë¡œì§ ì¢…ë£Œ ] ---
        
        final_user_profile_row = user_profile_row
        return gr.update(value=output_md, visible=True), final_user_profile_row
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ íë¦„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        gr.Error(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        reco_output = gr.update(value=f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì„¸ë¶€ì •ë³´: {e})", visible=True)
        return reco_output, final_user_profile_row
    
async def chat_survey(
    message: str, 
    gradio_history: List[Dict], 
    llm_history: List[Dict], 
    current_profile: Dict, 
    is_completed: bool,
    topk_value: int,              # (â˜… app_main.pyì™€ ì¼ì¹˜ì‹œí‚´)
    user_profile_row_state: Dict, # (â˜… app_main.pyì™€ ì¼ì¹˜ì‹œí‚´)
    # (app.stateì—ì„œ ì£¼ì…ë˜ëŠ” ìì›)
    http_client: httpx.AsyncClient,
    graphhopper_url: str
) -> Tuple[List[Dict], List[Dict], Dict, bool, gr.update, Dict]:
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    gradio_history.append({"role": "user", "content": message})
    llm_history.append({"role": "user", "content": message})
    
    # 2. gpt-4.1-mini API í˜¸ì¶œ (ì •ë³´ ìˆ˜ì§‘)
    try:
        bot_message, updated_profile = llm_utils.call_gpt4o(llm_history, current_profile)
    except Exception as e:
        print(f"chat_surveyì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        gradio_history.append({"role": "assistant", "content": error_msg})
        return gradio_history, llm_history, current_profile, is_completed, gr.update(), user_profile_row_state

    # 3. ë´‡ ì‘ë‹µ ì¶”ê°€ (LLM APIìš©)
    llm_history.append({"role": "assistant", "content": bot_message})

    # --- 4. ì™„ë£Œ ì—¬ë¶€ í™•ì¸ ë° ìµœì¢… ë°ì´í„° ìƒì„± ---
    final_bot_message = bot_message
    recommendation_output = gr.update()
    new_user_profile_row_state = user_profile_row_state 
    
    profile_is_complete = all(v is not None for v in updated_profile.values())
    
    if profile_is_complete and not is_completed:
        print("--- í”„ë¡œí•„ ì™„ì„±! 1/2ë‹¨ê³„ ì¶”ì²œ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ---")
        gr.Info("í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! AIê°€ 1/2ë‹¨ê³„ ë§ì¶¤ ì‹ë‹¹ ì¶”ì²œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        chat_message_html = llm_utils.generate_profile_summary_html(updated_profile)
        
        # (â˜… ìˆ˜ì •) _run_recommendation_flowëŠ” 2ê°œì˜ ê°’ì„ ë°˜í™˜
        recommendation_output, new_user_profile_row_state = await _run_recommendation_flow(
            updated_profile, 
            http_client, 
            graphhopper_url,
            top_k=topk_value # (â˜… ìŠ¬ë¼ì´ë”ì˜ topk_value ì „ë‹¬)
        )
        
        final_bot_message = f"{bot_message}\n{chat_message_html}\n\nğŸ‘‡ ì•„ë˜ì—ì„œ ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”! ğŸ‘‡"
        is_completed = True 
        print(json.dumps(updated_profile, indent=2, ensure_ascii=False))

    # 5. Gradio ì±—ë´‡ ê¸°ë¡ ì—…ë°ì´íŠ¸ (UIìš©)
    gradio_history.append({"role": "assistant", "content": final_bot_message})
    
    # 6. (â˜… 6ê°œ ìƒíƒœ ë°˜í™˜)
    return gradio_history, llm_history, updated_profile, is_completed, recommendation_output, new_user_profile_row_state


def update_recommendations_with_topk(topk_value: int, user_profile_row_state: Dict):
    """
    (ì‹ ê·œ í—¬í¼ í•¨ìˆ˜ - ìŠ¬ë¼ì´ë”ìš©)
    Top-K ê°’ì´ ë°”ë€” ë•Œë§ˆë‹¤, ì €ì¥ëœ 'user_profile_row_state'ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì¶”ì²œ ê²°ê³¼ Markdownë§Œ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤. (API í˜¸ì¶œ X)
    """
    
    # (í”„ë¡œí•„ì´ ì•„ì§ ì—†ê±°ë‚˜, 1ë‹¨ê³„ê°€ ì‹¤í–‰ëœ ì  ì—†ìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•¨)
    if not user_profile_row_state:
        return gr.update(value="...í”„ë¡œí•„ì„ ë¨¼ì € ì™„ì„±í•´ì£¼ì„¸ìš”...", visible=True)
    
    gr.Info(f"--- Top-K ë³€ê²½: {topk_value}ê°œë¡œ ì¶”ì²œ ëª©ë¡ì„ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤. ---")
    
    try:
        # 1. 2ë‹¨ê³„ (ëšœë²…ì´ ì ìˆ˜) ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        if user_profile_row_state.get("final_scored_df"):
            # (DataFrameì´ to_dict('records')ë¡œ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ ë³€í™˜)
            final_scored_df = pd.DataFrame(user_profile_row_state["final_scored_df"])
            # (idë¥¼ ì¸ë±ìŠ¤ë¡œ ë³µì› - format_restaurant_markdownì´ ì¸ë±ìŠ¤(store_id)ë¥¼ ì‚¬ìš©í•¨)
            if 'id' in final_scored_df.columns:
                 final_scored_df = final_scored_df.set_index('id')
            
            top_k_df = final_scored_df.head(topk_value)
            output_md = "### ğŸ¤– 'ëšœë²…ì´ ì ìˆ˜' í¬í•¨ ìµœì¢… ì¶”ì²œ!\n\n"
            
            for i, (store_id, row) in enumerate(top_k_df.iterrows()):
                output_md += search_logic.format_restaurant_markdown(
                    store_id_str=store_id, 
                    rank_prefix="ìµœì¢… ì¶”ì²œ", 
                    rank_index=i+1
                )
                output_md += (
                    f"*(Debug: Final={row['final_score']:.2f} | "
                    f"Travel={row['score_travel']:.2f} | "
                    f"Friend={row['score_friendliness']:.2f})*\n\n---\n\n"
                )
        
        # 2. 2ë‹¨ê³„ ê²°ê³¼ê°€ ì—†ê³ , 1ë‹¨ê³„ (Fallback) ê²°ê³¼ë§Œ ìˆëŠ”ì§€ í™•ì¸
        elif user_profile_row_state.get("final_candidate_ids"):
            output_md = (
                "### ğŸ¤– 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼\n"
                "(ëšœë²…ì´ ì ìˆ˜ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•Šì•„, 'ëšœë²…ì´ ì ìˆ˜'ê°€ ë°˜ì˜ë˜ì§€ ì•Šì€ 1ë‹¨ê³„ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.)\n\n"
            )
            top_k_ids = user_profile_row_state["final_candidate_ids"][:topk_value] 
            
            for i, store_id in enumerate(top_k_ids):
                output_md += search_logic.format_restaurant_markdown(
                    store_id_str=store_id, 
                    rank_prefix="RAG ì¶”ì²œ", 
                    rank_index=i+1
                )
                output_md += "\n---\n\n"
        
        # 3. ì•„ë¬´ ê²°ê³¼ë„ ì €ì¥ë˜ì§€ ì•Šì€ ê²½ìš°
        else:
            output_md = "...ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (State ë¹„ì–´ìˆìŒ)..."

        return gr.update(value=output_md, visible=True)

    except Exception as e:
        print(f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}")
        return gr.update(value=f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}", visible=True)