import uvicorn
import httpx
import asyncio
from contextlib import asynccontextmanager
from typing import List, Dict, Any, Tuple
import pandas as pd

from fastapi import FastAPI, HTTPException
import gradio as gr

# ëª¨ë“ˆ ì„í¬íŠ¸
import config
import data_loader
import llm_utils
import gradio_callbacks # (Gradio ì½œë°± í•¨ìˆ˜)
import search_logic
from API import final_scorer # (ì‚¬ì¥ë‹˜ ë¡œì§)
from models import RecommendationRequest, RecommendationResponse

# --- 1. FastAPI ì•± ë° Lifespan (ì„œë²„ ì‹œì‘/ì¢…ë£Œ) ---

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ì‹¤í–‰"""
    print("--- ì„œë²„ ì‹œì‘: Lifespan ì‹œì‘ ---")
    
    # 1. (í•„ìˆ˜) API í‚¤ ë¡œë“œ í™•ì¸
    if not config.client or not config.client.api_key:
        print("[ì¹˜ëª…ì  ì˜¤ë¥˜] OPENAI_API_KEYê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        # (ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” ì—¬ê¸°ì„œ exit() ë˜ëŠ” raise)
    else:
        print("  > OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ.")

    # 2. (í•„ìˆ˜) GraphHopper ì—°ê²°ìš© HTTP í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    # (final_scorerê°€ API í˜¸ì¶œ ì‹œ ì´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¬ì‚¬ìš©)
    app.state.http_client = httpx.AsyncClient()
    print("  > HTTPX AsyncClient ìƒì„± ì™„ë£Œ.")

    # 3. (í•„ìˆ˜) ëª¨ë“  CSV ë° VectorDB ë¡œë“œ
    # (data_loader.pyì˜ ì „ì—­ ë³€ìˆ˜ë“¤ì´ ì±„ì›Œì§)
    try:
        data_loader.load_app_data(
            config.RESTAURANT_DB_FILE, 
            config.MENU_DB_FILE
        )
        data_loader.load_user_ratings()
        data_loader.build_vector_db(
            config.RESTAURANT_DB_FILE,
            config.PROFILE_DB_FILE,
            config.CLEAR_DB_AND_REBUILD
        )
        
        # 4. (í•„ìˆ˜) /recommendations APIìš© ìŠ¤ì½”ì–´ë§ DB ë¡œë“œ
        # (ì´ ë°ì´í„°ë¥¼ app.stateì— ì €ì¥ -> /recommendationsê°€ ì‚¬ìš©)
        app.state.all_restaurants_df_scoring = data_loader.load_scoring_data(
            config.RESTAURANT_DB_SCORING_FILE
        )
        
        print("  > ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
        
    except Exception as e:
        print(f"[ì¹˜ëª…ì  ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        # (ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” ì—¬ê¸°ì„œ exit() ë˜ëŠ” raise)

    print("--- ì„œë²„ ì‹œì‘ ì™„ë£Œ ---")
    
    yield # (ì„œë²„ ì‹¤í–‰)
    
    # --- ì„œë²„ ì¢…ë£Œ ì‹œ ---
    print("--- ì„œë²„ ì¢…ë£Œ: Lifespan ì¢…ë£Œ ---")
    await app.state.http_client.aclose()
    print("  > HTTPX AsyncClient ì¢…ë£Œ.")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="FastAPI + Gradio í†µí•© ì¶”ì²œ ì„œë²„",
    description="ì±—ë´‡ ì„œë² ì´ì™€ 2ë‹¨ê³„ 'ëšœë²…ì´' ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ í†µí•©",
    lifespan=lifespan
)

# --- 2. (ê¸°ì¡´) /recommendations ì—”ë“œí¬ì¸íŠ¸ ---
# (ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì±—ë´‡ê³¼ 'ë…ë¦½ì 'ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤)

@app.post(
    "/recommendations", 
    response_model=RecommendationResponse,
    tags=["2-Stage Scorer (final_scorer)"]
)
async def get_recommendations(request: RecommendationRequest):
    """
    (ì±—ë´‡ê³¼ ë¬´ê´€) 1ë‹¨ê³„ í›„ë³´êµ° 150ê°œë¥¼ 'ëœë¤'ìœ¼ë¡œ ìƒì„±í•˜ê³ 
    'final_scorer' ë¡œì§ì„ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if app.state.all_restaurants_df_scoring is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì¤‘ (ìŠ¤ì½”ì–´ë§ DB ë¡œë“œ ì‹¤íŒ¨)")

    # 1. 1ë‹¨ê³„ í›„ë³´êµ° ìƒì„± (ëœë¤ ìƒ˜í”Œë§)
    try:
        candidate_df = app.state.all_restaurants_df_scoring.sample(n=request.n_results)
    except ValueError:
        # (DBê°€ 150ê°œë³´ë‹¤ ì ì„ ê²½ìš°)
        candidate_df = app.state.all_restaurants_df_scoring.copy()

    # 2. 2ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ ì‹¤í–‰ (final_scorer.py í˜¸ì¶œ)
    try:
        final_scored_df = await final_scorer.calculate_final_scores_async(
            candidate_df=candidate_df,
            user_start_location=request.user_start_location,
            user_price_prefs=request.user_price_prefs,
            async_http_client=app.state.http_client, # (Lifespanì—ì„œ ìƒì„±í•œ í´ë¼ì´ì–¸íŠ¸ ì£¼ì…)
            graphhopper_url=config.GRAPH_HOPPER_API_URL
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"2ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨: {e}")
        
    # 3. Pydantic ëª¨ë¸ì— ë§ì¶° ê²°ê³¼ ë°˜í™˜
    results = final_scored_df.reset_index().to_dict('records')
    return RecommendationResponse(
        recommendations=results,
        total_count=len(results)
    )

# --- 3. (ì‹ ê·œ) Gradio ì±—ë´‡ UI ---

with gr.Blocks(theme=gr.themes.Soft()) as gradio_app:
    gr.Markdown("# ğŸ¤– ëšœë²…ì´ ì—¬í–‰ìë¥¼ ìœ„í•œ ì±—ë´‡ (v2)")
    gr.Markdown("AIê°€ 14ê°€ì§€ í”„ë¡œí•„(ì¶œë°œ ìœ„ì¹˜ í¬í•¨)ì„ ìˆ˜ì§‘í•˜ê³ , 'ì´ë™ ë§ˆì°° ì ìˆ˜'ê°€ í¬í•¨ëœ ë§ì¶¤ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
    
    with gr.Row():
        with gr.Column(scale=2):
            # 1. (Gradioìš©) ë³´ì´ì§€ ì•ŠëŠ” ìƒíƒœ(State) ë³€ìˆ˜
            llm_history_state = gr.State(value=[]) 
            profile_state = gr.State(value=config.PROFILE_TEMPLATE.copy())
            is_completed_state = gr.State(value=False)

            # 2. ì±„íŒ…ì°½
            chatbot = gr.Chatbot(
                label="ì„œë² ì´ ì±—ë´‡", 
                height=700, 
                show_copy_button=True,
                type='messages'
            )
            
            # 3. ì‚¬ìš©ì ì…ë ¥
            msg_textbox = gr.Textbox(
                label="ë‹µë³€ ì…ë ¥", 
                placeholder="ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”..."
            )
        
        with gr.Column(scale=1):
            gr.Markdown("### ğŸŒŸ ë§ì¶¤ ì¶”ì²œ ê²°ê³¼")
            # (ê²°ê³¼ê°€ í‘œì‹œë  ì˜ì—­)
            recommendation_output = gr.Markdown(
                label="ì¶”ì²œ ê²°ê³¼",
                value="...í”„ë¡œí•„ ì„¤ë¬¸ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤...",
                visible=True # (í•­ìƒ ë³´ì´ë„ë¡ ìˆ˜ì •)
            )

    # --- 4. (â˜…í•µì‹¬â˜…) Gradio ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²° ---
    
    # (A) ì•±ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ
    gradio_app.load(
        fn=gradio_callbacks.start_chat, # (ì¼ë°˜ í•¨ìˆ˜)
        inputs=None,
        outputs=[chatbot, llm_history_state, profile_state, is_completed_state]
    )
    
    # (B) ì‚¬ìš©ìê°€ Enter(submit)ë¥¼ ëˆ„ë¥¼ ë•Œ
    
    async def chat_survey_handler(
        message: str, 
        gradio_history: List[Dict], 
        llm_history: List[Dict], 
        current_profile: Dict, 
        is_completed: bool
    ) -> Tuple[List[Dict], List[Dict], Dict, bool, gr.update]:
        """
        app_main.pyì— ì •ì˜ëœ ë¡œì»¬ í•¸ë“¤ëŸ¬.
        Gradioì˜ ì…ë ¥ì„ ë°›ì•„, 'app.state'ì˜ ìì›ì„
        gradio_callbacks.chat_survey í•¨ìˆ˜ì— 'ì£¼ì…(inject)'í•©ë‹ˆë‹¤.
        """
        return await gradio_callbacks.chat_survey(
            message=message,
            gradio_history=gradio_history,
            llm_history=llm_history,
            current_profile=current_profile,
            is_completed=is_completed,
            # --- (â˜…) app.stateì˜ ìì› ì£¼ì… (â˜…) ---
            http_client=app.state.http_client,
            graphhopper_url=config.GRAPH_HOPPER_API_URL
        )

    msg_textbox.submit(
        fn=chat_survey_handler, # (â˜…) (ë¹„ë™ê¸° ë¡œì»¬ í•¸ë“¤ëŸ¬)
        inputs=[
            msg_textbox, chatbot, llm_history_state, 
            profile_state, is_completed_state
        ],
        outputs=[
            chatbot, llm_history_state, profile_state, 
            is_completed_state, recommendation_output
        ]
    )
    
    # (C) Enter ëˆ„ë¥¸ í›„ í…ìŠ¤íŠ¸ë°•ìŠ¤ ë¹„ìš°ê¸°
    msg_textbox.submit(lambda: "", inputs=None, outputs=msg_textbox)

# --- 5. FastAPI ì•±ì— Gradio UI ë§ˆìš´íŠ¸ ---
app = gr.mount_gradio_app(
    app, 
    gradio_app, 
    path="/chatbot",
    # (Gradioì˜ ì •ì  íŒŒì¼(CSS/JS)ì„ FastAPIê°€ ì˜¬ë°”ë¥´ê²Œ ì„œë¹™í•˜ë„ë¡ ìˆ˜ì •)
    # (Gradio 4.x ì´ìƒ ë° FastAPI 0.100+ ì´ìƒì—ì„œ ê¶Œì¥)
    app_kwargs={
        "title": "Gradio App on FastAPI",
        "description": "Gradio app is mounted at /chatbot",
    }
)

# --- 6. ì„œë²„ ì‹¤í–‰ ---
if __name__ == "__main__":
    # (GraphHopperê°€ 8989, FastAPI/Gradioê°€ 8080ì„ ì‚¬ìš©)
    uvicorn.run(
        "app_main:app", 
        host="127.0.0.1", 
        port=8080, 
        reload=True
    )