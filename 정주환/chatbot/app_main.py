# app_main.py (CSS ì¶”ê°€)

import uvicorn
import httpx
from contextlib import asynccontextmanager
from typing import List, Dict, Any

from fastapi import FastAPI, HTTPException
import gradio as gr

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
import config 
import data_loader
import llm_utils
import gradio_callbacks
import search_logic
from API import final_scorer
from models import RecommendationRequest, RecommendationResponse

# â¬‡ï¸ í”„ë¡œí•„ ë·° ëª¨ë“ˆ
from profile_view import normalize_profile, render_profile_card, PROFILE_VIEW_CSS

# ë‹¤êµ­ì–´
from i18n_texts import I18N_TEXTS, get_lang_code, get_text

# ========= 0) ìš”ì•½ë¬¸ Fallback ì¶”ì¶œ ìœ í‹¸ =========
def _extract_summary_text(profile: Dict, chatbot_hist: List[Dict], llm_hist: List[Dict]) -> str:
  """profile/llm_history/chatbot íˆìŠ¤í† ë¦¬ì—ì„œ ìš”ì•½ë¬¸ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
  # 1) profile ë‚´ë¶€
  for k in ["summary","profile_summary","llm_summary","final_summary","ìš”ì•½","í”„ë¡œí•„ìš”ì•½"]:
    v = (profile or {}).get(k)
    if isinstance(v, str) and v.strip():
      return v.strip()
  # 2) llm_history ìµœê·¼
  if isinstance(llm_hist, list):
    for msg in reversed(llm_hist[-10:]):
      if not isinstance(msg, dict):
        continue
      txt = str(msg.get("content","")).strip()
      if len(txt) > 40 and any(key in txt for key in ["ìš”ì•½","í”„ë¡œí•„","summary","ì•ˆë…•í•˜ì„¸ìš”"]):
        return txt
  # 3) chatbot íˆìŠ¤í† ë¦¬ (type="messages" í¬ë§· or (u,a) tuple)
  if isinstance(chatbot_hist, list):
    for turn in reversed(chatbot_hist[-6:]):
      if isinstance(turn, dict) and turn.get("role") == "assistant":
        txt = str(turn.get("content","")).strip()
        if len(txt) > 40 and any(key in txt for key in ["ìš”ì•½","í”„ë¡œí•„","summary","ì•ˆë…•í•˜ì„¸ìš”"]):
          return txt
      if isinstance(turn, (list, tuple)) and len(turn) == 2:
        txt = str(turn[1]).strip()
        if len(txt) > 40 and any(key in txt for key in ["ìš”ì•½","í”„ë¡œí•„","summary","ì•ˆë…•í•˜ì„¸ìš”"]):
          return txt
  return ""


# ========= 1) Lifespan =========
@asynccontextmanager
async def lifespan(app: FastAPI):
  print("--- ì„œë²„ ì‹œì‘: Lifespan ì‹œì‘ ---")
  if not getattr(config, "client", None) or not getattr(config.client, "api_key", None):
    print("[ì¹˜ëª…ì  ì˜¤ë¥˜] OPENAI_API_KEYê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
  else:
    print("  > OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ.")

  app.state.http_client = httpx.AsyncClient()
  print("  > HTTPX AsyncClient ìƒì„± ì™„ë£Œ.")

  try:
    data_loader.load_app_data(
      config.RESTAURANT_DB_FILE_ALL, 
      config.MENU_DB_FILE,
    )
    data_loader.load_user_ratings()
    
    data_loader.build_vector_db(
      config.PROFILE_DB_FILE,         
      config.CLEAR_DB_AND_REBUILD,    
    )
    
    app.state.all_restaurants_df_scoring = data_loader.load_scoring_data(
      config.RESTAURANT_DB_SCORING_FILE
    )
    print("  > ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
  except Exception as e:
    print(f"[ì¹˜ëª…ì  ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

  print("--- ì„œë²„ ì‹œì‘ ì™„ë£Œ ---")
  yield
  print("--- ì„œë²„ ì¢…ë£Œ: Lifespan ì¢…ë£Œ ---")
  await app.state.http_client.aclose()
  print("  > HTTPX AsyncClient ì¢…ë£Œ.")


# ========= 2) FastAPI =========
app = FastAPI(
  title="FastAPI + Gradio í†µí•© ì¶”ì²œ ì„œë²„",
  description="ì±—ë´‡ ì„œë² ì´ì™€ 2ë‹¨ê³„ 'ëšœë²…ì´' ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ í†µí•©",
  lifespan=lifespan,
)


# ========= 3) /recommendations =========
@app.post(
  "/recommendations",
  response_model=RecommendationResponse,
  tags=["2-Stage Scorer (final_scorer)"],
)
async def get_recommendations(request: RecommendationRequest):
  if app.state.all_restaurants_df_scoring is None:
    raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì¤‘ (ìŠ¤ì½”ì–´ë§ DB ë¡œë“œ ì‹¤íŒ¨)")

  try:
    candidate_df = app.state.all_restaurants_df_scoring.sample(n=request.n_results)
  except ValueError:
    candidate_df = app.state.all_restaurants_df_scoring.copy()

  try:
    final_scored_df = await final_scorer.calculate_final_scores_async(
      candidate_df=candidate_df,
      user_start_location=request.user_start_location,
      user_price_prefs=request.user_price_prefs,
      async_http_client=app.state.http_client,
      graphhopper_url=config.GRAPH_HOPPER_API_URL,
    )
  except Exception as e:
    raise HTTPException(status_code=500, detail=f"2ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨: {e}")

  results = final_scored_df.reset_index().to_dict("records")
  return RecommendationResponse(recommendations=results, total_count=len(results))


# ========= 4) Gradio UI =========
GRADIO_CSS = PROFILE_VIEW_CSS + """
/* (â˜…â˜…â˜… ì•± ë©”ì¸ CSS â˜…â˜…â˜…) */
.controls-bar{display:flex;align-items:center;gap:12px;margin:8px 0}
.controls-left{flex:1;min-width:280px}
.controls-right{display:flex;gap:8px}

/* (â˜…â˜…â˜… 1. Charlieë‹˜ì´ ìš”ì²­í•œ ì‹ ê·œ CSS ì¶”ê°€ â˜…â˜…â˜…) */
/* Custom CSS for visual fidelity */
.border-container {
  border: 1px solid #e5e7eb;
  border-radius: 8px; /* rounded-lg */
  box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05); /* shadow-sm */
  padding: 1rem; /* p-4 */
  margin-bottom: 1rem; /* space-y-4 */
}

/* ìŒì‹ ì¶”ì²œ ì•„ì´í…œ ë‚´ë¶€ì˜ í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ */
.border-item {
  border: 1px solid #e5e7eb;
  border-radius: 8px;
  padding: 0.75rem; /* p-3 */
  margin-bottom: 0.75rem; /* space-y-3 */
}

/* ì‘ì€ í…ìŠ¤íŠ¸ + ë°°ê²½ (ìŒì‹ íƒìƒ‰ íƒ­ì˜ íƒœê·¸) */
.text-xs-bg {
  font-size: 0.75rem; /* text-xs */
  background-color: #f3f4f6; /* bg-gray-100 */
  border-radius: 4px;
  padding: 2px 8px;
  margin-right: 4px; /* (íƒœê·¸ ê°„ ê°„ê²©) */
  margin-bottom: 4px; /* (íƒœê·¸ ì¤„ë°”ê¿ˆ ì‹œ ê°„ê²©) */
  white-space: nowrap;
  display: inline-block;
}

/* (â˜…â˜…â˜… 2. gr.HTML ë‚´ë¶€ì—ì„œ ë²„íŠ¼ ìŠ¤íƒ€ì¼ì„ ì ìš©í•˜ê¸° ìœ„í•œ CSS ì¶”ê°€ â˜…â˜…â˜…) */
/* Gradioì˜ .gr-button-primary, .gr-button-secondary, .gr-button-sm ìŠ¤íƒ€ì¼ì„ ë³µì œ */

.html-button {
  text-decoration: none; /* ë§í¬ ë°‘ì¤„ ì œê±° */
  display: inline-block;
  padding: 0.25rem 0.5rem; /* sm: py-1 px-2 */
  font-size: 0.875rem; /* sm: text-sm */
  font-weight: 500; /* medium */
  border-radius: 0.375rem; /* rounded-md */
  border: 1px solid transparent;
  transition: all 0.2s;
  white-space: nowrap;
}

/* Primary Button (ìƒì„¸ ë³´ê¸°) */
.html-button-primary {
  background-color: #ff7600; /* gradio-orange-600 */
  color: white;
  border-color: #ff7600;
}
.html-button-primary:hover {
  background-color: #f06e00; /* hover ì–´ë‘¡ê²Œ */
  border-color: #f06e00;
  box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
}

/* Secondary Button (ì¹´ì¹´ì˜¤ë§µ) -> Kakao Yellow */
.html-button-secondary {
  background-color: #FEE500; /* Kakao Yellow */
  color: #374151; /* Dark Text (gray-700) */
  border-color: #FEE500; 
}
.html-button-secondary:hover {
  background-color: #F0D900; /* Darker Yellow */
  border-color: #F0D900;
  color: #374151; /* Keep Dark Text */
  box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
}

/* â¬‡ï¸ [ì‹ ê·œ] ë±ƒì§€/íƒœê·¸ CSS (3ê°œ ì¶”ê°€) â¬‡ï¸ */
.badge-ribbon {
  display: inline-block;
  font-size: 1.1rem; /* ì´ëª¨ì§€ í¬ê¸° */
  margin-left: 6px;
  vertical-align: middle;
  line-height: 1;
}
.badge-seoul2025 {
  display: inline-block;
  background-color: #007bff; /* ì„œìš¸ì‹œ íŒŒë€ìƒ‰ (ì˜ˆì‹œ) */
  color: white;
  font-size: 0.7rem;
  font-weight: 700;
  padding: 3px 6px;
  border-radius: 4px;
  margin-left: 6px;
  vertical-align: middle;
  line-height: 1;
}
.tags-container {
  margin-bottom: 12px;
}
/* (â˜…â˜…â˜… ì‹ ê·œ CSS ë â˜…â˜…â˜…) */
"""

# â¬‡ï¸ ì´ˆê¸° ì–¸ì–´ ì„¤ì • (ì´ì œ load ì´ë²¤íŠ¸ê°€ ë®ì–´ì”€)
INITIAL_LANG_CODE = "KR"

with gr.Blocks(title=get_text("app_title", INITIAL_LANG_CODE), theme=gr.themes.Soft(), css=GRADIO_CSS) as gradio_app:
    # â¬‡ï¸ [ìˆ˜ì •] ì»´í¬ë„ŒíŠ¸ ë³€ìˆ˜ë§Œ ì •ì˜. (ê°’ ì„¤ì •ì€ load ì´ë²¤íŠ¸ì—ì„œ)
    title_md = gr.Markdown("## ...")
    desc_md = gr.Markdown("...")

    # â¬‡ï¸ [ì‚­ì œ] js_loader ì‚­ì œ
    # js_loader = gr.HTML(visible=False)

    with gr.Group():
        #gr.Markdown("### ğŸŒ ì–¸ì–´ ì„¤ì •")
        with gr.Row():
            # â¬‡ï¸ [ìˆ˜ì •] 4ê°œ ë²„íŠ¼ -> 1ê°œ Radioë¡œ ë³µê·€
            lang_radio = gr.Radio(
                ["í•œêµ­ì–´ KR", "English US", "æ—¥æœ¬èª JP", "ä¸­æ–‡ CN"],
                label="...", # (loadì—ì„œ ì„¤ì •)
                value="í•œêµ­ì–´ KR",
                interactive=True,
            )

    # States
    llm_history_state = gr.State(value=[])
    profile_state = gr.State(value=config.PROFILE_TEMPLATE.copy())
    is_completed_state = gr.State(value=False)
    user_profile_row_state = gr.State(value=None)
    lang_code_state = gr.State(value=INITIAL_LANG_CODE)

    with gr.Tabs():
        # â¬‡ï¸ [ìˆ˜ì •] ì»´í¬ë„ŒíŠ¸ ë³€ìˆ˜ë§Œ ì •ì˜
        with gr.TabItem("...") as tab_explore:
            # ---- ì±„íŒ… ì˜ì—­ ----
            with gr.Group() as chat_group:
                with gr.Column():
                    chatbot = gr.Chatbot(
                        label="...", # (loadì—ì„œ ì„¤ì •)
                        height=700,
                        show_copy_button=True,
                        type="messages",
                    )
                    msg_textbox = gr.Textbox(
                        label="...", # (loadì—ì„œ ì„¤ì •)
                        placeholder="...", # (loadì—ì„œ ì„¤ì •)
                    )
                    # âœ… ê²°ê³¼ ë³´ê¸° ë²„íŠ¼ (ì±„íŒ… â†’ ê²°ê³¼ í™”ë©´ ì´ë™)
                    show_results_btn = gr.Button("...", variant="primary") # (loadì—ì„œ ì„¤ì •)

            # ---- ê²°ê³¼ ì˜ì—­ ----
            with gr.Group(visible=False) as result_group:
                profile_html = gr.HTML(label=None, value="")

                gr.HTML("<div class='controls-bar'><div id='ctrl-left' class='controls-left'></div><div id='ctrl-right' class='controls-right'></div></div>")
                with gr.Group(elem_id="ctrl-left"):
                    topk_slider = gr.Slider(
                        minimum=1, maximum=30, value=5, step=1, label="..." # (loadì—ì„œ ì„¤ì •)
                    )
                with gr.Group(elem_id="ctrl-right"):
                    with gr.Row():
                        refresh_btn = gr.Button("...", variant="secondary") # (loadì—ì„œ ì„¤ì •)
                        back_btn    = gr.Button("...",  variant="secondary") # (loadì—ì„œ ì„¤ì •)

                recommendation_output = gr.HTML(label=None, value="") # (ìˆ˜ì •)
                
        with gr.TabItem("...") as tab_setting:
            with gr.Column():
                # â¬‡ï¸ ì„¤ì • íƒ­ í…ìŠ¤íŠ¸ ë³€ìˆ˜ì— í• ë‹¹ ë° get_text() ì‚¬ìš©
                setting_header_md = gr.Markdown("...") # (loadì—ì„œ ì„¤ì •)
                setting_desc_md = gr.Markdown("...") # (loadì—ì„œ ì„¤ì •)
                
                rebuild_btn = gr.Button("...") # (loadì—ì„œ ì„¤ì •)
                debug_checkbox = gr.Checkbox(label="...", value=False) # (loadì—ì„œ ì„¤ì •)

                # ğŸ” ë””ë²„ê·¸ íŒ¨ë„
                debug_toggle = gr.Checkbox(label="...", value=False) # (loadì—ì„œ ì„¤ì •)
                debug_profile_json = gr.JSON(label="...", visible=False) # (loadì—ì„œ ì„¤ì •)
                debug_summary_text = gr.Textbox(label="...", visible=False) # (loadì—ì„œ ì„¤ì •)
                debug_norm_json    = gr.JSON(label="...", visible=False) # (loadì—ì„œ ì„¤ì •)

    # ---- ì´ë²¤íŠ¸ ë°”ì¸ë”© ----

    # â¬‡ï¸ [ìˆ˜ì •] (A) í˜ì´ì§€ ë¡œë“œ
    # start_chatì´ 26ê°œì˜ State/UI ì´ˆê¸°ê°’ì„ ë°˜í™˜
    # (Radioë¡œ ë³µê·€í–ˆìœ¼ë¯€ë¡œ 29ê°œ -> 26ê°œë¡œ ë‹¤ì‹œ ë³€ê²½)
    gradio_app.load(
        fn=gradio_callbacks.start_chat,  
        inputs=None, # (fn ì‹œê·¸ë‹ˆì²˜ì— request: gr.Requestê°€ ìˆìœ¼ë©´ ìë™ ì£¼ì…ë¨)
        outputs=[
            # --- States (6ê°œ) ---
            chatbot,                  # 1. (Welcome ë©”ì‹œì§€)
            llm_history_state,        # 2
            profile_state,            # 3
            is_completed_state,       # 4
            user_profile_row_state,   # 5
            lang_code_state,          # 6
            
            # --- UI Components (20ê°œ) ---
            title_md,                 # 7
            desc_md,                  # 8
            
            lang_radio,               # 9. (Radioë¡œ ë³µê·€)
            
            tab_explore,              # 10
            tab_setting,              # 11
            chatbot,                  # 12 (chatbot label ì—…ë°ì´íŠ¸ìš© - ì¤‘ë³µ ì•„ë‹˜)
            msg_textbox,              # 13
            show_results_btn,         # 14
            topk_slider,              # 15
            refresh_btn,              # 16
            back_btn,                 # 17
            profile_html,             # 18 (value=Noneìœ¼ë¡œ ì´ˆê¸°í™”)
            setting_header_md,        # 19
            setting_desc_md,          # 20
            rebuild_btn,              # 21
            debug_checkbox,           # 22
            debug_toggle,             # 23
            debug_profile_json,       # 24
            debug_summary_text,       # 25
            debug_norm_json           # 26
        ],
    )

    # â¬‡ï¸ [ìˆ˜ì •] (B) ì–¸ì–´ ë³€ê²½ (ì±—ë´‡ ì´ˆê¸°í™” + UI ìƒˆë¡œê³ ì¹¨)
    lang_radio.change(
        fn=gradio_callbacks.reset_chat_for_language, # â¬…ï¸ [ì‹ ê·œ] ì½œë°± í•¨ìˆ˜
        inputs=[lang_radio],
        outputs=[
            # â¬‡ï¸ load ì´ë²¤íŠ¸ì˜ outputsì™€ ë™ì¼í•œ 26ê°œ ì»´í¬ë„ŒíŠ¸
            # --- States (6ê°œ) ---
            chatbot,                  # (Welcome ë©”ì‹œì§€)
            llm_history_state,
            profile_state,
            is_completed_state,
            user_profile_row_state,
            lang_code_state,
            
            # --- UI Components (20ê°œ) ---
            title_md,
            desc_md,
            lang_radio,
            tab_explore,
            tab_setting,
            chatbot,                  # (chatbot label ì—…ë°ì´íŠ¸ìš© - ì¤‘ë³µ ì•„ë‹˜)
            msg_textbox,
            show_results_btn,
            topk_slider,
            refresh_btn,
            back_btn,
            profile_html,
            setting_header_md,
            setting_desc_md,
            rebuild_btn,
            debug_checkbox,
            debug_toggle,
            debug_profile_json,
            debug_summary_text,
            debug_norm_json,
            
            # â¬‡ï¸ [ì‹ ê·œ] 27, 28ë²ˆì§¸ outputìœ¼ë¡œ ì¶”ê°€
            chat_group,               # 27. ì±„íŒ… í™”ë©´
            result_group,             # 28. ê²°ê³¼ í™”ë©´
        ],
        queue=True # (LLM APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ í ì‚¬ìš©)
    )
    
    # --- (ì´í•˜ ë‚˜ë¨¸ì§€ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ëŠ” ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©) ---

    async def chat_survey_handler(
        message: str,
        gradio_history: List[Dict],
        llm_history: List[Dict],
        current_profile: Dict,
        is_completed: bool,
        topk_value: int,
        user_profile_row: Dict,
        debug_on: bool,
        lang_code: str,
    ):
        """
        (ìˆ˜ì •ë¨: ì´ í•¨ìˆ˜ëŠ” ì´ì œ ì œë„ˆë ˆì´í„°ì…ë‹ˆë‹¤)
        chat_survey ì½œë°±ì´ yieldí•˜ëŠ” ê°’ë“¤ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì•„ UIë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        
        # 1. (ìˆ˜ì •) `await` ëŒ€ì‹  `async for`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        #    gradio_callbacks.chat_surveyê°€ (A)ëŒ€ê¸°, (B)ê²°ê³¼ 2ê°œë¥¼ yieldí•©ë‹ˆë‹¤.
        async for (
            chatbot_out,
            llm_out,
            profile_out,
            is_completed_out,
            rec_md_out,
            upr_out,
        ) in gradio_callbacks.chat_survey( # â¬…ï¸ (await ì œê±°)
            message=message,
            gradio_history=gradio_history,
            llm_history=llm_history,
            current_profile=current_profile,
            is_completed=is_completed,
            topk_value=topk_value,
            user_profile_row_state=user_profile_row,
            http_client=app.state.http_client,
            graphhopper_url=config.GRAPH_HOPPER_API_URL,
            lang_code=lang_code,
        ):
            # --- (ì´í•˜ ë¡œì§ì€ yieldë˜ëŠ” ê°’ë“¤ë¡œ UIë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤) ---
            
            # â˜… ìš”ì•½ë¬¸ ê°•ì œ ì£¼ì… (fallback)
            summary_text = _extract_summary_text(profile_out, chatbot_out, llm_out)
            profile_for_view = dict(profile_out or {})
            if summary_text and "summary" not in profile_for_view:
                profile_for_view["summary"] = summary_text
    
            # í™”ë©´ ì „í™˜/ì¹´ë“œ ë Œë”
            chat_group_vis   = gr.update(visible=not is_completed_out)
            result_group_vis = gr.update(visible=is_completed_out)
            profile_html_out = gr.update(value=render_profile_card(profile_for_view, lang_code))
    
            # ë””ë²„ê·¸ íŒ¨ë„ ê°’
            norm_preview = normalize_profile(profile_for_view)
            vis = gr.update(visible=bool(debug_on))
            
            # 2. (ìˆ˜ì •) `return` ëŒ€ì‹  `yield`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            #    (Gradioì— 12ê°œ ì¶œë ¥ê°’ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ë‹¬)
            yield ( 
                chatbot_out, llm_out, profile_out, is_completed_out,
                rec_md_out, upr_out,
                chat_group_vis, result_group_vis, profile_html_out,
                gr.update(value=profile_out, visible=bool(debug_on)),
                gr.update(value=summary_text, visible=bool(debug_on)),
                gr.update(value=norm_preview,  visible=bool(debug_on)),
            )

    msg_textbox.submit(
        fn=chat_survey_handler, # (ì´ í•¨ìˆ˜ëŠ” ì´ì œ ì œë„ˆë ˆì´í„°ì…ë‹ˆë‹¤)
        inputs=[msg_textbox, chatbot, llm_history_state, profile_state, is_completed_state, topk_slider, user_profile_row_state, debug_toggle, lang_code_state],
        outputs=[chatbot, llm_history_state, profile_state, is_completed_state, recommendation_output, user_profile_row_state, chat_group, result_group, profile_html, debug_profile_json, debug_summary_text, debug_norm_json],
    )
    msg_textbox.submit(lambda: "", inputs=None, outputs=msg_textbox)
    
    
    # (C) Top-K ë³€ê²½ ì‹œ ì¶”ì²œë§Œ ê°±ì‹ 
    def update_recommendations_with_topk_handler(topk_value: int, user_profile_row: Dict, lang_code: str):
        return gradio_callbacks.update_recommendations_with_topk(
            topk_value=topk_value,
            user_profile_row_state=user_profile_row,
            lang_code=lang_code, 
        )

    topk_slider.change(
        fn=update_recommendations_with_topk_handler,
        inputs=[topk_slider, user_profile_row_state, lang_code_state], 
        outputs=recommendation_output,
    )

    refresh_btn.click(
        fn=update_recommendations_with_topk_handler,
        inputs=[topk_slider, user_profile_row_state, lang_code_state], 
        outputs=recommendation_output,
    )

    # (D) ë””ë²„ê·¸ í† ê¸€: í‘œì‹œë§Œ í† ê¸€
    def _toggle_debug(v: bool):
        return gr.update(visible=v), gr.update(visible=v), gr.update(visible=v)
    debug_toggle.change(_toggle_debug, inputs=[debug_toggle], outputs=[debug_profile_json, debug_summary_text, debug_norm_json])

    # (E) ë’¤ë¡œê°€ê¸°(í”„ë¡œí•„ ìˆ˜ì •): ê²°ê³¼â†’ì±„íŒ…
    def back_to_chat():
        return gr.update(visible=True), gr.update(visible=False), False
    back_btn.click(fn=back_to_chat, inputs=None, outputs=[chat_group, result_group, is_completed_state])

    # (F) âœ… ê²°ê³¼ ë³´ê¸°: ì±„íŒ…â†’ê²°ê³¼ (ìš”ì•½ ì£¼ì… + ì¹´ë“œ ê°±ì‹  í¬í•¨)
    def show_results_from_chat_handler(current_profile: Dict, user_profile_row: Dict, topk_value: int, chatbot_hist: List[Dict], llm_hist: List[Dict], lang_code: str):
        rec_md = update_recommendations_with_topk_handler(topk_value, user_profile_row, lang_code)
        # ìš”ì•½ ì£¼ì…
        summary_text = _extract_summary_text(current_profile, chatbot_hist, llm_hist)
        profile_for_view = dict(current_profile or {})
        if summary_text and "summary" not in profile_for_view:
            profile_for_view["summary"] = summary_text
        return (
            gr.update(visible=False),                                   # chat_group ìˆ¨ê¹€
            gr.update(visible=True),                                    # result_group í‘œì‹œ
            gr.update(value=render_profile_card(profile_for_view, lang_code)),  # í”„ë¡œí•„ ì¹´ë“œ
            rec_md,                                                     # ì¶”ì²œ ê²°ê³¼
            True                                                        # is_completed_state = True
        )

    show_results_btn.click(
        fn=show_results_from_chat_handler,
        inputs=[profile_state, user_profile_row_state, topk_slider, chatbot, llm_history_state, 
            lang_code_state],
        outputs=[chat_group, result_group, profile_html, recommendation_output, is_completed_state],
    )


# ========= 5) ë§ˆìš´íŠ¸ =========
app = gr.mount_gradio_app(
    app,
    gradio_app,
    path="/chatbot", # â¬…ï¸ JS ìƒˆë¡œê³ ì¹¨ ê²½ë¡œì™€ ì¼ì¹˜
    app_kwargs={
        "title": "Gradio App on FastAPI",
        "description": "Gradio app is mounted at /chatbot",
    },
)


# ========= 6) ì‹¤í–‰ =========
if __name__ == "__main__":
    uvicorn.run(
        "app_main:app",
        host="127.0.0.1",
        port=8080,
        reload=True,
    )
