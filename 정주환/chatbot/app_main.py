import uvicorn
import httpx
from contextlib import asynccontextmanager
from typing import List, Dict, Any

from fastapi import FastAPI, HTTPException
import gradio as gr

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
import config
import data_loader
import llm_utils
import gradio_callbacks
import search_logic
from API import final_scorer
from models import RecommendationRequest, RecommendationResponse

# â¬‡ï¸ í”„ë¡œí•„ ë·° ëª¨ë“ˆ
from profile_view import normalize_profile, render_profile_card, PROFILE_VIEW_CSS


# ========= 0) ìš”ì•½ë¬¸ Fallback ì¶”ì¶œ ìœ í‹¸ =========
def _extract_summary_text(profile: Dict, chatbot_hist: List[Dict], llm_hist: List[Dict]) -> str:
    """profile/llm_history/chatbot íˆìŠ¤í† ë¦¬ì—ì„œ ìš”ì•½ë¬¸ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    # 1) profile ë‚´ë¶€
    for k in ["summary","profile_summary","llm_summary","final_summary","ìš”ì•½","í”„ë¡œí•„ìš”ì•½"]:
        v = (profile or {}).get(k)
        if isinstance(v, str) and v.strip():
            return v.strip()
    # 2) llm_history ìµœê·¼
    if isinstance(llm_hist, list):
        for msg in reversed(llm_hist[-10:]):
            if not isinstance(msg, dict):
                continue
            txt = str(msg.get("content","")).strip()
            if len(txt) > 40 and any(key in txt for key in ["ìš”ì•½","í”„ë¡œí•„","summary","ì•ˆë…•í•˜ì„¸ìš”"]):
                return txt
    # 3) chatbot íˆìŠ¤í† ë¦¬ (type="messages" í¬ë§· or (u,a) tuple)
    if isinstance(chatbot_hist, list):
        for turn in reversed(chatbot_hist[-6:]):
            if isinstance(turn, dict) and turn.get("role") == "assistant":
                txt = str(turn.get("content","")).strip()
                if len(txt) > 40 and any(key in txt for key in ["ìš”ì•½","í”„ë¡œí•„","summary","ì•ˆë…•í•˜ì„¸ìš”"]):
                    return txt
            if isinstance(turn, (list, tuple)) and len(turn) == 2:
                txt = str(turn[1]).strip()
                if len(txt) > 40 and any(key in txt for key in ["ìš”ì•½","í”„ë¡œí•„","summary","ì•ˆë…•í•˜ì„¸ìš”"]):
                    return txt
    return ""


# ========= 1) Lifespan =========
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("--- ì„œë²„ ì‹œì‘: Lifespan ì‹œì‘ ---")
    if not getattr(config, "client", None) or not getattr(config.client, "api_key", None):
        print("[ì¹˜ëª…ì  ì˜¤ë¥˜] OPENAI_API_KEYê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        print("  > OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ.")

    app.state.http_client = httpx.AsyncClient()
    print("  > HTTPX AsyncClient ìƒì„± ì™„ë£Œ.")

    try:
        data_loader.load_app_data(
            config.RESTAURANT_DB_FILE,
            config.MENU_DB_FILE,
        )
        data_loader.load_user_ratings()
        data_loader.build_vector_db(
            config.RESTAURANT_DB_FILE,
            config.PROFILE_DB_FILE,
            config.CLEAR_DB_AND_REBUILD,
        )
        app.state.all_restaurants_df_scoring = data_loader.load_scoring_data(
            config.RESTAURANT_DB_SCORING_FILE
        )
        print("  > ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
    except Exception as e:
        print(f"[ì¹˜ëª…ì  ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

    print("--- ì„œë²„ ì‹œì‘ ì™„ë£Œ ---")
    yield
    print("--- ì„œë²„ ì¢…ë£Œ: Lifespan ì¢…ë£Œ ---")
    await app.state.http_client.aclose()
    print("  > HTTPX AsyncClient ì¢…ë£Œ.")


# ========= 2) FastAPI =========
app = FastAPI(
    title="FastAPI + Gradio í†µí•© ì¶”ì²œ ì„œë²„",
    description="ì±—ë´‡ ì„œë² ì´ì™€ 2ë‹¨ê³„ 'ëšœë²…ì´' ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ í†µí•©",
    lifespan=lifespan,
)


# ========= 3) /recommendations =========
@app.post(
    "/recommendations",
    response_model=RecommendationResponse,
    tags=["2-Stage Scorer (final_scorer)"],
)
async def get_recommendations(request: RecommendationRequest):
    if app.state.all_restaurants_df_scoring is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì¤‘ (ìŠ¤ì½”ì–´ë§ DB ë¡œë“œ ì‹¤íŒ¨)")

    try:
        candidate_df = app.state.all_restaurants_df_scoring.sample(n=request.n_results)
    except ValueError:
        candidate_df = app.state.all_restaurants_df_scoring.copy()

    try:
        final_scored_df = await final_scorer.calculate_final_scores_async(
            candidate_df=candidate_df,
            user_start_location=request.user_start_location,
            user_price_prefs=request.user_price_prefs,
            async_http_client=app.state.http_client,
            graphhopper_url=config.GRAPH_HOPPER_API_URL,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"2ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨: {e}")

    results = final_scored_df.reset_index().to_dict("records")
    return RecommendationResponse(recommendations=results, total_count=len(results))


# ========= 4) Gradio UI =========
GRADIO_CSS = PROFILE_VIEW_CSS + """
/* (â˜…â˜…â˜… ì•± ë©”ì¸ CSS â˜…â˜…â˜…) */
.controls-bar{display:flex;align-items:center;gap:12px;margin:8px 0}
.controls-left{flex:1;min-width:280px}
.controls-right{display:flex;gap:8px}

/* (â˜…â˜…â˜… 1. Charlieë‹˜ì´ ìš”ì²­í•œ ì‹ ê·œ CSS ì¶”ê°€ â˜…â˜…â˜…) */
/* Custom CSS for visual fidelity */
.border-container {
  border: 1px solid #e5e7eb;
  border-radius: 8px; /* rounded-lg */
  box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05); /* shadow-sm */
  padding: 1rem; /* p-4 */
  margin-bottom: 1rem; /* space-y-4 */
}

/* ìŒì‹ ì¶”ì²œ ì•„ì´í…œ ë‚´ë¶€ì˜ í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ */
.border-item {
  border: 1px solid #e5e7eb;
  border-radius: 8px;
  padding: 0.75rem; /* p-3 */
  margin-bottom: 0.75rem; /* space-y-3 */
}

/* ì‘ì€ í…ìŠ¤íŠ¸ + ë°°ê²½ (ìŒì‹ íƒìƒ‰ íƒ­ì˜ íƒœê·¸) */
.text-xs-bg {
  font-size: 0.75rem; /* text-xs */
  background-color: #f3f4f6; /* bg-gray-100 */
  border-radius: 4px;
  padding: 2px 8px;
  margin-right: 4px; /* (íƒœê·¸ ê°„ ê°„ê²©) */
  margin-bottom: 4px; /* (íƒœê·¸ ì¤„ë°”ê¿ˆ ì‹œ ê°„ê²©) */
  white-space: nowrap;
  display: inline-block;
}
/* (â˜…â˜…â˜… ì‹ ê·œ CSS ë â˜…â˜…â˜…) */
"""

with gr.Blocks(title="ê±°ê¸´ì–´ë•Œ", theme=gr.themes.Soft(), css=GRADIO_CSS) as gradio_app:
    gr.Markdown("## ê±°ê¸´ì–´ë•Œ")
    gr.Markdown("AIê°€ 13ê°€ì§€ í”„ë¡œí•„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì™„ë£Œë˜ë©´ ë§ì¶¤ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")

    with gr.Group():
        #gr.Markdown("### ğŸŒ ì–¸ì–´ ì„¤ì •")
        with gr.Row():
            lang_radio = gr.Radio(
                ["í•œêµ­ì–´ KR", "English US", "æ—¥æœ¬èª JP", "ä¸­æ–‡ CN"],
                label="ğŸŒ ì‚¬ìš© ì–¸ì–´ ì„ íƒ",
                value="í•œêµ­ì–´ KR",
                interactive=True,
            )

    # States
    llm_history_state = gr.State(value=[])
    profile_state = gr.State(value=config.PROFILE_TEMPLATE.copy())
    is_completed_state = gr.State(value=False)
    user_profile_row_state = gr.State(value=None)

    with gr.Tabs():
        with gr.TabItem("ğŸ½ ìŒì‹ íƒìƒ‰"):
            # ---- ì±„íŒ… ì˜ì—­ ----
            with gr.Group() as chat_group:
                with gr.Column():
                    chatbot = gr.Chatbot(
                        label="í•œêµ­ ì—¬í–‰ ë„ìš°ë¯¸ ì±—ë´‡",
                        height=700,
                        show_copy_button=True,
                        type="messages",
                    )
                    msg_textbox = gr.Textbox(
                        label="ë‹µë³€ ì…ë ¥",
                        placeholder="ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...",
                    )
                    # âœ… ê²°ê³¼ ë³´ê¸° ë²„íŠ¼ (ì±„íŒ… â†’ ê²°ê³¼ í™”ë©´ ì´ë™)
                    show_results_btn = gr.Button("âœ… ê²°ê³¼ ë³´ê¸°", variant="primary")

            # ---- ê²°ê³¼ ì˜ì—­ ----
            with gr.Group(visible=False) as result_group:
                profile_html = gr.HTML(label=None, value="")

                gr.HTML("<div class='controls-bar'><div id='ctrl-left' class='controls-left'></div><div id='ctrl-right' class='controls-right'></div></div>")
                with gr.Group(elem_id="ctrl-left"):
                    topk_slider = gr.Slider(
                        minimum=1, maximum=30, value=5, step=1, label="í‘œì‹œ ê°œìˆ˜ (Top-K)"
                    )
                with gr.Group(elem_id="ctrl-right"):
                    with gr.Row():
                        refresh_btn = gr.Button("ğŸ”® ì¶”ì²œ ìƒˆë¡œê³ ì¹¨", variant="secondary")
                        back_btn    = gr.Button("âœï¸ í”„ë¡œí•„ ìˆ˜ì •",  variant="secondary")

                recommendation_output = gr.HTML(label=None, value="") # (ìˆ˜ì •)
                
        with gr.TabItem("âš™ï¸ ì„¤ì •"):
            with gr.Column():
                gr.Markdown("### âš™ï¸ ì•± ì„¤ì • (ì˜ˆì‹œ)")
                gr.Markdown(
                    "- ë‚˜ì¤‘ì— ë²¡í„° DB ë¦¬ì…‹, ë””ë²„ê·¸ ì˜µì…˜, ëª¨ë¸ ì„ íƒ ë“±ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                    "- í˜„ì¬ëŠ” UI í‹€ë§Œ ë§Œë“¤ì–´ ë‘” ìƒíƒœì…ë‹ˆë‹¤."
                )
                rebuild_btn = gr.Button("ğŸ” ë²¡í„° DB ë‹¤ì‹œ ë¹Œë“œ (ì˜ˆì‹œ)")
                debug_checkbox = gr.Checkbox(label="ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (ì˜ˆì‹œ)", value=False)

                # ğŸ” ë””ë²„ê·¸ íŒ¨ë„
                debug_toggle = gr.Checkbox(label="ğŸ” ë””ë²„ê·¸ íŒ¨ë„ ë³´ê¸°", value=False)
                debug_profile_json = gr.JSON(label="profile_state(raw)", visible=False)
                debug_summary_text = gr.Textbox(label="inferred summary text", visible=False)
                debug_norm_json    = gr.JSON(label="normalized for card", visible=False)

    # ---- ì´ë²¤íŠ¸ ë°”ì¸ë”© ----

    # (A) í˜ì´ì§€ ë¡œë“œ
    gradio_app.load(
        fn=gradio_callbacks.start_chat,  # 5ê°œ ê°’ ë°˜í™˜
        inputs=None,
        outputs=[chatbot, llm_history_state, profile_state, is_completed_state, user_profile_row_state],
    )

    # (B) ì„¤ë¬¸/ì±„íŒ… ì§„í–‰
    async def chat_survey_handler(
        message: str,
        gradio_history: List[Dict],
        llm_history: List[Dict],
        current_profile: Dict,
        is_completed: bool,
        topk_value: int,
        user_profile_row: Dict,
        debug_on: bool
    ):
        (
            chatbot_out,
            llm_out,
            profile_out,
            is_completed_out,
            rec_md_out,
            upr_out,
        ) = await gradio_callbacks.chat_survey(
            message=message,
            gradio_history=gradio_history,
            llm_history=llm_history,
            current_profile=current_profile,
            is_completed=is_completed,
            topk_value=topk_value,
            user_profile_row_state=user_profile_row,
            http_client=app.state.http_client,
            graphhopper_url=config.GRAPH_HOPPER_API_URL,
        )

        # â˜… ìš”ì•½ë¬¸ ê°•ì œ ì£¼ì… (fallback)
        summary_text = _extract_summary_text(profile_out, chatbot_out, llm_out)
        profile_for_view = dict(profile_out or {})
        if summary_text and "summary" not in profile_for_view:
            profile_for_view["summary"] = summary_text

        # í™”ë©´ ì „í™˜/ì¹´ë“œ ë Œë”
        chat_group_vis   = gr.update(visible=not is_completed_out)
        result_group_vis = gr.update(visible=is_completed_out)
        profile_html_out = gr.update(value=render_profile_card(profile_for_view))

        # ë””ë²„ê·¸ íŒ¨ë„ ê°’
        norm_preview = normalize_profile(profile_for_view)
        vis = gr.update(visible=bool(debug_on))
        return (
            chatbot_out, llm_out, profile_out, is_completed_out,
            rec_md_out, upr_out,
            chat_group_vis, result_group_vis, profile_html_out,
            gr.update(value=profile_out, visible=bool(debug_on)),
            gr.update(value=summary_text, visible=bool(debug_on)),
            gr.update(value=norm_preview,  visible=bool(debug_on)),
        )

    msg_textbox.submit(
        fn=chat_survey_handler,
        inputs=[msg_textbox, chatbot, llm_history_state, profile_state, is_completed_state, topk_slider, user_profile_row_state, debug_toggle],
        outputs=[chatbot, llm_history_state, profile_state, is_completed_state, recommendation_output, user_profile_row_state, chat_group, result_group, profile_html, debug_profile_json, debug_summary_text, debug_norm_json],
    )
    msg_textbox.submit(lambda: "", inputs=None, outputs=msg_textbox)

    # (C) Top-K ë³€ê²½ ì‹œ ì¶”ì²œë§Œ ê°±ì‹ 
    def update_recommendations_with_topk_handler(topk_value: int, user_profile_row: Dict):
        return gradio_callbacks.update_recommendations_with_topk(
            topk_value=topk_value,
            user_profile_row_state=user_profile_row,
        )

    topk_slider.change(
        fn=update_recommendations_with_topk_handler,
        inputs=[topk_slider, user_profile_row_state],
        outputs=recommendation_output,
    )

    refresh_btn.click(
        fn=update_recommendations_with_topk_handler,
        inputs=[topk_slider, user_profile_row_state],
        outputs=recommendation_output,
    )

    # (D) ë””ë²„ê·¸ í† ê¸€: í‘œì‹œë§Œ í† ê¸€
    def _toggle_debug(v: bool):
        return gr.update(visible=v), gr.update(visible=v), gr.update(visible=v)
    debug_toggle.change(_toggle_debug, inputs=[debug_toggle], outputs=[debug_profile_json, debug_summary_text, debug_norm_json])

    # (E) ë’¤ë¡œê°€ê¸°(í”„ë¡œí•„ ìˆ˜ì •): ê²°ê³¼â†’ì±„íŒ…
    def back_to_chat():
        return gr.update(visible=True), gr.update(visible=False), False
    back_btn.click(fn=back_to_chat, inputs=None, outputs=[chat_group, result_group, is_completed_state])

    # (F) âœ… ê²°ê³¼ ë³´ê¸°: ì±„íŒ…â†’ê²°ê³¼ (ìš”ì•½ ì£¼ì… + ì¹´ë“œ ê°±ì‹  í¬í•¨)
    def show_results_from_chat_handler(current_profile: Dict, user_profile_row: Dict, topk_value: int, chatbot_hist: List[Dict], llm_hist: List[Dict]):
        rec_md = update_recommendations_with_topk_handler(topk_value, user_profile_row)
        # ìš”ì•½ ì£¼ì…
        summary_text = _extract_summary_text(current_profile, chatbot_hist, llm_hist)
        profile_for_view = dict(current_profile or {})
        if summary_text and "summary" not in profile_for_view:
            profile_for_view["summary"] = summary_text
        return (
            gr.update(visible=False),                                   # chat_group ìˆ¨ê¹€
            gr.update(visible=True),                                    # result_group í‘œì‹œ
            gr.update(value=render_profile_card(profile_for_view)),     # í”„ë¡œí•„ ì¹´ë“œ
            rec_md,                                                     # ì¶”ì²œ ê²°ê³¼
            True                                                        # is_completed_state = True
        )

    show_results_btn.click(
        fn=show_results_from_chat_handler,
        inputs=[profile_state, user_profile_row_state, topk_slider, chatbot, llm_history_state],
        outputs=[chat_group, result_group, profile_html, recommendation_output, is_completed_state],
    )


# ========= 5) ë§ˆìš´íŠ¸ =========
app = gr.mount_gradio_app(
    app,
    gradio_app,
    path="/chatbot",
    app_kwargs={
        "title": "Gradio App on FastAPI",
        "description": "Gradio app is mounted at /chatbot",
    },
)


# ========= 6) ì‹¤í–‰ =========
if __name__ == "__main__":
    uvicorn.run(
        "app_main:app",
        host="127.0.0.1",
        port=8080,
        reload=True,
    )
