import uvicorn
import httpx
import asyncio
from contextlib import asynccontextmanager
from typing import List, Dict, Any, Tuple
import pandas as pd

from fastapi import FastAPI, HTTPException
import gradio as gr

# ëª¨ë“ˆ ì„í¬íŠ¸
import config
import data_loader
import llm_utils
import gradio_callbacks # (Gradio ì½œë°± í•¨ìˆ˜)
import search_logic
from API import final_scorer # (ì‚¬ì¥ë‹˜ ë¡œì§)
from models import RecommendationRequest, RecommendationResponse

# --- 1. FastAPI ì•± ë° Lifespan (ì„œë²„ ì‹œì‘/ì¢…ë£Œ) ---

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ì‹¤í–‰"""
    print("--- ì„œë²„ ì‹œì‘: Lifespan ì‹œì‘ ---")
    
    # 1. (í•„ìˆ˜) API í‚¤ ë¡œë“œ í™•ì¸
    if not config.client or not config.client.api_key:
        print("[ì¹˜ëª…ì  ì˜¤ë¥˜] OPENAI_API_KEYê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        # (ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” ì—¬ê¸°ì„œ exit() ë˜ëŠ” raise)
    else:
        print("  > OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ.")

    # 2. (í•„ìˆ˜) GraphHopper ì—°ê²°ìš© HTTP í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    # (final_scorerê°€ API í˜¸ì¶œ ì‹œ ì´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¬ì‚¬ìš©)
    app.state.http_client = httpx.AsyncClient()
    print("  > HTTPX AsyncClient ìƒì„± ì™„ë£Œ.")

    # 3. (í•„ìˆ˜) ëª¨ë“  CSV ë° VectorDB ë¡œë“œ
    # (data_loader.pyì˜ ì „ì—­ ë³€ìˆ˜ë“¤ì´ ì±„ì›Œì§)
    try:
        data_loader.load_app_data(
            config.RESTAURANT_DB_FILE, 
            config.MENU_DB_FILE
        )
        data_loader.load_user_ratings()
        data_loader.build_vector_db(
            config.RESTAURANT_DB_FILE,
            config.PROFILE_DB_FILE,
            config.CLEAR_DB_AND_REBUILD
        )
        
        # 4. (í•„ìˆ˜) /recommendations APIìš© ìŠ¤ì½”ì–´ë§ DB ë¡œë“œ
        # (ì´ ë°ì´í„°ë¥¼ app.stateì— ì €ì¥ -> /recommendationsê°€ ì‚¬ìš©)
        app.state.all_restaurants_df_scoring = data_loader.load_scoring_data(
            config.RESTAURANT_DB_SCORING_FILE
        )
        
        print("  > ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
        
    except Exception as e:
        print(f"[ì¹˜ëª…ì  ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        # (ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” ì—¬ê¸°ì„œ exit() ë˜ëŠ” raise)

    print("--- ì„œë²„ ì‹œì‘ ì™„ë£Œ ---")
    
    yield # (ì„œë²„ ì‹¤í–‰)
    
    # --- ì„œë²„ ì¢…ë£Œ ì‹œ ---
    print("--- ì„œë²„ ì¢…ë£Œ: Lifespan ì¢…ë£Œ ---")
    await app.state.http_client.aclose()
    print("  > HTTPX AsyncClient ì¢…ë£Œ.")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="FastAPI + Gradio í†µí•© ì¶”ì²œ ì„œë²„",
    description="ì±—ë´‡ ì„œë² ì´ì™€ 2ë‹¨ê³„ 'ëšœë²…ì´' ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ í†µí•©",
    lifespan=lifespan
)

# --- 2. (ê¸°ì¡´) /recommendations ì—”ë“œí¬ì¸íŠ¸ ---
# (ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì±—ë´‡ê³¼ 'ë…ë¦½ì 'ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤)

@app.post(
    "/recommendations", 
    response_model=RecommendationResponse,
    tags=["2-Stage Scorer (final_scorer)"]
)
async def get_recommendations(request: RecommendationRequest):
    """
    (ì±—ë´‡ê³¼ ë¬´ê´€) 1ë‹¨ê³„ í›„ë³´êµ° 150ê°œë¥¼ 'ëœë¤'ìœ¼ë¡œ ìƒì„±í•˜ê³ 
    'final_scorer' ë¡œì§ì„ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if app.state.all_restaurants_df_scoring is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì¤‘ (ìŠ¤ì½”ì–´ë§ DB ë¡œë“œ ì‹¤íŒ¨)")

    # 1. 1ë‹¨ê³„ í›„ë³´êµ° ìƒì„± (ëœë¤ ìƒ˜í”Œë§)
    try:
        candidate_df = app.state.all_restaurants_df_scoring.sample(n=request.n_results)
    except ValueError:
        # (DBê°€ 150ê°œë³´ë‹¤ ì ì„ ê²½ìš°)
        candidate_df = app.state.all_restaurants_df_scoring.copy()

    # 2. 2ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ ì‹¤í–‰ (final_scorer.py í˜¸ì¶œ)
    try:
        final_scored_df = await final_scorer.calculate_final_scores_async(
            candidate_df=candidate_df,
            user_start_location=request.user_start_location,
            user_price_prefs=request.user_price_prefs,
            async_http_client=app.state.http_client, # (Lifespanì—ì„œ ìƒì„±í•œ í´ë¼ì´ì–¸íŠ¸ ì£¼ì…)
            graphhopper_url=config.GRAPH_HOPPER_API_URL
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"2ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨: {e}")
        
    # 3. Pydantic ëª¨ë¸ì— ë§ì¶° ê²°ê³¼ ë°˜í™˜
    results = final_scored_df.reset_index().to_dict('records')
    return RecommendationResponse(
        recommendations=results,
        total_count=len(results)
    )

# --- 3. (ì‹ ê·œ) Gradio ì±—ë´‡ UI --- 

with gr.Blocks(theme=gr.themes.Soft()) as gradio_app:
    gr.Markdown("# ê¸¸ë”°ë¼ ë§›ë”°ë¼")
    gr.Markdown("AIê°€ 13ê°€ì§€ í”„ë¡œí•„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì™„ë£Œë˜ë©´ ë§ì¶¤ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")

    # ğŸŒ ì–¸ì–´ ì„¤ì • (UIë§Œ, ì•„ì§ ë¡œì§ì€ ì‚¬ìš© X)
    with gr.Group():
        gr.Markdown("### ğŸŒ ì–¸ì–´ ì„¤ì •")
        with gr.Row():
            lang_radio = gr.Radio(
                ["í•œêµ­ì–´ KR", "English US", "æ—¥æœ¬èª JP", "ä¸­æ–‡ CN"],
                label="ì‚¬ìš© ì–¸ì–´ ì„ íƒ",
                value="í•œêµ­ì–´ KR",
                interactive=True
            )

    # â”€â”€ Gradio State ë³€ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    llm_history_state = gr.State(value=[])
    profile_state = gr.State(value=config.PROFILE_TEMPLATE.copy())
    is_completed_state = gr.State(value=False)
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš© í”„ë¡œí•„ Row (ë„¤ê°€ ë§Œë“  user_profile_row_state)
    user_profile_row_state = gr.State(value=None)

    with gr.Tabs():
        # [íƒ­ 1] ìŒì‹ íƒìƒ‰
        with gr.TabItem("ğŸ½ ìŒì‹ íƒìƒ‰"):
            with gr.Column():
                chatbot = gr.Chatbot(
                    label="ì„œë² ì´ ì±—ë´‡",
                    height=700,
                    show_copy_button=True,
                    type="messages",
                )

                msg_textbox = gr.Textbox(
                    label="ë‹µë³€ ì…ë ¥",
                    placeholder="ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...",
                )

                # ì±—ë´‡ ì•„ë˜ ë§ì¶¤ ì¶”ì²œ ê²°ê³¼ íƒ­
                with gr.Tabs():
                    with gr.TabItem("ğŸŒŸ ë§ì¶¤ ì¶”ì²œ ê²°ê³¼"):
                        topk_slider = gr.Slider(
                            minimum=1,
                            maximum=30,
                            value=5,
                            step=1,
                            label="í‘œì‹œ ê°œìˆ˜ (Top-K)",
                        )
                        recommendation_output = gr.Markdown(
                            label="ì¶”ì²œ ê²°ê³¼",
                            value="...í”„ë¡œí•„ ì„¤ë¬¸ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤...",
                            visible=False,
                        )

        # [íƒ­ 2] ì„¤ì •
        with gr.TabItem("âš™ï¸ ì„¤ì •"):
            with gr.Column():
                gr.Markdown("### âš™ï¸ ì•± ì„¤ì • (ì˜ˆì‹œ)")
                gr.Markdown(
                    "- ì´ íƒ­ì—ëŠ” ë‚˜ì¤‘ì— ë²¡í„° DB ë¦¬ì…‹, ë””ë²„ê·¸ ì˜µì…˜, ëª¨ë¸ ì„ íƒ ë“±ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                    "- í˜„ì¬ëŠ” UI í‹€ë§Œ ë§Œë“¤ì–´ ë‘” ìƒíƒœì…ë‹ˆë‹¤."
                )
                rebuild_btn = gr.Button("ğŸ” ë²¡í„° DB ë‹¤ì‹œ ë¹Œë“œ (ì˜ˆì‹œ)")
                debug_checkbox = gr.Checkbox(label="ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (ì˜ˆì‹œ)", value=False)

    # --- 4.  Gradio ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²° ---

    # (A) ì•±ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ
    gradio_app.load(
        fn=gradio_callbacks.start_chat,  # ë°˜ë“œì‹œ 5ê°œ ê°’ ë¦¬í„´í•˜ë„ë¡ êµ¬í˜„
        inputs=None,
        outputs=[
            chatbot,
            llm_history_state,
            profile_state,
            is_completed_state,
            user_profile_row_state, 
        ],
    )

    # (B) ì‚¬ìš©ìê°€ Enter(submit)ë¥¼ ëˆ„ë¥¼ ë•Œ
    async def chat_survey_handler(
        message: str,
        gradio_history: List[Dict],
        llm_history: List[Dict],
        current_profile: Dict,
        is_completed: bool,
        topk_value: int,
        user_profile_row: Dict,
    ) -> Tuple[
        List[Dict],  # chatbot history
        List[Dict],  # llm_history_state
        Dict,        # profile_state
        bool,        # is_completed_state
        gr.update,   # recommendation_output
        Dict,        # user_profile_row_state
    ]:
        """
        Gradioì—ì„œ ë„˜ì–´ì˜¨ ì…ë ¥ + ìƒíƒœ + Top-K ê°’ì„
        gradio_callbacks.chat_surveyì— ë„˜ê²¨ì£¼ëŠ” í•¸ë“¤ëŸ¬.
        (app.stateì˜ http_client, GRAPH_HOPPER_URLë„ ê°™ì´ ì£¼ì…)
        """
        return await gradio_callbacks.chat_survey(
            message=message,
            gradio_history=gradio_history,
            llm_history=llm_history,
            current_profile=current_profile,
            is_completed=is_completed,
            topk_value=topk_value,
            user_profile_row_state=user_profile_row,
            http_client=app.state.http_client,
            graphhopper_url=config.GRAPH_HOPPER_API_URL,
        )

    msg_textbox.submit(
        fn=chat_survey_handler,
        inputs=[
            msg_textbox,
            chatbot,
            llm_history_state,
            profile_state,
            is_completed_state,
            topk_slider,
            user_profile_row_state,
        ],
        outputs=[
            chatbot,
            llm_history_state,
            profile_state,
            is_completed_state,
            recommendation_output,
            user_profile_row_state,
        ],
    )

    # (C) Enter ëˆ„ë¥¸ í›„ í…ìŠ¤íŠ¸ë°•ìŠ¤ ë¹„ìš°ê¸°
    msg_textbox.submit(lambda: "", inputs=None, outputs=msg_textbox)

    # (D) Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì‹œ ì¶”ì²œ ì¬ê³„ì‚°
    def update_recommendations_with_topk_handler(topk_value: int, user_profile_row: Dict):
        """
        Top-K ê°’ì´ ë°”ë€” ë•Œë§ˆë‹¤, í˜„ì¬ user_profile_row_stateë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ì¶”ì²œ ê²°ê³¼ë§Œ ë‹¤ì‹œ ê³„ì‚°í•´ì„œ Markdownì„ ì—…ë°ì´íŠ¸.
        (ì‹¤ì œ ë¡œì§ì€ gradio_callbacks.update_recommendations_with_topk ì— êµ¬í˜„)
        """
        return gradio_callbacks.update_recommendations_with_topk(
            topk_value=topk_value,
            user_profile_row_state=user_profile_row,
        )

    topk_slider.change(
        fn=update_recommendations_with_topk_handler,
        inputs=[topk_slider, user_profile_row_state],
        outputs=recommendation_output,
    )

# --- 5. FastAPI ì•±ì— Gradio UI ë§ˆìš´íŠ¸ --- 
app = gr.mount_gradio_app(
    app,
    gradio_app,
    path="/chatbot",
    app_kwargs={
        "title": "Gradio App on FastAPI",
        "description": "Gradio app is mounted at /chatbot",
    },
)

# --- 6. ì„œë²„ ì‹¤í–‰ --- 
if __name__ == "__main__":
    uvicorn.run(
        "app_main:app",
        host="127.0.0.1",
        port=8080,
        reload=True,
    )