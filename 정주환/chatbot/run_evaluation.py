# run_evaluation.py (ìµœì¢… ìˆ˜ì •ë³¸: P@K/R@K í•¨ìˆ˜ ì¶”ê°€ ë° [Dict] ì˜¤ë¥˜ ìˆ˜ì •)

import pandas as pd
import numpy as np
import asyncio
import httpx
import json
import os
from typing import List, Set, Dict, Any

# --- Plotly ì‹œê°í™” ëª¨ë“ˆ ì„í¬íŠ¸ ---
try:
  import plotly.graph_objects as go
  import plotly.io as pio
  pio.templates.default = "plotly_white"
except ImportError:
  print("[ê²½ê³ ] Plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œê°í™”(ì´ë¯¸ì§€ ì €ì¥)ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
  print("pip install plotly kaleido")
  go, pio = None, None

# --- ì œê³µëœ ì†ŒìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸ ---
try:
  import config
  import data_loader
  import search_logic
  import llm_utils
  from llm_utils import extract_profile_from_summary 
  import gradio_callbacks
  from API import final_scorer
  from API.final_scorer import GraphHopperDownError
except ImportError as e:
  print(f"ì˜¤ë¥˜: í•„ìˆ˜ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨. '{e.name}' ëª¨ë“ˆì´ ì—†ê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
  exit()
  
# [!!!] ì´ í•œ ì¤„ì„ ì—¬ê¸°ì— ì¶”ê°€í•˜ì„¸ìš” [!!!]
os.environ["TOKENIZERS_PARALLELISM"] = "false"  
  
# (ìºì‹œ ë””ë ‰í† ë¦¬)
CACHE_DIR = "evaluation_cache"
os.makedirs(CACHE_DIR, exist_ok=True)


# ==================================================================
# [!!! ìˆ˜ì • 1: ëˆ„ë½ëœ í‰ê°€ í•¨ìˆ˜ 2ê°œ ì¶”ê°€ !!!]
# ==================================================================

def calculate_precision_k(recommendations: List[str], ground_truth: Set[str], k: int) -> float:
  """ Precision@K (ì •ë°€ë„) ê³„ì‚° """
  if not ground_truth: 
    return 0.0 
  
  top_k_recs = recommendations[:k]
  if not top_k_recs: 
    return 0.0 # (ì¶”ì²œì´ 0ê°œë©´ 0ì )
  
  relevant_set = ground_truth
  hits = sum(1 for item in top_k_recs if item in relevant_set)
  
  # [!!! ë¡œì§ ìˆ˜ì • !!!] (P@Kì˜ ë¶„ëª¨ëŠ” í•­ìƒ K)
  return hits / k

def calculate_recall_k(recommendations: List[str], ground_truth: Set[str], k: int) -> float:
  """ Recall@K (ì¬í˜„ìœ¨) ê³„ì‚° """
  if not ground_truth or len(ground_truth) == 0: 
    return 0.0 
    
  top_k_recs = recommendations[:k]
  relevant_set = ground_truth
  hits = sum(1 for item in top_k_recs if item in relevant_set)
  
  # [!!! ë¡œì§ ìˆ˜ì • !!!] (R@Kì˜ ë¶„ëª¨ëŠ” ì „ì²´ ì •ë‹µ ê°œìˆ˜)
  return hits / len(relevant_set)

# ==================================================================
# 2. Ground Truth ë¡œë“œ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
# ==================================================================

def load_ground_truth(csv_path: str) -> Dict[str, Set[str]]:
  print(f"\n--- [Ground Truth] '{csv_path}' ë¡œë“œ ì¤‘ ---")
  try:
    df = pd.read_csv(csv_path)
    df_truth = df[df['ì‚¬ìš©ìí‰ê°€'] == 'ì¶”ì²œ']
    ground_truth_map = df_truth.groupby('user_id')['restaurant_id'].apply(
      lambda x: set(x.astype(str))
    )
    print(f"[Ground Truth] ì •ë‹µ ì…‹ ë¡œë“œ ì™„ë£Œ (ì´ {len(ground_truth_map)}ëª…)")
    return ground_truth_map.to_dict()
  except Exception as e:
    print(f"[ì˜¤ë¥˜] Ground Truth ë¡œë“œ ì‹¤íŒ¨: {e}")
    return {}

# ==================================================================
# [!!! ìˆ˜ì • 3: '[Dict]' ì˜¤ë¥˜ í•´ê²° !!!]
# ==================================================================
async def run_single_user_recommendation(
    user_row: pd.Series,
    ground_truth_map: Dict[str, Set[str]],
    http_client: httpx.AsyncClient,
    k: int
) -> Dict[str, Any]:
  
  user_id = str(user_row['id'])
  summary_text = user_row['summary_text']
  ground_truth_set = ground_truth_map.get(user_id, set())
  
  try:
    # --- [A] LLM í”„ë¡œí•„ ì—­ì¶”ì¶œ ---
    profile_data = extract_profile_from_summary(summary_text)
    
    if not profile_data or not profile_data.get("start_location"):
      return {
        "user_id": user_id, f"precision_at_{k}": 0.0, f"recall_at_{k}": 0.0,
        "ground_truth_size": len(ground_truth_set), "live_recs_count": 0,
        "error": "LLM profile extraction failed"
      }

    # --- [B] 1ë‹¨ê³„: RAG + ì ìˆ˜ì œ ---
    filter_dict = search_logic.create_filter_metadata(profile_data)
    user_profile_row = {
      "rag_query_text": summary_text,
      "filter_metadata_json": json.dumps(filter_dict, ensure_ascii=False)
    }
    
    # [!!! 1. ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ê¸° !!!]
    candidate_results = search_logic.get_rag_candidate_ids(
        user_profile_row, 
        n_results=config.RAG_REQUEST_N_RESULTS
    )
    
    live_recs_ids = []
    if not candidate_results:
      live_recs_ids = [] # (ê²°ê³¼ 0ê±´)
    else:
      # [!!! 2. ID ë¦¬ìŠ¤íŠ¸ì™€ ì ìˆ˜ ë§µ ë¶„ë¦¬ !!!]
      candidate_ids = [item['id'] for item in candidate_results]
      # (run_evaluation.pyëŠ” 1ë‹¨ê³„ ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ scores_mapì€ í•„ìš” ì—†ìŒ)
      
      # --- [C] 2ë‹¨ê³„: final_scorer ---
      try:
        # [!!! 3. ì˜¬ë°”ë¥¸ ID ë¦¬ìŠ¤íŠ¸ ì „ë‹¬ !!!]
        candidate_df = data_loader.get_restaurants_by_ids(candidate_ids)
        
        user_start_location_name = profile_data.get("start_location")
        user_budget_pref_str = profile_data.get("budget")
        user_start_coords = gradio_callbacks.get_start_location_coords(user_start_location_name)
        user_price_prefs = gradio_callbacks.budget_mapper(user_budget_pref_str)

        final_scored_df = await final_scorer.calculate_final_scores_async(
            candidate_df=candidate_df,
            user_start_location=user_start_coords,
            user_price_prefs=user_price_prefs,
            async_http_client=http_client,
            graphhopper_url=config.GRAPH_HOPPER_API_URL,
        )
        live_recs_ids = final_scored_df.index.astype(str).tolist()

      except GraphHopperDownError as e:
        print(f"  > [ê²½ê³ ] User {user_id}: 2ë‹¨ê³„ Scorer ì‹¤íŒ¨ ({e}). 1ë‹¨ê³„ RAGë¡œ ëŒ€ì²´.")
        live_recs_ids = candidate_ids # (1ë‹¨ê³„ Fallback)
      except Exception as e:
        print(f"  > [ê²½ê³ ] User {user_id}: 2ë‹¨ê³„ Scorer ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ({e}). 1ë‹¨ê³„ RAGë¡œ ëŒ€ì²´.")
        live_recs_ids = candidate_ids # (1ë‹¨ê³„ Fallback)

    # (ë””ë²„ê¹… ë¡œê·¸ - ê¸°ì¡´ ì½”ë“œ)
    print(f"\n  > [ë””ë²„ê·¸: {user_id}]")
    print(f"  > 1. ì •ë‹µ (Ground Truth): {ground_truth_set}")
    print(f"  > 2. ì‹¤ì‹œê°„ ì¶”ì²œ (Live Top {k}): {live_recs_ids[:k]}")
    
    # (P@K, R@K í•¨ìˆ˜ í˜¸ì¶œ - ì´ì œ NameError ì•ˆ ë‚¨)
    precision = calculate_precision_k(live_recs_ids, ground_truth_set, k)
    recall = calculate_recall_k(live_recs_ids, ground_truth_set, k)
    
    print(f"  > 3. ê²°ê³¼: P@{k}={precision:.2f}, R@{k}={recall:.2f}")

    return {
      "user_id": user_id,
      f"precision_at_{k}": precision,
      f"recall_at_{k}": recall,
      "ground_truth_size": len(ground_truth_set),
      "live_recs_count": len(live_recs_ids),
      "error": None
    }
    
  except Exception as e:
    return { "user_id": user_id, "error": str(e) }

# ==================================================================
# 4. Plotly ì‹œê°í™” ì €ì¥ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
# ==================================================================
def save_result_visualizations(df: pd.DataFrame, p_col: str, r_col: str, k: int):
  if go is None:
    print("\n[ì‹œê°í™”] Plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì°¨íŠ¸ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    return
  print(f"\n[ì‹œê°í™”] Plotly ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  .png íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
  try:
    fig_p = go.Figure(data=[go.Histogram(x=df[p_col], nbinsx=20, marker_color='#FF7600')])
    fig_p.update_layout(title_text=f'<b>Precision@{k} ë¶„í¬ (N={len(df)})</b>', xaxis_title_text='Precision@K', yaxis_title_text='ì‚¬ìš©ì ìˆ˜ (Count)')
    fig_p.write_image(f"evaluation_precision_at_{k}_histogram.png", width=800, height=500)
    print(f"  > 'evaluation_precision_at_{k}_histogram.png' ì €ì¥ ì™„ë£Œ")
    
    fig_r = go.Figure(data=[go.Histogram(x=df[r_col], nbinsx=20, marker_color='#007BFF')])
    fig_r.update_layout(title_text=f'<b>Recall@{k} ë¶„í¬ (N={len(df)})</b>', xaxis_title_text='Recall@K', yaxis_title_text='ì‚¬ìš©ì ìˆ˜ (Count)')
    fig_r.write_image(f"evaluation_recall_at_{k}_histogram.png", width=800, height=500)
    print(f"  > 'evaluation_recall_at_{k}_histogram.png' ì €ì¥ ì™„ë£Œ")
    
    fig_box = go.Figure()
    fig_box.add_trace(go.Box(y=df[p_col], name=f'Precision@{k}', marker_color='#FF7600'))
    fig_box.add_trace(go.Box(y=df[r_col], name=f'Recall@{k}', marker_color='#007BFF'))
    fig_box.update_layout(title_text=f'<b>í‰ê°€ ì§€í‘œ Box Plot (N={len(df)})</b>')
    fig_box.write_image(f"evaluation_metrics_boxplot.png", width=800, height=600)
    print(f"  > 'evaluation_metrics_boxplot.png' ì €ì¥ ì™„ë£Œ")
  except Exception as e:
    print(f"[ì˜¤ë¥˜] Plotly ì°¨íŠ¸ ìƒì„±/ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("      (Kaleidoê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”)")

# ==================================================================
# 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Charlieë‹˜ì´ ì£¼ì‹  'ì´ì „' ìºì‹œ ë¡œì§)
# ==================================================================
async def main_evaluation():
  
  # --- [ 1. ì„¤ì • ë³€ìˆ˜ ] ---
  MAX_USERS_TO_TEST = None
  K_VALUE = 10
  CONCURRENT_LIMIT = 1 
  
  PROFILES_CSV_PATH = './data/user_profiles_combined.csv'
  GROUND_TRUTH_CSV_PATH = './data/recommendation_results_with_ratings.csv'
  
  CACHE_DIR = "evaluation_cache"
  FINAL_CSV_OUTPUT = "final_evaluation_metrics_all.csv"
  
  os.makedirs(CACHE_DIR, exist_ok=True)
  
  # --- [ 2. ë°ì´í„° ë¡œë“œ ] ---
  print("--- [1/5] ì„œë²„ ë°ì´í„° ë¡œë“œ ì‹œì‘ ---")
  try:
    data_loader.load_app_data(config.RESTAURANT_DB_FILE_ALL, config.MENU_DB_FILE)
    if not config.client or not config.client.api_key:
      print("[ì¹˜ëª…ì  ì˜¤ë¥˜] OpenAI API í‚¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
      return
    print("  > OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ.")
    data_loader.build_vector_db(
        config.RESTAURANT_DB_FILE_ALL, config.PROFILE_DB_FILE, config.CLEAR_DB_AND_REBUILD
    )
    data_loader.load_scoring_data(config.RESTAURANT_DB_SCORING_FILE)
    print("--- [1/5] ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ ---")
  except Exception as e:
    print(f"[ì¹˜ëª…ì  ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    return

  ground_truth_map = load_ground_truth(GROUND_TRUTH_CSV_PATH)
  if not ground_truth_map:
    print("[ì¹˜ëª…ì  ì˜¤ë¥˜] Ground Truthê°€ ì—†ìŠµë‹ˆë‹¤.")
    return

  print(f"\n--- [2/5] '{PROFILES_CSV_PATH}' ë¡œë“œ ì¤‘ ---")
  try:
    profiles_df_all = pd.read_csv(PROFILES_CSV_PATH, dtype={'id': str})
    
    if MAX_USERS_TO_TEST is not None:
      print(f"  > [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] {MAX_USERS_TO_TEST}ëª…ë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
      profiles_df = profiles_df_all.head(MAX_USERS_TO_TEST).copy()
    else:
      print(f"  > [ì „ì²´ ì‹¤í–‰ ëª¨ë“œ] {len(profiles_df_all)}ëª… ì „ì²´ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
      profiles_df = profiles_df_all
      
  except FileNotFoundError:
    print(f"[ì¹˜ëª…ì  ì˜¤ë¥˜] '{PROFILES_CSV_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return
  
  # --- [ 3. ìºì‹œ í™•ì¸ (ì´ì „ ë°©ì‹) ] ---
  print(f"\n--- [3/5] ìºì‹œ í™•ì¸ ë° ì‹¤í–‰ ëª©ë¡ ìƒì„± ---")
  
  tasks = []
  cached_results = []
  users_to_run_rows = [] 

  for _, user_row in profiles_df.iterrows():
    user_id = str(user_row['id'])
    
    # (ì´ì „ ìºì‹œ íŒŒì¼ ì´ë¦„: {user_id}.json)
    cache_file = os.path.join(CACHE_DIR, f"{user_id}.json")
    
    if os.path.exists(cache_file):
      try:
        with open(cache_file, 'r', encoding='utf-8') as f:
          cached_results.append(json.load(f))
      except:
        users_to_run_rows.append(user_row)
    else:
      users_to_run_rows.append(user_row)

  print(f"  > ì´ {len(profiles_df)}ëª… ì¤‘ {len(cached_results)}ëª… ìºì‹œ ë¡œë“œ, {len(users_to_run_rows)}ëª… ìƒˆë¡œ ì‹¤í–‰.")

  # --- [ 4. ë¹„ë™ê¸° í‰ê°€ ì‹¤í–‰ (ì´ì „ ë°©ì‹) ] ---
  newly_completed_results = []
  
  if users_to_run_rows:
    print(f"\n--- [4/5] {len(users_to_run_rows)}ëª… í‰ê°€ ì‹œì‘ (ë™ì‹œì„±={CONCURRENT_LIMIT}) ---")
    
    async with httpx.AsyncClient(timeout=10.0) as http_client:
      semaphore = asyncio.Semaphore(CONCURRENT_LIMIT)
      
      async def limited_task(user_row, index):
        user_id = user_row['id']
        print(f"  > ì‹œì‘ ( {index + 1} / {len(users_to_run_rows)} ) : User {user_id}")
        
        async with semaphore:
          # (ìˆ˜ì •ëœ run_single_user_recommendation í˜¸ì¶œ)
          result = await run_single_user_recommendation(
            user_row, ground_truth_map, http_client, K_VALUE
          )
        
        if isinstance(result, dict) and result.get("error") is None:
          # (ì´ì „ ìºì‹œ íŒŒì¼ ì´ë¦„: {user_id}.json)
          cache_file = os.path.join(CACHE_DIR, f"{user_id}.json")
          try:
            with open(cache_file, 'w', encoding='utf-8') as f:
              json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"  > ì™„ë£Œ/ì €ì¥ ( {index + 1} / {len(users_to_run_rows)} ) : User {user_id}")
          except Exception as e:
            print(f"  > ì™„ë£Œ/ì €ì¥ì‹¤íŒ¨ ( {index + 1} ) : User {user_id} (ì´ìœ : {e})")
        else:
          error_msg = result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜") if isinstance(result, dict) else str(result)
          print(f"  > ì‹¤íŒ¨ ( {index + 1} / {len(users_to_run_rows)} ) : User {user_id} (ì´ìœ : {error_msg})")
          
        return result

      tasks = [limited_task(row, i) for i, row in enumerate(users_to_run_rows)]
      new_results_raw = await asyncio.gather(*tasks, return_exceptions=True)

    for r in new_results_raw:
      if isinstance(r, dict) and r.get("error") is None:
        newly_completed_results.append(r)

  else:
    print("\n--- [4/5] ìƒˆë¡œ ì‹¤í–‰í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ìºì‹œë¨) ---")

  # --- [ 5. ìµœì¢… ê²°ê³¼ ì·¨í•© ë° í†µê³„ (ë³€ê²½ ì—†ìŒ) ] ---
  print("\n--- [5/5] í‰ê°€ ì™„ë£Œ. ìµœì¢… í†µê³„ ê³„ì‚° ì¤‘ ---")

  all_success_results = cached_results + newly_completed_results

  if not all_success_results:
    print("[ì˜¤ë¥˜] ì„±ê³µí•œ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í†µê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return

  df_metrics = pd.DataFrame(all_success_results)
  try:
    df_metrics.to_csv(FINAL_CSV_OUTPUT, index=False, encoding='utf-8-sig')
    print(f"\n[ì„±ê³µ] ìµœì¢… í‰ê°€ ê²°ê³¼ê°€ '{FINAL_CSV_OUTPUT}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
  except Exception as e:
    print(f"\n[ì˜¤ë¥˜] ìµœì¢… CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

  p_col = f'precision_at_{K_VALUE}'
  r_col = f'recall_at_{K_VALUE}'
  
  p_stats = df_metrics[p_col].describe()
  p_var = df_metrics[p_col].var()
  r_stats = df_metrics[r_col].describe()
  r_var = df_metrics[r_col].var()
  
  print("\n" + "="*50)
  print(f"ğŸ“Š 'Live' ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì „ì²´ í‰ê°€ í†µê³„ (K={K_VALUE})")
  print(f"(ì´ {len(all_success_results)}ëª… ì„±ê³µ / {len(profiles_df) - len(all_success_results)}ëª… ì‹¤íŒ¨ ë˜ëŠ” ëˆ„ë½)")
  print("="*50)
  
  stats_df = pd.DataFrame({ p_col: p_stats, r_col: r_stats })
  stats_df.loc['variance'] = [p_var, r_var]
  stats_df = stats_df.rename(index={
      'count': 'ê°œìˆ˜ (count)', 'mean': 'í‰ê·  (mean)', 'std': 'í‘œì¤€í¸ì°¨ (std)',
      '50%': 'ì¤‘ìœ„ê°’ (median)', 'min': 'ìµœì†Œê°’ (min)', '25%': '25% (Q1)',
      '75%': '75% (Q3)', 'max': 'ìµœëŒ€ê°’ (max)', 'variance': 'ë¶„ì‚° (variance)'
  })
  
  final_order = [
      'ê°œìˆ˜ (count)', 'í‰ê·  (mean)', 'ë¶„ì‚° (variance)', 'í‘œì¤€í¸ì°¨ (std)', 
      'ì¤‘ìœ„ê°’ (median)', 'ìµœì†Œê°’ (min)', '25% (Q1)', '75% (Q3)', 'ìµœëŒ€ê°’ (max)'
  ]
  
  printable_order = [idx for idx in final_order if idx in stats_df.index]
  print(stats_df.loc[printable_order])
  print("-" * 50)
  print(f"ì°¸ê³ : ì‚¬ìš©ìë‹¹ í‰ê·  ì •ë‹µ('ì¶”ì²œ') ê°œìˆ˜: {df_metrics['ground_truth_size'].mean():.2f} ê°œ")
  
  save_result_visualizations(df_metrics, p_col, r_col, K_VALUE)


# ==================================================================
# 6. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# ==================================================================
if __name__ == "__main__":
  print("í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ìºì‹œ ê¸°ëŠ¥ í¬í•¨)...")
  
  if os.name == 'nt':
    try:
      asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    except:
      print("[ì •ë³´] WindowsSelectorEventLoopPolicy ì„¤ì • ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰)")
      
  asyncio.run(main_evaluation())
  
  
  
"""
==================================================
ğŸ“Š 'Live' ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì „ì²´ í‰ê°€ í†µê³„ (K=10)
(ì´ 500ëª… ì„±ê³µ / 0ëª… ì‹¤íŒ¨ ë˜ëŠ” ëˆ„ë½)
==================================================
               precision_at_10  recall_at_10
ê°œìˆ˜ (count)        500.000000    500.000000
í‰ê·  (mean)           0.447400      0.639143
ë¶„ì‚° (variance)       0.064542      0.131719
í‘œì¤€í¸ì°¨ (std)         0.254052      0.362931
ì¤‘ìœ„ê°’ (median)       0.500000      0.714286
ìµœì†Œê°’ (min)          0.000000      0.000000
25% (Q1)            0.200000      0.285714
75% (Q3)            0.700000      1.000000
ìµœëŒ€ê°’ (max)          0.700000      1.000000
--------------------------------------------------
ì°¸ê³ : ì‚¬ìš©ìë‹¹ í‰ê·  ì •ë‹µ('ì¶”ì²œ') ê°œìˆ˜: 6.52 ê°œ
"""
