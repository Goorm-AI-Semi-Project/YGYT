import gradio as gr
import json
import pandas as pd
import httpx
from typing import Dict, Any, List, Tuple

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
import config
import llm_utils
import search_logic
import data_loader
from API import final_scorer # (ì‚¬ì¥ë‹˜ ë¡œì§ ì„í¬íŠ¸)
from config import PROFILE_TEMPLATE

# --- í—¬í¼ ---

def budget_mapper(budget_str: str) -> List[str]:
    """'ì €', 'ì¤‘', 'ê³ 'ë¥¼ 'final_scorer'ê°€ ì•Œì•„ë“£ëŠ” ['$', '$$']ë¡œ ë³€í™˜"""
    if budget_str == 'ì €':
        return ['$', '$$']
    elif budget_str == 'ì¤‘':
        return ['$$', '$$$']
    elif budget_str == 'ê³ ':
        return ['$$$', '$$$$']
    else:
        return ['$', '$$', '$$$', '$$$$'] # (N/Aì˜ ê²½ìš° ì „ì²´)

# --- Gradio ì½œë°± ---

def start_chat():
    try:
        initial_profile = PROFILE_TEMPLATE.copy()

        bot_message = "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¸¸ë”°ë¼ ë§›ë”°ë¼ AIì…ë‹ˆë‹¤ ğŸ˜Š\në¨¼ì € ì„±í•¨ì„ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
        # ë˜ëŠ” call_gpt4o(...) ì‚¬ìš© ë²„ì „ ì“°ê³  ì‹¶ìœ¼ë©´ ê·¸ ì½”ë“œ

        gradio_history = [{"role": "assistant", "content": bot_message}]
        llm_history = [{"role": "assistant", "content": bot_message}]

        return gradio_history, llm_history, initial_profile, False, None

    except Exception as e:
        print(f"start_chatì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = f"ì±—ë´‡ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤): {e}"

        gradio_history = [{"role": "assistant", "content": error_msg}]
        llm_history = []

        return gradio_history, llm_history, PROFILE_TEMPLATE.copy(), False, None


async def chat_survey(
    message: str, 
    gradio_history: List[Dict], 
    llm_history: List[Dict], 
    current_profile: Dict, 
    is_completed: bool,
    topk_value,                 # âœ… Top-K ìŠ¬ë¼ì´ë” ê°’ ì¶”ê°€
    user_profile_row_state,     # âœ… í”„ë¡œí•„ row state ì¶”ê°€
    http_client: httpx.AsyncClient,
    graphhopper_url: str
) -> Tuple[List[Dict], List[Dict], Dict, bool, gr.update, Dict]:
    """
    ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•  ë•Œë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    (â˜… 2ë‹¨ê³„ ì¶”ì²œ ë¡œì§ + Top-K ë°˜ì˜ ë²„ì „ â˜…)
    """
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    gradio_history.append({"role": "user", "content": message})
    llm_history.append({"role": "user", "content": message})
    
    # 2. gpt-4.1-mini API í˜¸ì¶œ (ì •ë³´ ìˆ˜ì§‘)
    try:
        bot_message, updated_profile = llm_utils.call_gpt4o(llm_history, current_profile)
    except Exception as e:
        print(f"chat_surveyì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        gradio_history.append({"role": "assistant", "content": error_msg})
        # âœ… í•­ìƒ 6ê°œ ë¦¬í„´
        return gradio_history, llm_history, current_profile, is_completed, gr.update(), user_profile_row_state

    # 3. ë´‡ ì‘ë‹µ ì¶”ê°€ (LLM APIìš©)
    llm_history.append({"role": "assistant", "content": bot_message})

    # --- 4. ì™„ë£Œ ì—¬ë¶€ í™•ì¸ ë° â˜… 2ë‹¨ê³„ ì¶”ì²œ ì‹¤í–‰ â˜… ---
    final_bot_message = bot_message
    recommendation_string = gr.update() 
    
    # í”„ë¡œí•„ì˜ ëª¨ë“  ê°’ì´ Noneì´ ì•„ë‹Œì§€ í™•ì¸
    profile_is_complete = all(v is not None for v in updated_profile.values())
    
    if profile_is_complete and not is_completed:
        print("--- í”„ë¡œí•„ ì™„ì„±! 1ë‹¨ê³„, 2ë‹¨ê³„ ì¶”ì²œì„ ìˆœì°¨ ì‹¤í–‰í•©ë‹ˆë‹¤. ---")
        gr.Info("í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! AIê°€ ìš”ì•½ ë° ì‹ë‹¹ ì¶”ì²œì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")

        # (A) êµ¬ì–´ì²´ ìš”ì•½ (RAG í…ìŠ¤íŠ¸) ìƒì„±
        chat_message_html, raw_summary_text = llm_utils.generate_profile_summary(updated_profile)
        
        # (B) í•„í„° ë©”íƒ€ë°ì´í„° ìƒì„±
        filter_dict = search_logic.create_filter_metadata(updated_profile)
        filter_metadata_json = json.dumps(filter_dict, ensure_ascii=False)
        
        # (C) 1ë‹¨ê³„ ê²€ìƒ‰ìš© 'user_profile_row' ìƒì„±
        user_profile_row = {
            "name": updated_profile.get("name", "N/A"),
            "user_id": "live_user",
            "rag_query_text": raw_summary_text,
            "filter_metadata_json": filter_metadata_json
        }

        try:
            # --- (â˜… 1ë‹¨ê³„: ì±—ë´‡ RAG ê²€ìƒ‰) ---
            candidate_ids = search_logic.get_rag_candidate_ids(
                user_profile_row,
                n_results=50  # (ì±—ë´‡ì´ 50ê°œ í›„ë³´êµ° ìƒì„±)
            )
            
            if not candidate_ids:
                raise Exception("1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼, í›„ë³´êµ° 0ê°œ.")

            # --- (â˜… 2ë‹¨ê³„: final_scorer í˜¸ì¶œ) ---
            print(f"\n--- 2ë‹¨ê³„: final_scorer ì‹¤í–‰ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
            
            candidate_df = data_loader.get_restaurants_by_ids(candidate_ids)
            if candidate_df.empty:
                raise Exception("1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")

            # ì‹œì‘ ìœ„ì¹˜
            user_start_location = updated_profile.get('start_location', 'ëª…ë™ì—­')
            if user_start_location == 'ëª…ë™ì—­':
                user_start_coords = "37.5630,126.9830"
            elif user_start_location == 'í™ëŒ€ì…êµ¬ì—­':
                user_start_coords = "37.5570,126.9244"
            elif user_start_location == 'ê°•ë‚¨ì—­':
                user_start_coords = "37.4980,127.0276"
            else:
                user_start_coords = "37.5630,126.9830"  # ê¸°ë³¸ê°’ ëª…ë™ì—­
            
            user_price_prefs = budget_mapper(updated_profile.get('budget'))

            # 2ë‹¨ê³„ ì ìˆ˜ ê³„ì‚°
            final_scored_df = await final_scorer.calculate_final_scores_async(
                candidate_df=candidate_df,
                user_start_location=user_start_coords,
                user_price_prefs=user_price_prefs,
                async_http_client=http_client,
                graphhopper_url=graphhopper_url
            )

            # --- (â˜… 3ë‹¨ê³„: Top-K ë°˜ì˜í•´ì„œ ìµœì¢… ê²°ê³¼ í¬ë§·íŒ…) ---
            k = int(topk_value) if topk_value is not None else 10  # âœ… ìŠ¬ë¼ì´ë” ê°’ ë°˜ì˜
            top_results = final_scored_df.head(k)
            
            output_string = f"\n\n---\n\n### ğŸ¤– {updated_profile['name']}ë‹˜ì„ ìœ„í•œ ìµœì¢… ì¶”ì²œ (ëšœë²…ì´ ì ìˆ˜ í¬í•¨!)\n\n"
            
            for i, (store_id, row) in enumerate(top_results.iterrows()):
                output_string += search_logic.format_restaurant_markdown(
                    store_id_str=str(store_id),
                    rank_prefix="ìµœì¢… ì¶”ì²œ",
                    rank_index=i + 1
                )
                # (ë””ë²„ê¹…ìš© ì ìˆ˜ ì¶œë ¥)
                output_string += (
                    f"  - (Debug: Final={row['final_score']:.2f} | "
                    f"Travel={row['score_travel']:.2f} | "
                    f"Friend={row['score_friendliness']:.2f})\n\n---\n\n"
                )

            recommendation_string = gr.update(value=output_string, visible=True)
            # âœ… stateì— ì €ì¥
            user_profile_row_state = user_profile_row
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] 2ë‹¨ê³„ ì¶”ì²œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            reco_error_msg = (
                f"\n\n[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n"
                f"(ì„¸ë¶€ì •ë³´: {e})\n"
                f"1ë‹¨ê³„ í›„ë³´êµ° ìƒì„± ë˜ëŠ” 2ë‹¨ê³„ ì ìˆ˜ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            )
            recommendation_string = gr.update(value=reco_error_msg, visible=True)

        # (ìµœì¢… ë´‡ ë©”ì‹œì§€ ì¡°í•©)
        final_bot_message = f"{bot_message}\n{chat_message_html}\n\nğŸ‘‡ ì•„ë˜ì—ì„œ ìµœì¢… ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”! ğŸ‘‡"
        is_completed = True 
        print(json.dumps(updated_profile, indent=2, ensure_ascii=False))

    # 5. Gradio ì±—ë´‡ ê¸°ë¡ ì—…ë°ì´íŠ¸ (UIìš©)
    gradio_history.append({"role": "assistant", "content": final_bot_message})
    
    # 6. (6ê°œ ìƒíƒœ ë°˜í™˜: chatbot, llm, profile, is_completed, ì¶”ì²œ, user_profile_row_state)
    return gradio_history, llm_history, updated_profile, is_completed, recommendation_string, user_profile_row_state
