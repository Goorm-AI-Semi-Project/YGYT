import gradio as gr
import json
import pandas as pd
import httpx
from typing import Dict, Any, List, Tuple

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
import config
import llm_utils
import search_logic
import data_loader
from API import final_scorer
from API.final_scorer import GraphHopperDownError

# =========================
# ê³µí†µ í—¬í¼
# =========================

# ì¹´ë“œ êµ¬ë¶„ìš© ê³µí†µ ì„¸í¼ë ˆì´í„° (test.pyì—ì„œ ì“°ëŠ” ê²ƒê³¼ ë§ì¶”ê¸°)
CARD_SEPARATOR = "\n---\n\n"


def _build_reco_md_from_df(df: pd.DataFrame, top_k: int = 5, prefix: str = "ìµœì¢… ì¶”ì²œ") -> str:
    """
    final_scorer ê²°ê³¼ DataFrame -> ì¹´ë“œí˜• markdownìœ¼ë¡œ ë³€í™˜
    (ë””ë²„ê·¸/ì„¤ëª… ì¤„ì€ ì ˆëŒ€ ë„£ì§€ ì•ŠëŠ”ë‹¤.)
    """
    blocks: List[str] = []

    # final_scored_dfë¥¼ reset_index().to_dict(...)ë¡œ ì €ì¥í–ˆë‹¤ê°€ ë‹¤ì‹œ DataFrameìœ¼ë¡œ ì½ìœ¼ë©´
    # 'id' ì»¬ëŸ¼ì´ ìƒê²¨ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë³µì›í•´ì¤€ë‹¤.
    if "id" in df.columns:
        df = df.set_index("id")

    for i, (store_id, row) in enumerate(df.head(top_k).iterrows(), start=1):
        block = search_logic.format_restaurant_markdown(
            store_id_str=str(store_id),
            rank_prefix=prefix,
            rank_index=i,
        )
        blocks.append(block.strip())
    return CARD_SEPARATOR.join(blocks)


def _build_reco_md_from_ids(store_ids, top_k: int = 5, prefix: str = "RAG ì¶”ì²œ") -> str:
    """
    1ë‹¨ê³„ RAGë¡œ ë½‘ì€ ì‹ë‹¹ id ë¦¬ìŠ¤íŠ¸ -> ì¹´ë“œí˜• markdownìœ¼ë¡œ ë³€í™˜
    """
    blocks = []
    for i, store_id in enumerate(list(store_ids)[:top_k], start=1):
        block = search_logic.format_restaurant_markdown(
            store_id_str=str(store_id),
            rank_prefix=prefix,
            rank_index=i,
        )
        blocks.append(block.strip())
    return CARD_SEPARATOR.join(blocks)


def budget_mapper(budget_str: str) -> List[str]:
    """'ì €', 'ì¤‘', 'ê³ 'ë¥¼ 'final_scorer'ê°€ ì•Œì•„ë“£ëŠ” ['$', '$$']ë¡œ ë³€í™˜"""
    if budget_str == "ì €":
        return ["$", "$$"]
    elif budget_str == "ì¤‘":
        return ["$$", "$$$"]
    elif budget_str == "ê³ ":
        return ["$$$", "$$$$"]
    else:
        # (N/Aì˜ ê²½ìš° ì „ì²´)
        return ["$", "$$", "$$$", "$$$$"]


# (ì¢Œí‘œ ë³€í™˜ í—¬í¼)
# (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì´ ë¶€ë¶„ì„ DBë‚˜ APIë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤)
LOCATION_COORDS = {
    "ëª…ë™ì—­": "37.5630,126.9830",
    "í™ëŒ€ì…êµ¬ì—­": "37.5570,126.9244",
    "ê°•ë‚¨ì—­": "37.4980,127.0276",
    "ì„œìš¸ì—­": "37.5547,126.9704",
    "ì„œìš¸ì‹œì²­": "37.5665, 126.9780",  # (Chloe í”„ë¡œí•„ ëŒ€ì‘)
    "ì‹œì²­ì—­": "37.5658,126.9772",
}


def get_start_location_coords(location_name: str) -> str:
    """ê°„ë‹¨í•œ ì¥ì†Œ ì´ë¦„ì„ ì¢Œí‘œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    # (ì¼ì¹˜í•˜ëŠ” ì—­ ì´ë¦„ì´ ì—†ìœ¼ë©´ 'ëª…ë™ì—­' ì¢Œí‘œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©)
    return LOCATION_COORDS.get(location_name, "37.5630,126.9830")


# =========================
# Gradio ì½œë°±
# =========================

def start_chat() -> Tuple[List[Dict], List[Dict], Dict, bool, Dict, gr.update]:
    """
    ì±„íŒ…ë°©ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ ì‹¤í–‰.
    app_main.pyì—ì„œ 6ê°œë¥¼ ë°›ì•„ê°€ë¯€ë¡œ 6ê°œë¥¼ ë°˜í™˜í•œë‹¤.
    """
    try:
        initial_profile = config.PROFILE_TEMPLATE.copy()

        bot_message, updated_profile = llm_utils.call_gpt4o(
            chat_messages=[], current_profile=initial_profile
        )

        gradio_history = [{"role": "assistant", "content": bot_message}]
        llm_history = [{"role": "assistant", "content": bot_message}]

        # user_profile_row_state ì´ˆê¸°ê°’
        initial_user_profile_row = {}

        # ì¶”ì²œ ì¶œë ¥ ì˜ì—­ ì´ˆê¸°ê°’
        initial_reco_state = gr.update(
            value="...í”„ë¡œí•„ ì„¤ë¬¸ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤...", visible=False
        )

        return (
            gradio_history,
            llm_history,
            updated_profile,
            False,
            initial_user_profile_row,
            initial_reco_state,
        )

    except Exception as e:
        print(f"start_chatì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = (
            f"ì±—ë´‡ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤): {e}"
        )

        initial_user_profile_row = {}
        error_reco_state = gr.update(value="ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨...", visible=True)

        return (
            [{"role": "assistant", "content": error_msg}],
            [],
            config.PROFILE_TEMPLATE.copy(),
            False,
            initial_user_profile_row,
            error_reco_state,
        )


async def _run_recommendation_flow(
    profile_data: dict,
    http_client: httpx.AsyncClient,
    graphhopper_url: str,
    top_k: int,
) -> Tuple[gr.update, Dict]:
    """
    1ë‹¨ê³„ RAG -> 2ë‹¨ê³„ final_scorer ì‹¤í–‰ (Fallback í¬í•¨)
    ì—¬ê¸°ì„œëŠ” 'ì¹´ë“œë¡œ ë³€í™˜í•˜ê¸° ì¢‹ì€ markdown'ë§Œ ë§Œë“¤ì–´ì„œ ë¦¬í„´í•œë‹¤.
    """
    final_user_profile_row: Dict[str, Any] = {}

    try:
        # --- 1ë‹¨ê³„: RAG + í•„í„° ë©”íƒ€ë°ì´í„° ìƒì„± ---
        print("--- 1ë‹¨ê³„: RAG + ì ìˆ˜ì œ í›„ë³´êµ° ìƒì„± ì‹œì‘ ---")
        #gr.Info("--- 1ë‹¨ê³„: 1ì°¨ RAG í›„ë³´êµ° ìƒì„± ì¤‘... ---")

        profile_summary = llm_utils.generate_profile_summary_text_only(profile_data)

        filter_dict = search_logic.create_filter_metadata(profile_data)
        filter_metadata_json = json.dumps(filter_dict, ensure_ascii=False)

        user_profile_row = {
            "name": profile_data.get("name", "N/A"),
            "user_id": "live_user",
            "rag_query_text": profile_summary,
            "filter_metadata_json": filter_metadata_json,
            "final_candidate_ids": [],
            "final_scored_df": None,
        }

        candidate_ids = search_logic.get_rag_candidate_ids(
            user_profile_row, n_results=config.RAG_REQUEST_N_RESULTS
        )

        if not candidate_ids:
            print("[ì˜¤ë¥˜] 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼, í›„ë³´êµ° 0ê°œ.")
            gr.Warning("1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”.")
            return (
                gr.update(
                    value="1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”.",
                    visible=True,
                ),
                final_user_profile_row,
            )

        print(f"--- 1ë‹¨ê³„ RAG ì™„ë£Œ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
        user_profile_row["final_candidate_ids"] = candidate_ids

        # --- 2ë‹¨ê³„: final_scorer ì‹œë„ ---
        try:
            print(f"--- 2ë‹¨ê³„: final_scorer ì‹¤í–‰ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
            #gr.Info(f"--- 2ë‹¨ê³„: {len(candidate_ids)}ê°œ í›„ë³´ 'ëšœë²…ì´ ì ìˆ˜' ê³„ì‚° ì¤‘... (API í˜¸ì¶œ) ---")

            candidate_df = data_loader.get_restaurants_by_ids(candidate_ids)
            if candidate_df.empty:
                print("[ì˜¤ë¥˜] 1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")
                raise Exception("1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")

            user_start_coords = get_start_location_coords(
                profile_data.get("start_location")
            )
            user_price_prefs = budget_mapper(profile_data.get("budget"))

            final_scored_df = await final_scorer.calculate_final_scores_async(
                candidate_df=candidate_df,
                user_start_location=user_start_coords,
                user_price_prefs=user_price_prefs,
                async_http_client=http_client,
                graphhopper_url=graphhopper_url,
            )

            # ìŠ¬ë¼ì´ë”ì—ì„œ ë‹¤ì‹œ ì“¸ ìˆ˜ ìˆë„ë¡ stateì— ì €ì¥
            user_profile_row["final_scored_df"] = final_scored_df.reset_index().to_dict(
                "records"
            )

            # âœ… ì—¬ê¸°! ê¹”ë”í•œ ì¹´ë“œìš© ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œë§Œ ë§Œë“ ë‹¤
            output_md = _build_reco_md_from_df(
                final_scored_df, top_k=top_k, prefix="ìµœì¢… ì¶”ì²œ"
            )

        except GraphHopperDownError as e:
            # --- 2ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ: 1ë‹¨ê³„ë§Œ ì‚¬ìš© ---
            print(
                f"[ê²½ê³ ] 2ë‹¨ê³„ final_scorer ì‹¤íŒ¨: {e}. 1ë‹¨ê³„ RAG ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
            )
            gr.Warning(
                "âš ï¸ ëšœë²…ì´ ì ìˆ˜ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
            )

            output_md = _build_reco_md_from_ids(
                candidate_ids, top_k=top_k, prefix="RAG ì¶”ì²œ"
            )

        # ê²°ê³¼ ë°˜í™˜
        final_user_profile_row = user_profile_row
        return gr.update(value=output_md, visible=True), final_user_profile_row

    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ íë¦„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        gr.Error(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return (
            gr.update(
                value=f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì„¸ë¶€ì •ë³´: {e})",
                visible=True,
            ),
            final_user_profile_row,
        )


async def chat_survey(
    message: str,
    gradio_history: List[Dict],
    llm_history: List[Dict],
    current_profile: Dict,
    is_completed: bool,
    topk_value: int,
    user_profile_row_state: Dict,
    http_client: httpx.AsyncClient,
    graphhopper_url: str,
) -> Tuple[List[Dict], List[Dict], Dict, bool, gr.update, Dict]:
    """
    ì‹¤ì œë¡œ ì‚¬ìš©ìê°€ ì±„íŒ…ì°½ì— ë‹µë³€ì„ ë„£ì„ ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜.
    í”„ë¡œí•„ì´ ì™„ì„±ë˜ëŠ” ìˆœê°„ ì¶”ì²œ íë¦„ì„ ëŒë¦¬ê³ , ê·¸ ì™¸ì—ëŠ” ëŒ€í™”ë§Œ ì´ì–´ê°„ë‹¤.
    """
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡
    gradio_history.append({"role": "user", "content": message})
    llm_history.append({"role": "user", "content": message})

    # 2) LLM í˜¸ì¶œí•´ì„œ ë‹¤ìŒ ì§ˆë¬¸/ì‘ë‹µ ìƒì„±
    try:
        bot_message, updated_profile = llm_utils.call_gpt4o(
            llm_history, current_profile
        )
    except Exception as e:
        print(f"chat_surveyì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        gradio_history.append({"role": "assistant", "content": error_msg})
        return (
            gradio_history,
            llm_history,
            current_profile,
            is_completed,
            gr.update(),
            user_profile_row_state,
        )

    # LLM íˆìŠ¤í† ë¦¬ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
    llm_history.append({"role": "assistant", "content": bot_message})

    # 3) í”„ë¡œí•„ì´ ë‹¤ ëª¨ì˜€ëŠ”ì§€ í™•ì¸
    profile_is_complete = all(v is not None for v in updated_profile.values())

    final_bot_message = bot_message
    recommendation_output = gr.update()
    new_user_profile_row_state = user_profile_row_state

    if profile_is_complete and not is_completed:
        print("--- í”„ë¡œí•„ ì™„ì„±! ì¶”ì²œ ë¡œì§ ì‹¤í–‰ ---")
        #gr.Info("í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! AIê°€ ë§ì¶¤ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤...")

        profile_html = llm_utils.generate_profile_summary_html(updated_profile)

        recommendation_output, new_user_profile_row_state = await _run_recommendation_flow(
            updated_profile,
            http_client,
            graphhopper_url,
            top_k=topk_value,
        )

        final_bot_message = (
            f"{bot_message}\n{profile_html}\n\nğŸ‘‡ ì•„ë˜ì—ì„œ ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”! ğŸ‘‡"
        )
        is_completed = True
        print(json.dumps(updated_profile, indent=2, ensure_ascii=False))

    # 4) UIì— ë³´ì—¬ì¤„ ëŒ€í™” ê¸°ë¡ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
    gradio_history.append({"role": "assistant", "content": final_bot_message})

    # 5) 6ê°œ ìƒíƒœ ë°˜í™˜ (app_main.pyì™€ ë§ì¶¤)
    return (
        gradio_history,
        llm_history,
        updated_profile,
        is_completed,
        recommendation_output,
        new_user_profile_row_state,
    )


def update_recommendations_with_topk(topk_value: int, user_profile_row_state: Dict):
    """
    Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì‹œ í˜¸ì¶œ.
    ì´ë¯¸ stateì— ì €ì¥ëœ ê²°ê³¼ë§Œìœ¼ë¡œ 'ì¹´ë“œ ë³€í™˜í•˜ê¸° ì¢‹ì€ markdown'ì„ ë‹¤ì‹œ ë§Œë“ ë‹¤.
    """
    if not user_profile_row_state:
        return gr.update(value="...í”„ë¡œí•„ì„ ë¨¼ì € ì™„ì„±í•´ì£¼ì„¸ìš”...", visible=True)

    try:
        # 1) 2ë‹¨ê³„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        if user_profile_row_state.get("final_scored_df"):
            df = pd.DataFrame(user_profile_row_state["final_scored_df"])
            md = _build_reco_md_from_df(df, top_k=topk_value, prefix="ìµœì¢… ì¶”ì²œ")
            return gr.update(value=md, visible=True)

        # 2) 1ë‹¨ê³„ í›„ë³´ë§Œ ìˆëŠ” ê²½ìš°
        if user_profile_row_state.get("final_candidate_ids"):
            ids = user_profile_row_state["final_candidate_ids"]
            md = _build_reco_md_from_ids(ids, top_k=topk_value, prefix="RAG ì¶”ì²œ")
            return gr.update(value=md, visible=True)

        # 3) ì•„ë¬´ê²ƒë„ ì—†ì„ ë•Œ
        return gr.update(value="ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (State ë¹„ì–´ìˆìŒ)", visible=True)

    except Exception as e:
        print(f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}")
        return gr.update(
            value=f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}", visible=True
        )
