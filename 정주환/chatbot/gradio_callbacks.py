import gradio as gr
import json
import pandas as pd
import httpx
from typing import Dict, Any, List, Tuple, Set
import random

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
import config
import llm_utils
import search_logic
import data_loader
from API import final_scorer
from API.final_scorer import GraphHopperDownError

# =========================
# ê³µí†µ í—¬í¼
# =========================

# ì¹´ë“œ êµ¬ë¶„ìš© ê³µí†µ ì„¸í¼ë ˆì´í„° (test.pyì—ì„œ ì“°ëŠ” ê²ƒê³¼ ë§ì¶”ê¸°)
CARD_SEPARATOR = "\n---\n\n"


def _build_reco_md_from_df(df: pd.DataFrame, top_k: int = 5, prefix: str = "ìµœì¢… ì¶”ì²œ") -> str:
    """
    final_scorer ê²°ê³¼ DataFrame -> ì¹´ë“œí˜• markdownìœ¼ë¡œ ë³€í™˜
    (ë””ë²„ê·¸/ì„¤ëª… ì¤„ì€ ì ˆëŒ€ ë„£ì§€ ì•ŠëŠ”ë‹¤.)
    """
    blocks: List[str] = []

    # final_scored_dfë¥¼ reset_index().to_dict(...)ë¡œ ì €ì¥í–ˆë‹¤ê°€ ë‹¤ì‹œ DataFrameìœ¼ë¡œ ì½ìœ¼ë©´
    # 'id' ì»¬ëŸ¼ì´ ìƒê²¨ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë³µì›í•´ì¤€ë‹¤.
    if "id" in df.columns:
        df = df.set_index("id")

    for i, (store_id, row) in enumerate(df.head(top_k).iterrows(), start=1):
        block = search_logic.format_restaurant_markdown(
            store_id_str=str(store_id),
            rank_prefix=prefix,
            rank_index=i,
        )
        blocks.append(block.strip())
    return CARD_SEPARATOR.join(blocks)


def _build_reco_md_from_ids(store_ids, top_k: int = 5, prefix: str = "RAG ì¶”ì²œ") -> str:
    """
    1ë‹¨ê³„ RAGë¡œ ë½‘ì€ ì‹ë‹¹ id ë¦¬ìŠ¤íŠ¸ -> ì¹´ë“œí˜• markdownìœ¼ë¡œ ë³€í™˜
    """
    blocks = []
    for i, store_id in enumerate(list(store_ids)[:top_k], start=1):
        block = search_logic.format_restaurant_markdown(
            store_id_str=str(store_id),
            rank_prefix=prefix,
            rank_index=i,
        )
        blocks.append(block.strip())
    return CARD_SEPARATOR.join(blocks)


def budget_mapper(budget_str: str) -> List[str]:
    """'ì €', 'ì¤‘', 'ê³ 'ë¥¼ 'final_scorer'ê°€ ì•Œì•„ë“£ëŠ” ['$', '$$']ë¡œ ë³€í™˜"""
    if budget_str == "ì €":
        return ["$", "$$"]
    elif budget_str == "ì¤‘":
        return ["$$", "$$$"]
    elif budget_str == "ê³ ":
        return ["$$$", "$$$$"]
    else:
        # (N/Aì˜ ê²½ìš° ì „ì²´)
        return ["$", "$$", "$$$", "$$$$"]


def calculate_evaluation_metrics(
    live_reco_ids: List[str],
    preprocessed_reco_ids: List[str],
    ground_truth_set: Set[str],
    k: int
) -> Dict[str, Any]:
  """
  ë‘ ê°œì˜ ì¶”ì²œ ëª©ë¡ê³¼ ì •ë‹µ(Ground Truth) Setì„ ë°›ì•„
  Precision@k, Recall@kë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
  """
  
  if not ground_truth_set:
    print("[í‰ê°€] Ground Truthê°€ ë¹„ì–´ìˆì–´ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    return {"error": "Ground Truth set is empty."}
  
  k_live = min(k, len(live_reco_ids))
  k_preprocessed = min(k, len(preprocessed_reco_ids))

  # 1. ì¶”ì²œ ëª©ë¡ì„ Setìœ¼ë¡œ ë³€í™˜ (Kê°œë§Œí¼ ìë¦„)
  live_reco_set_at_k = set(live_reco_ids[:k_live])
  preprocessed_reco_set_at_k = set(preprocessed_reco_ids[:k_preprocessed])
  
  # 2. êµì§‘í•© (Hits) ê³„ì‚°
  hits_live = live_reco_set_at_k.intersection(ground_truth_set)
  hits_preprocessed = preprocessed_reco_set_at_k.intersection(ground_truth_set)

  # 3. ì§€í‘œ ê³„ì‚°
  precision_live = len(hits_live) / k_live if k_live > 0 else 0.0
  recall_live = len(hits_live) / len(ground_truth_set)
  
  precision_preprocessed = len(hits_preprocessed) / k_preprocessed if k_preprocessed > 0 else 0.0
  recall_preprocessed = len(hits_preprocessed) / len(ground_truth_set)

  # 4. ê²°ê³¼ í¬ë§·íŒ…
  results = {
    "ground_truth_size": len(ground_truth_set),
    "k_value": k,
    "live_recommendation": {
      "k": k_live,
      "hits": len(hits_live),
      "precision_at_k": precision_live,
      "recall_at_k": recall_live
    },
    "preprocessed_recommendation": {
      "k": k_preprocessed,
      "hits": len(hits_preprocessed),
      "precision_at_k": precision_preprocessed,
      "recall_at_k": recall_preprocessed
    }
  }
  return results


# (ì¢Œí‘œ ë³€í™˜ í—¬í¼)
# (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì´ ë¶€ë¶„ì„ DBë‚˜ APIë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤)
LOCATION_COORDS = {
    "ëª…ë™ì—­": "37.5630,126.9830",
    "í™ëŒ€ì…êµ¬ì—­": "37.5570,126.9244",
    "ê°•ë‚¨ì—­": "37.4980,127.0276",
    "ì„œìš¸ì—­": "37.5547,126.9704",
    "ì„œìš¸ì‹œì²­": "37.5665, 126.9780",  # (Chloe í”„ë¡œí•„ ëŒ€ì‘)
    "ì‹œì²­ì—­": "37.5658,126.9772",
}


def get_start_location_coords(location_name: str) -> str:
    """ê°„ë‹¨í•œ ì¥ì†Œ ì´ë¦„ì„ ì¢Œí‘œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    # (ì¼ì¹˜í•˜ëŠ” ì—­ ì´ë¦„ì´ ì—†ìœ¼ë©´ 'ëª…ë™ì—­' ì¢Œí‘œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©)
    return LOCATION_COORDS.get(location_name, "37.5630,126.9830")


# =========================
# Gradio ì½œë°±
# =========================

def start_chat() -> Tuple[List[Dict], List[Dict], Dict, bool, Dict]:
    """
    ì±„íŒ…ë°©ì´ ì²˜ìŒ ë¡œë“œë  ë•Œ ì‹¤í–‰.
    app_main.pyì—ì„œ 6ê°œë¥¼ ë°›ì•„ê°€ë¯€ë¡œ 6ê°œë¥¼ ë°˜í™˜í•œë‹¤.
    """
    try:
        # ìˆœì„œëŒ€ë¡œ ì§ˆë¬¸í•¨
        # (ê¸°ì¡´) initial_profile = config.PROFILE_TEMPLATE.copy()

        # (ìˆ˜ì •) í…œí”Œë¦¿ì˜ í‚¤(key) ìˆœì„œë¥¼ ì„ì–´ì„œ ìƒˆë¡œìš´ ì´ˆê¸° í”„ë¡œí•„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        profile_keys = list(config.PROFILE_TEMPLATE.keys())
        random.shuffle(profile_keys)
        initial_profile = {key: config.PROFILE_TEMPLATE[key] for key in profile_keys}
        
        print(f"[start_chat] ì„ì¸ í”„ë¡œí•„ í‚¤ ìˆœì„œ: {list(initial_profile.keys())}")

        bot_message, updated_profile = llm_utils.call_gpt4o(
            chat_messages=[], current_profile=initial_profile
        )

        gradio_history = [{"role": "assistant", "content": bot_message}]
        llm_history = [{"role": "assistant", "content": bot_message}]

        # user_profile_row_state ì´ˆê¸°ê°’
        initial_user_profile_row = {}

        # ì¶”ì²œ ì¶œë ¥ ì˜ì—­ ì´ˆê¸°ê°’
        initial_reco_state = gr.update(
            value="...í”„ë¡œí•„ ì„¤ë¬¸ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì¶”ì²œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤...", visible=False
        )

        return (
            gradio_history,
            llm_history,
            updated_profile,
            False,
            initial_user_profile_row,
            #initial_reco_state,
        )

    except Exception as e:
        print(f"start_chatì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = (
            f"ì±—ë´‡ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤): {e}"
        )

        initial_user_profile_row = {}
        error_reco_state = gr.update(value="ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨...", visible=True)

        return (
            [{"role": "assistant", "content": error_msg}],
            [],
            config.PROFILE_TEMPLATE.copy(),
            False,
            initial_user_profile_row,
            #error_reco_state,
        )


async def _run_recommendation_flow(
    profile_data: dict,
    http_client: httpx.AsyncClient,
    graphhopper_url: str,
    top_k: int,
) -> Tuple[gr.update, Dict]:
    """
    1ë‹¨ê³„ RAG -> 2ë‹¨ê³„ final_scorer ì‹¤í–‰ (Fallback í¬í•¨)
    ì—¬ê¸°ì„œëŠ” 'ì¹´ë“œë¡œ ë³€í™˜í•˜ê¸° ì¢‹ì€ markdown'ë§Œ ë§Œë“¤ì–´ì„œ ë¦¬í„´í•œë‹¤.
    """
    final_user_profile_row: Dict[str, Any] = {}

    try:
        # --- 1ë‹¨ê³„: RAG + í•„í„° ë©”íƒ€ë°ì´í„° ìƒì„± ---
        print("--- 1ë‹¨ê³„: RAG + ì ìˆ˜ì œ í›„ë³´êµ° ìƒì„± ì‹œì‘ ---")
        #gr.Info("--- 1ë‹¨ê³„: 1ì°¨ RAG í›„ë³´êµ° ìƒì„± ì¤‘... ---")

        profile_summary = llm_utils.generate_profile_summary_text_only(profile_data)

        filter_dict = search_logic.create_filter_metadata(profile_data)
        filter_metadata_json = json.dumps(filter_dict, ensure_ascii=False)

        user_profile_row = {
            "name": profile_data.get("name", "N/A"),
            "user_id": "live_user",
            "rag_query_text": profile_summary,
            "filter_metadata_json": filter_metadata_json,
            "final_candidate_ids": [],
            "final_scored_df": None,
        }

        candidate_ids = search_logic.get_rag_candidate_ids(
            user_profile_row, n_results=config.RAG_REQUEST_N_RESULTS
        )

        if not candidate_ids:
            print("[ì˜¤ë¥˜] 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼, í›„ë³´êµ° 0ê°œ.")
            gr.Warning("1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”.")
            return (
                gr.update(
                    value="1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”.",
                    visible=True,
                ),
                final_user_profile_row,
            )

        print(f"--- 1ë‹¨ê³„ RAG ì™„ë£Œ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
        user_profile_row["final_candidate_ids"] = candidate_ids

        # --- 2ë‹¨ê³„: final_scorer ì‹œë„ ---
        try:
            print(f"--- 2ë‹¨ê³„: final_scorer ì‹¤í–‰ (í›„ë³´: {len(candidate_ids)}ê°œ) ---")
            #gr.Info(f"--- 2ë‹¨ê³„: {len(candidate_ids)}ê°œ í›„ë³´ 'ëšœë²…ì´ ì ìˆ˜' ê³„ì‚° ì¤‘... (API í˜¸ì¶œ) ---")

            candidate_df = data_loader.get_restaurants_by_ids(candidate_ids)
            if candidate_df.empty:
                print("[ì˜¤ë¥˜] 1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")
                raise Exception("1ë‹¨ê³„ IDë¡œ 2ë‹¨ê³„ DataFrame ì¡°íšŒ ì‹¤íŒ¨.")

            user_start_coords = get_start_location_coords(
                profile_data.get("start_location")
            )
            user_price_prefs = budget_mapper(profile_data.get("budget"))

            final_scored_df = await final_scorer.calculate_final_scores_async(
                candidate_df=candidate_df,
                user_start_location=user_start_coords,
                user_price_prefs=user_price_prefs,
                async_http_client=http_client,
                graphhopper_url=graphhopper_url,
            )
            
            
            try:
              # 1. Ground Truth ê°€ì ¸ì˜¤ê¸°
              ground_truth_set = search_logic.get_ground_truth_for_user(
                  live_rag_query_text=profile_summary,
                  max_similar_users=5 
              )
              
              # 2. ì¶”ì²œ ëª©ë¡ ID ê°€ì ¸ì˜¤ê¸°
              live_reco_ids = final_scored_df.index.astype(str).tolist()
              
              # (â­ï¸ ì¤‘ìš”: Charlieë‹˜ì´ ì´ ë°ì´í„°ë¥¼ profile_dataì— ë„£ì–´ë‘ì—ˆë‹¤ê³  ê°€ì •)
              preprocessed_reco_ids = profile_data.get("preprocessed_list", []) 
              if not preprocessed_reco_ids:
                print("[í‰ê°€] 'preprocessed_list'ê°€ í”„ë¡œí•„ì— ì—†ì–´ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

              # 3. í‰ê°€ ìˆ˜í–‰ (K=5 ê¸°ì¤€)
              evaluation_results = calculate_evaluation_metrics(
                  live_reco_ids=live_reco_ids,
                  preprocessed_reco_ids=preprocessed_reco_ids,
                  ground_truth_set=ground_truth_set,
                  k=5 # (K=5 ê¸°ì¤€ìœ¼ë¡œ í‰ê°€)
              )
              
              # 4. ê²°ê³¼ ì¶œë ¥
              print("\n--- [ì¶”ì²œ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ (K=5)] ---")
              print(json.dumps(evaluation_results, indent=2, ensure_ascii=False))
              print("----------------------------------\n")

            except Exception as eval_e:
              print(f"[ì˜¤ë¥˜] í‰ê°€ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {eval_e}")
            

            # ìŠ¬ë¼ì´ë”ì—ì„œ ë‹¤ì‹œ ì“¸ ìˆ˜ ìˆë„ë¡ stateì— ì €ì¥
            user_profile_row["final_scored_df"] = final_scored_df.reset_index().to_dict(
                "records"
            )

            # âœ… ì—¬ê¸°! ê¹”ë”í•œ ì¹´ë“œìš© ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œë§Œ ë§Œë“ ë‹¤
            output_md = _build_reco_md_from_df(
                final_scored_df, top_k=top_k, prefix="ìµœì¢… ì¶”ì²œ"
            )

        except GraphHopperDownError as e:
            # --- 2ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ: 1ë‹¨ê³„ë§Œ ì‚¬ìš© ---
            print(
                f"[ê²½ê³ ] 2ë‹¨ê³„ final_scorer ì‹¤íŒ¨: {e}. 1ë‹¨ê³„ RAG ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
            )
            gr.Warning(
                "âš ï¸ ëšœë²…ì´ ì ìˆ˜ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 1ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
            )

            output_md = _build_reco_md_from_ids(
                candidate_ids, top_k=top_k, prefix="RAG ì¶”ì²œ"
            )

        # ê²°ê³¼ ë°˜í™˜
        final_user_profile_row = user_profile_row
        return gr.update(value=output_md, visible=True), final_user_profile_row

    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ íë¦„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        gr.Error(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return (
            gr.update(
                value=f"[ì˜¤ë¥˜] ì‹ë‹¹ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì„¸ë¶€ì •ë³´: {e})",
                visible=True,
            ),
            final_user_profile_row,
        )


async def chat_survey(
    message: str,
    gradio_history: List[Dict],
    llm_history: List[Dict],
    current_profile: Dict,
    is_completed: bool,
    topk_value: int,
    user_profile_row_state: Dict,
    http_client: httpx.AsyncClient,
    graphhopper_url: str,
):
    """
    (ìˆ˜ì •ë¨: ì´ í•¨ìˆ˜ëŠ” ì´ì œ ì œë„ˆë ˆì´í„°(generator)ì…ë‹ˆë‹¤)
    ì±„íŒ… ë‹µë³€ì„ ì²˜ë¦¬í•˜ê³ , í”„ë¡œí•„ì´ ì™„ì„±ë˜ë©´ 2ë‹¨ê³„(ëŒ€ê¸°/ê²°ê³¼)ë¡œ UIë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡
    gradio_history.append({"role": "user", "content": message})
    llm_history.append({"role": "user", "content": message})

    # 2) LLM í˜¸ì¶œí•´ì„œ ë‹¤ìŒ ì§ˆë¬¸/ì‘ë‹µ ìƒì„±
    try:
        bot_message, updated_profile = llm_utils.call_gpt4o(
            llm_history, current_profile
        )
    except Exception as e:
        print(f"chat_surveyì—ì„œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        gradio_history.append({"role": "assistant", "content": error_msg})
        yield ( # (ì˜¤ë¥˜ ìƒíƒœ ë°˜í™˜)
            gradio_history,
            llm_history,
            current_profile,
            is_completed,
            gr.update(),
            user_profile_row_state,
        )
        return # (ì œë„ˆë ˆì´í„° ì¢…ë£Œ)

    # LLM íˆìŠ¤í† ë¦¬ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
    llm_history.append({"role": "assistant", "content": bot_message})

    # 3) í”„ë¡œí•„ì´ ë‹¤ ëª¨ì˜€ëŠ”ì§€ í™•ì¸
    profile_is_complete = all(v is not None for v in updated_profile.values())

    final_bot_message = bot_message
    recommendation_output = gr.update()
    new_user_profile_row_state = user_profile_row_state

    if profile_is_complete and not is_completed:
        
        # --- (A) 1ì°¨: "ëŒ€ê¸° ë©”ì‹œì§€" ì¦‰ì‹œ ë°˜í™˜ ---
        loading_message = "\n\nğŸ¤– í”„ë¡œí•„ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì‹œë©´, ìˆ˜ì§‘ëœ í”„ë¡œí•„ì„ ê¸°ë°˜ìœ¼ë¡œ ë©‹ì§„ ìŒì‹ì ì„ ì°¾ì•„ë“œë¦´ê²Œìš”."
        
        # (ë´‡ì˜ ë§ˆì§€ë§‰ ì‘ë‹µ + ë¡œë”© ë©”ì‹œì§€ë¥¼ ì±„íŒ…ì°½ì— ì¶”ê°€)
        gradio_history.append({"role": "assistant", "content": f"{bot_message}{loading_message}"})
        
        print("--- í”„ë¡œí•„ ì™„ì„±! [1/2] ëŒ€ê¸° ë©”ì‹œì§€ ì „ì†¡ (í™”ë©´ ìœ ì§€) ---")
        
        # (â˜…ìˆ˜ì •â˜…) is_completed=Falseë¥¼ ë°˜í™˜í•˜ì—¬ í™”ë©´ì„ ì±„íŒ…ì°½ì— ë¨¸ë¬´ë¥´ê²Œ í•¨
        yield (
            gradio_history,
            llm_history,
            updated_profile,
            False, # â¬…ï¸ [í•µì‹¬ ìˆ˜ì •] ì•„ì§ is_completed=False ì…ë‹ˆë‹¤.
            gr.update(), # â¬…ï¸ ì¶”ì²œì°½ì€ ì•„ì§ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            user_profile_row_state
        )

        # --- (B) 2ì°¨: ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì¶”ì²œ ë¡œì§ ì‹¤í–‰ ---
        print("--- í”„ë¡œí•„ ì™„ì„±! [2/2] ì¶”ì²œ ë¡œì§ ì‹¤í–‰ ---")
        recommendation_output, new_user_profile_row_state = await _run_recommendation_flow(
            updated_profile,
            http_client,
            graphhopper_url,
            top_k=topk_value,
        )
        
        is_completed = True # (ì´ì œ ìƒíƒœë¥¼ Trueë¡œ ë³€ê²½)

        # --- (C) 3ì°¨: "ìµœì¢… ê²°ê³¼" ë°˜í™˜ ---
        print("--- í”„ë¡œí•„ ì™„ì„±! [2/2] ìµœì¢… ê²°ê³¼ ì „ì†¡ (í™”ë©´ ì „í™˜) ---")
        
        # (â˜…ìˆ˜ì •â˜…) is_completed=Trueì™€ ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì—¬ í™”ë©´ì„ ì „í™˜ì‹œí‚´
        yield (
            gradio_history, 
            llm_history,
            updated_profile,
            True, # â¬…ï¸ [í•µì‹¬ ìˆ˜ì •] ì´ì œ is_completed=True ì…ë‹ˆë‹¤.
            recommendation_output, # â¬…ï¸ ì‹¤ì œ ì‹ë‹¹ HTMLì´ ë‹´ê¹€
            new_user_profile_row_state
        )
        
    else:
        # --- (í”„ë¡œí•„ ë¯¸ì™„ì„±) ---
        # í‰ì†Œì²˜ëŸ¼ ì±—ë´‡ ë©”ì‹œì§€ë§Œ ë°˜í™˜
        gradio_history.append({"role": "assistant", "content": bot_message})
        yield (
            gradio_history,
            llm_history,
            updated_profile,
            is_completed, # (False)
            recommendation_output, # (gr.update())
            new_user_profile_row_state
        )


def update_recommendations_with_topk(topk_value: int, user_profile_row_state: Dict):
    """
    Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì‹œ í˜¸ì¶œ.
    ì´ë¯¸ stateì— ì €ì¥ëœ ê²°ê³¼ë§Œìœ¼ë¡œ 'ì¹´ë“œ ë³€í™˜í•˜ê¸° ì¢‹ì€ markdown'ì„ ë‹¤ì‹œ ë§Œë“ ë‹¤.
    """
    if not user_profile_row_state:
        return gr.update(value="...í”„ë¡œí•„ì„ ë¨¼ì € ì™„ì„±í•´ì£¼ì„¸ìš”...", visible=True)

    try:
        # 1) 2ë‹¨ê³„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        if user_profile_row_state.get("final_scored_df"):
            df = pd.DataFrame(user_profile_row_state["final_scored_df"])
            md = _build_reco_md_from_df(df, top_k=topk_value, prefix="ìµœì¢… ì¶”ì²œ")
            return gr.update(value=md, visible=True)

        # 2) 1ë‹¨ê³„ í›„ë³´ë§Œ ìˆëŠ” ê²½ìš°
        if user_profile_row_state.get("final_candidate_ids"):
            ids = user_profile_row_state["final_candidate_ids"]
            md = _build_reco_md_from_ids(ids, top_k=topk_value, prefix="RAG ì¶”ì²œ")
            return gr.update(value=md, visible=True)

        # 3) ì•„ë¬´ê²ƒë„ ì—†ì„ ë•Œ
        return gr.update(value="ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (State ë¹„ì–´ìˆìŒ)", visible=True)

    except Exception as e:
        print(f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}")
        return gr.update(
            value=f"[ì˜¤ë¥˜] Top-K ìŠ¬ë¼ì´ë” ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}", visible=True
        )
