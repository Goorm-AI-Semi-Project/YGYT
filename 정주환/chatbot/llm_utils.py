import json
from config import client, GPT_API_NAME, SYSTEM_PROMPT, PROFILE_TEMPLATE

# --- (í•¨ìˆ˜ 4/9) ---
def call_gpt4o(chat_messages, current_profile, lang_code: str = "KR"):
  """(ë©”ì¸) gpt-4.1-mini APIë¥¼ í˜¸ì¶œí•˜ê³  JSON ì‘ë‹µì„ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
  
  if client is None:
      return "ì£„ì†¡í•©ë‹ˆë‹¤. OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", current_profile

  lang_map = {"KR": "Korean", "US": "English", "JP": "Japanese", "CN": "Chinese"}
  target_language = lang_map.get(lang_code, "Korean")
  
  # â¬‡ï¸ [í•µì‹¬ ìˆ˜ì •] .format() ëŒ€ì‹  .replace()ë¥¼ ì‚¬ìš©í•˜ì—¬ KeyErrorë¥¼ ì›ì²œ ë°©ì§€
  formatted_system_prompt = SYSTEM_PROMPT.replace("{lang_code}", target_language)
      
  system_message_with_profile = f"""
  {formatted_system_prompt}
  [í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í”„ë¡œí•„]
  {json.dumps(current_profile, indent=2, ensure_ascii=False)}
  [ëŒ€í™” ê¸°ë¡]
  (ëŒ€í™” ê¸°ë¡ì€ ì•„ë˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤)
  """
  
  messages_for_api = [
    {"role": "system", "content": system_message_with_profile}
  ]
  messages_for_api.extend(chat_messages)

  try:
    response = client.chat.completions.create(
      model=GPT_API_NAME,
      messages=messages_for_api,
      response_format={"type": "json_object"}, 
      temperature=0.7
    )
    
    response_content = response.choices[0].message.content
    response_data = json.loads(response_content)
    
    bot_message = response_data.get("bot_response")
    updated_profile = response_data.get("updated_profile", current_profile) 
    
    if not bot_message:
        # (ì½˜ì†”ì— ê²½ê³  ë¡œê·¸ë¥¼ ì¶œë ¥)
        print(f"[ê²½ê³ ] LLM ì‘ë‹µ JSONì— 'bot_response' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ì „ì²´ ì‘ë‹µ: {response_content})")
        bot_message = "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." # (Fallback ë©”ì‹œì§€)

    return bot_message, updated_profile
    
  except Exception as e:
    print(f"API í˜¸ì¶œ ë˜ëŠ” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
    error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    return error_message, current_profile

# --- (í•¨ìˆ˜ 6/9) ---
def generate_profile_summary(profile_data):
  """
  ì™„ì„±ëœ í”„ë¡œí•„(JSON)ì„ ë°›ì•„, gpt-4.1-minië¥¼ í˜¸ì¶œí•˜ì—¬
  (1) Gradio ì±„íŒ…ìš© ë©”ì‹œì§€, (2) CSV ì €ì¥ìš© ì›ë³¸ ìš”ì•½ë¬¸ í…ìŠ¤íŠ¸ 
  2ê°€ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
  """
  if client is None:
      return "(ì˜¤ë¥˜: API í‚¤ ë¯¸ì„¤ì •)", "(ì˜¤ë¥˜: API í‚¤ ë¯¸ì„¤ì •)"

  profile_str = json.dumps(profile_data, indent=2, ensure_ascii=False)
  
  summary_system_prompt = """
  ë‹¹ì‹ ì€ JSON í”„ë¡œí•„ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ, ê·¸ ì‚¬ëŒì˜ ì…ì¥ì—ì„œ ìì‹ ì„ ì†Œê°œí•˜ëŠ” 'êµ¬ì–´ì²´' í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê¸€ì“°ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
  [ê·œì¹™]
  1. (í•„ìˆ˜) JSONì˜ 'name' í•„ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” [name]ì…ë‹ˆë‹¤."ë¡œ ë¬¸ì¥ì„ ì‹œì‘í•˜ì„¸ìš”.
  2. ë”±ë”±í•œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ, í•˜ë‚˜ì˜ ì—°ê²°ëœ ë¬¸ë‹¨ìœ¼ë¡œ ë§Œë“œì„¸ìš”.
  3. ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ë˜, ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥ì— ë…¹ì—¬ë‚´ì„¸ìš”.
  4. 'party_size'ì™€ 'travel_type'ì„ ë¬¶ì–´ì„œ í‘œí˜„í•˜ì„¸ìš”.
  5. 'budget'ì€ "ê°€ì„±ë¹„ ìˆëŠ”(ì €ë ´í•œ)", "ì ë‹¹í•œ", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´" ë“±ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.
  """
  
  user_prompt = f"""
  [ì‚¬ìš©ì í”„ë¡œí•„ JSON]
  {profile_str}
  ìœ„ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ê·œì¹™ì— ë§ê²Œ ìê¸°ì†Œê°œ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
  """
  
  try:
    response = client.chat.completions.create(
      model=GPT_API_NAME,
      messages=[
        {"role": "system", "content": summary_system_prompt},
        {"role": "user", "content": user_prompt}
      ],
      temperature=0.7
    )
    
    raw_summary_text = response.choices[0].message.content
    name = profile_data.get('name', 'ì‚¬ìš©ì')
    chat_message_html = f"\n\n---\n\n### ğŸ¤– AIê°€ íŒŒì•…í•œ {name}ë‹˜ì˜ í”„ë¡œí•„\n\n{raw_summary_text}"
    
    return chat_message_html, raw_summary_text
  
  except Exception as e:
    print(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
    error_html = "\n\n(í”„ë¡œí•„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)"
    error_text = "(í”„ë¡œí•„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)"
    return error_html, error_text

# --- (í•¨ìˆ˜ 8/9 ì¤‘ í•˜ë‚˜) ---
def generate_rag_query(user_profile_summary):
  """
  LLMì„ í˜¸ì¶œí•˜ì—¬ ê¸´ ìê¸°ì†Œê°œ(ìš”ì•½ë¬¸)ë¥¼
  ê°€ê²Œ RAG í…ìŠ¤íŠ¸ì™€ ë§¤ì¹­í•˜ê¸° ì¢‹ì€ 'ì§§ì€ í•µì‹¬ ì¿¼ë¦¬'ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
  """
  if client is None:
      return user_profile_summary[:150] # API í‚¤ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
      
  print("  > [RAG] LLMì„ í˜¸ì¶œí•˜ì—¬ 'ë¶„ìœ„ê¸°/ì„±í–¥' ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤...")
  
  system_prompt = """
  ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê¸´ ìê¸°ì†Œê°œ í…ìŠ¤íŠ¸ë¥¼, ë ˆìŠ¤í† ë‘ ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ
  'ì§§ê³  í•µì‹¬ì ì¸ ì¿¼ë¦¬ ë¬¸ì¥'ìœ¼ë¡œ ì¬ì‘ì„±(Re-writing)í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
  
  [ê·œì¹™]
  1.  'ì•ˆë…•í•˜ì„¸ìš”', 'ì €ëŠ” OOOì…ë‹ˆë‹¤', '30ëŒ€', 'ìºë‚˜ë‹¤' ë“± ê°œì¸ ì‹ ìƒ ì •ë³´ëŠ” *ëª¨ë‘ ì œê±°*í•©ë‹ˆë‹¤.
  2.  'ì˜ˆì‚°(ì €/ì¤‘/ê³ )', 'ë§µê¸°(O/X)', 'ì„ í˜¸ ì¬ë£Œ(ì†Œê³ ê¸°)' ë“± 'ì‚¬ì‹¤(Fact)' ì •ë³´ëŠ” *ëª¨ë‘ ì œê±°*í•©ë‹ˆë‹¤.
  3.  ì˜¤ì§ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” *ë¶„ìœ„ê¸°*, *ìƒí™©*, *ê²½í—˜*, *ì„±í–¥* (ì˜ˆ: 'ì¡°ìš©í•œ', 'í˜¼ì', 'ì—°ì¸ê³¼ í•¨ê»˜', 'ìƒˆë¡œìš´ ë„ì „', 'ì¸ê¸° ë§›ì§‘', 'ê°€ì¡±ì ì¸')ë§Œ ì¶”ì¶œí•˜ì—¬ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
  4.  ê²°ê³¼ëŠ” ì˜¤ì§ 'ì¬ì‘ì„±ëœ ì¿¼ë¦¬ ë¬¸ì¥' í•˜ë‚˜ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
  """
  
  user_prompt = f"""
  [ì‚¬ìš©ì ìê¸°ì†Œê°œ]
  {user_profile_summary}
  
  [ì¬ì‘ì„±ëœ ì¿¼ë¦¬]
  """

  try:
    response = client.chat.completions.create(
      model=GPT_API_NAME,
      messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
      ],
      temperature=0.2
    )
    rewritten_query = response.choices[0].message.content.strip().replace('"', '')
    return rewritten_query
  except Exception as e:
    print(f"  > [ì˜¤ë¥˜] ì¿¼ë¦¬ ì¬ì‘ì„± ì‹¤íŒ¨: {e}")
    return user_profile_summary[:150]
  
  
def generate_profile_summary_html(profile_data: dict) -> str:
    """
    (ì‹ ê·œ í—¬í¼ 1)
    Gradio ì±—ë´‡ UIê°€ ì‚¬ìš©í•  HTML ìš”ì•½ë³¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    chat_message_html, _ = generate_profile_summary(profile_data)
    return chat_message_html

def generate_profile_summary_text_only(profile_data: dict) -> str:
    """
    (ì‹ ê·œ í—¬í¼ 2)
    1ë‹¨ê³„ RAG ì¿¼ë¦¬ê°€ ì‚¬ìš©í•  ìˆœìˆ˜ í…ìŠ¤íŠ¸ ìš”ì•½ë³¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    _, raw_summary_text = generate_profile_summary(profile_data)
    return raw_summary_text


def extract_profile_from_summary(summary_text: str) -> dict:
  """
  [!!! ì‹ ê·œ ì¶”ê°€ í•¨ìˆ˜ !!!]
  ì™„ì„±ëœ summary_textë¥¼ LLMì— ì „ë‹¬í•˜ì—¬,
  14ê°œ í•­ëª©ì˜ êµ¬ì¡°í™”ëœ í”„ë¡œí•„ JSONì„ ì—­ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
  """
  if client is None:
    print("[ì˜¤ë¥˜] extract_profile_from_summary: OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return {} # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

  # (PROFILE_TEMPLATEì„ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì‚¬ìš©)
  empty_profile_json = json.dumps(PROFILE_TEMPLATE, indent=2, ensure_ascii=False)

  system_prompt = f"""
  ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œ í…ìŠ¤íŠ¸(summary_text)ë¥¼ ì½ê³ ,
  ì£¼ì–´ì§„ JSON ìŠ¤í‚¤ë§ˆì˜ 14ê°œ í•­ëª©ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” AIì…ë‹ˆë‹¤.

  [ì¶”ì¶œí•´ì•¼ í•  JSON ìŠ¤í‚¤ë§ˆ]
  {empty_profile_json}

  [ê·œì¹™]
  1.  ìê¸°ì†Œê°œ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 14ê°œ í•­ëª©ì„ ëª¨ë‘ ì±„ì›ë‹ˆë‹¤.
  2.  í…ìŠ¤íŠ¸ì— ëª…ì‹œë˜ì§€ ì•Šì€ í•­ëª©ì€ 'null'ë¡œ ë‘¡ë‹ˆë‹¤.
  3.  'start_location'ì€ "í˜„ì¬ [ì¥ì†Œ] ì— ìˆì–´" ë¶€ë¶„ì—ì„œ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤.
  4.  'budget'ì€ "ì €ë ´í•œ", "ì¤‘ê°„", "ê³ ê¸‰"ì„ "ì €", "ì¤‘", "ê³ "ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
  5.  'avoid_ingredients'ì™€ 'like_ingredients'ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
  6.  *ë°˜ë“œì‹œ* ì£¼ì–´ì§„ ìŠ¤í‚¤ë§ˆì™€ ë™ì¼í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
  """

  user_prompt = f"""
  [ì‚¬ìš©ì ìê¸°ì†Œê°œ í…ìŠ¤íŠ¸]
  {summary_text}

  [ì¶”ì¶œëœ JSON ê²°ê³¼]
  """

  try:
    response = client.chat.completions.create(
      model=GPT_API_NAME,
      messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
      ],
      response_format={"type": "json_object"},
      temperature=0.0 # (ì •í™•í•œ ì¶”ì¶œì„ ìœ„í•´ 0.0)
    )
    
    extracted_data = json.loads(response.choices[0].message.content)
    
    # (14ê°œ í‚¤ê°€ ëª¨ë‘ ìˆëŠ”ì§€ ìµœì†Œí•œìœ¼ë¡œ í™•ì¸)
    if "name" in extracted_data and "start_location" in extracted_data:
      return extracted_data
    else:
      print(f"[ê²½ê³ ] LLMì´ {summary_text}ì—ì„œ ë¶ˆì™„ì „í•œ JSONì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
      return {} # (ë¶ˆì™„ì „í•˜ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜)

  except Exception as e:
    print(f"[ì˜¤ë¥˜] extract_profile_from_summary: LLM í˜¸ì¶œ/íŒŒì‹± ì‹¤íŒ¨ - {e}")
    return {} # (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜)
