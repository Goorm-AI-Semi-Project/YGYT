import pandas as pd
from transformers import pipeline
import re
import warnings

# -----------------------------------------------------------------
# 1. ì„¤ì •: ëª¨ë¸, í‚¤ì›Œë“œ, ì ìˆ˜ ë§¤í•‘
# -----------------------------------------------------------------

# "transformers" ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
# ì´ ëª¨ë¸ì€ ì˜ì–´, í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼
# ë²ˆì—­ ì—†ì´ ë°”ë¡œ ì´í•´í•˜ê³  ê°ì„±ì„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
MODEL_NAME = "cardiffnlp/twitter-xlm-roberta-base-sentiment"

# ë¶„ì„í•  'ì™¸êµ­ì¸ ì¹œí™”ë„' ê´€ë ¨ í‚¤ì›Œë“œ
# (ë‹¤êµ­ì–´)
FOREIGNER_KEYWORDS = [
    # English
    'menu', 'staff', 'order', 'english', 'communication', 'friendly', 'speaks', 'foreigner',
    # Korean
    'ë©”ë‰´', 'ì˜ì–´', 'ì§ì›', 'ì£¼ë¬¸', 'ì¹œì ˆ', 'ë¶ˆì¹œì ˆ', 'ì™¸êµ­ì¸',
    # Japanese
    'ãƒ¡ãƒ‹ãƒ¥ãƒ¼', 'è‹±èª', 'åº—å“¡', 'æ³¨æ–‡', 'è¦ªåˆ‡',
    # Chinese (Simplified)
    'èœå•', 'è‹±è¯­', 'æœåŠ¡å‘˜', 'ç‚¹é¤', 'å‹å¥½'
]
# íš¨ìœ¨ì ì¸ ê²€ìƒ‰ì„ ìœ„í•´ í•˜ë‚˜ì˜ regex íŒ¨í„´ìœ¼ë¡œ ì»´íŒŒì¼ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
keyword_pattern = re.compile("|".join(FOREIGNER_KEYWORDS), re.IGNORECASE)

# ëª¨ë¸ì´ ì¶œë ¥í•˜ëŠ” ê°ì„± ë ˆì´ë¸”ì„ ì ìˆ˜ë¡œ ë³€í™˜
SENTIMENT_SCORE_MAP = {
    'Positive': 1,
    'Neutral': 0,
    'Negative': -1
}

# -----------------------------------------------------------------
# 2. ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
# -----------------------------------------------------------------
def analyze_restaurant_friendliness(csv_path: str):
    """
    ì£¼ì–´ì§„ CSV íŒŒì¼ì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ 'ì™¸êµ­ì¸ ì¹œí™”ë„ ì ìˆ˜'ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    
    # --- A. ëª¨ë¸ ë¡œë“œ ---
    print(f"Loading multilingual sentiment model '{MODEL_NAME}'...")
    try:
        sentiment_pipeline = pipeline("sentiment-analysis", model=MODEL_NAME)
        print("âœ… Model loaded successfully.")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        print("HuggingFace Hubì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # --- B. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
    print(f"\nLoading reviews from '{csv_path}'...")
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
    except UnicodeDecodeError:
        df = pd.read_csv(csv_path, encoding='cp949') # ìœˆë„ìš°ìš© fallback

    # 'review_text' ì»¬ëŸ¼(ì›ë³¸ ë¦¬ë·°)ì— NaN(ë¹ˆ ê°’)ì´ ìˆëŠ” í–‰ ì œê±°
    original_count = len(df)
    df.dropna(subset=['review_text'], inplace=True)
    print(f"Loaded {original_count} reviews. Processing {len(df)} non-empty reviews.")

    # --- C. ë¶„ì„ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ---
    def get_friendliness_score(review_text: str):
        """
        ë¦¬ë·° 1ê°œë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°ì„± ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if not isinstance(review_text, str):
            return None
        
        # 1. í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if keyword_pattern.search(review_text):
            try:
                # 2. í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´, ë‹¤êµ­ì–´ ê°ì„± ëª¨ë¸ ì‹¤í–‰
                result = sentiment_pipeline(review_text, max_length=512, truncation=True)
                label = result[0]['label']
                # 3. ë ˆì´ë¸”ì„ ì ìˆ˜(1, 0, -1)ë¡œ ë³€í™˜
                return SENTIMENT_SCORE_MAP.get(label, 0)
            except Exception as e:
                print(f"Error during sentiment analysis: {e}")
                return None
        else:
            # ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì ìˆ˜ ê³„ì‚°ì—ì„œ ì œì™¸ (None)
            return None

    # --- D. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---
    print("\nRunning NLP pipeline on relevant reviews (this may take a a few minutes)...")
    # 'review_text' ì»¬ëŸ¼ì˜ ëª¨ë“  ë¦¬ë·°ì— í•¨ìˆ˜ ì ìš©
    df['friendliness_score'] = df['review_text'].apply(get_friendliness_score)

    # --- E. ê²°ê³¼ ì§‘ê³„ ---
    # í‚¤ì›Œë“œê°€ ìˆì–´ì„œ ì ìˆ˜ê°€ ë§¤ê²¨ì§„ ë¦¬ë·°ë§Œ í•„í„°ë§
    scored_reviews_df = df.dropna(subset=['friendliness_score'])

    print(f"\n--- Analysis Complete ---")
    print(f"Found {len(scored_reviews_df)} reviews containing relevant keywords.")

    if scored_reviews_df.empty:
        print("\n=======================================================")
        print(f"âš ï¸ '{csv_path}'ì˜ ë¦¬ë·° ì¤‘ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("=======================================================")
        return

    # ì ìˆ˜ê°€ ë§¤ê²¨ì§„ ë¦¬ë·°ì™€ ì›ë³¸ í…ìŠ¤íŠ¸ ì¶œë ¥
    print("\n--- Scored Reviews ---")
    for _, row in scored_reviews_df.iterrows():
        score_text = {1: 'Positive', -1: 'Negative', 0: 'Neutral'}.get(row['friendliness_score'])
        print(f"  [{score_text:8}] : \"{row['review_text'][:80]}...\"")

    # ì´ ì‹ë‹¹ì˜ ìµœì¢… 'ì™¸êµ­ì¸ ì¹œí™”ë„ ì ìˆ˜' (í‰ê· ê°’)
    final_score = scored_reviews_df['friendliness_score'].mean()
    
    print("\n=======================================================")
    print(f"ğŸ† ìµœì¢… 'ì™¸êµ­ì¸ ì¹œí™”ë„ ì ìˆ˜': {final_score:.4f}")
    print("=======================================================")


# -----------------------------------------------------------------
# 3. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# -----------------------------------------------------------------
if __name__ == "__main__":
    # ë¶„ì„í•  CSV íŒŒì¼ ì§€ì •
    warnings.filterwarnings('ignore')
    analyze_restaurant_friendliness(csv_path="ë‹¤ì´ë‹ë§ˆ-detailed-reviews.csv")