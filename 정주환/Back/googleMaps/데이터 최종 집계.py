"""
[ìµœì¢… ì§‘ê³„ ìŠ¤í¬ë¦½íŠ¸ V2: aggregate_final_data_v2.py]
-------------------------------------------------
ëª©ì : 'all_reviews_processed.csv' (ëª¨ë“  ë¦¬ë·°ì— ì ìˆ˜/ì •ë³´ê°€ í¬í•¨ëœ íŒŒì¼)ì„
     'place_id' ê¸°ì¤€ìœ¼ë¡œ 'ì§‘ê³„(Aggregate)'í•˜ì—¬
     ê°€ê²Œë³„ ìµœì¢… ë§ˆìŠ¤í„° íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

í•„ìš” íŒŒì¼:
1. all_reviews_processed.csv (ì •ì£¼í™˜ë‹˜ì´ ì£¼ì‹  8ê°œ ì»¬ëŸ¼ì„ ê°€ì§„ íŒŒì¼)

ìƒì„± íŒŒì¼:
1. ENRICHED_RESTAURANTS_FINAL.csv (íœ´ë¦¬ìŠ¤í‹± ëª¨ë¸ìš© ìµœì¢… DB)
"""

import pandas as pd
import json
import re
from collections import Counter
from tqdm import tqdm
tqdm.pandas(desc="Aggregating Tags")

# --- 0. ì„¤ì •: íŒŒì¼ ì´ë¦„ ë° ì»¬ëŸ¼ëª… ---

# [ì…ë ¥ íŒŒì¼] (ì •ì£¼í™˜ë‹˜ì˜ ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼)
INPUT_PROCESSED_FILE = 'all_reviews_processed.csv'

# [ì¶œë ¥ íŒŒì¼] (ìµœì¢… ë§ˆìŠ¤í„° DB)
OUTPUT_FINAL_FILE = 'ENRICHED_RESTAURANTS_FINAL.csv'

# (ì¤‘ìš”!) ì •ì£¼í™˜ë‹˜ì´ ì£¼ì‹  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜
COLUMN_NAMES = {
    # --- ì‹ë³„ì ---
    "place_id": "place_id",

    # --- ì§‘ê³„í•  ì ìˆ˜ ---
    "q_score": "quality_score",       # (ì‹ ê·œ) í’ˆì§ˆ ì ìˆ˜
    "f_score": "friendliness_score",    # (ì‹ ê·œ) ì¹œí™”ë„ ì ìˆ˜
    
    # --- ì§‘ê³„í•  íƒœê·¸ ---
    "tags": "experience_details",     # (ë‹¤ì´ë‹ë§ˆ íŒŒì¼ì˜ ê·¸ ì»¬ëŸ¼)
    
    # --- ì¹´ìš´íŠ¸ìš© ---
    "text": "review_text",

    # --- ê³ ìœ  ì •ë³´ (ê°€ê²Œë‹¹ 1ê°œ) ---
    "unique_info": [
        "place_id", 
        "place_name", 
        "price_range", 
        "is_vegetarian"
    ] 
}

# --- 1. ì§‘ê³„ìš© ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì •ì˜ (íƒœê·¸ í•©ì‚°) ---

def aggregate_tags_from_json_list(experience_details_series):
    """
    í•œ ê°€ê²Œì˜ ëª¨ë“  'experience_details' (JSON ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´)ë¥¼ ë°›ì•„
    ëª¨ë“  íƒœê·¸ì˜ ì¹´ìš´íŠ¸ë¥¼ í•©ì‚°í•˜ì—¬ ìµœì¢… JSON ë¬¸ìì—´ 1ê°œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
     í˜•ì‹ ì˜ˆ: "[{""name"":""ìŒì‹"",""value"":5}, {""name"":""ì„œë¹„ìŠ¤"",""value"":""ë§¤ì¥ ë‚´ ì‹ì‚¬""}]"
    """
    total_counter = Counter()
    
    for json_list_str in experience_details_series.dropna():
        try:
            # JSON ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ê°ì²´ë¡œ ë³€í™˜
            tags_list = json.loads(json_list_str)
            
            if isinstance(tags_list, list):
                for tag_dict in tags_list:
                    if isinstance(tag_dict, dict) and 'name' in tag_dict and tag_dict['name'] is not None:
                        # "name"ì„ íƒœê·¸ í‚¤ë¡œ ì‚¬ìš©
                        tag_name = tag_dict['name']
                        total_counter.update([tag_name])
                        
        except (json.JSONDecodeError, TypeError):
            pass # íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ
            
    # ìµœì¢… í•©ì‚°ëœ Counterë¥¼ ë‹¤ì‹œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
    return json.dumps(dict(total_counter), ensure_ascii=False)

# --- 2. ë©”ì¸ ì§‘ê³„ íŒŒì´í”„ë¼ì¸ ---
def main():
    print(f"--- ìµœì¢… ì§‘ê³„ íŒŒì´í”„ë¼ì¸ (V2) ì‹œì‘ ---")
    
    # 1. 'ì²˜ë¦¬ ì™„ë£Œëœ' ë¦¬ë·° íŒŒì¼ ë¡œë“œ
    print(f"1/3. '{INPUT_PROCESSED_FILE}' ë¡œë“œ ì¤‘...")
    try:
        # (ì¤‘ìš”) ìŠ¤í¬ë¦½íŠ¸ì— í•„ìš”í•œ ëª¨ë“  ì»¬ëŸ¼ëª…ì„ usecolsì— ëª…ì‹œ
        use_cols = [
            COLUMN_NAMES["place_id"],
            COLUMN_NAMES["q_score"],
            COLUMN_NAMES["f_score"],
            COLUMN_NAMES["tags"],
            COLUMN_NAMES["text"]
        ] + [col for col in COLUMN_NAMES["unique_info"] if col != COLUMN_NAMES["place_id"]]
        
        # ì¤‘ë³µëœ ì»¬ëŸ¼ëª… ì œê±°
        use_cols = sorted(list(set(use_cols))) 
        
        df = pd.read_csv(INPUT_PROCESSED_FILE, usecols=use_cols, encoding='utf-8')
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{INPUT_PROCESSED_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except ValueError as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {e}")
        print(f"í•„ìš”í•œ ì»¬ëŸ¼: {use_cols}")
        print("COLUMN_NAMES ë³€ìˆ˜ì˜ ì»¬ëŸ¼ëª…ì´ ì‹¤ì œ íŒŒì¼ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ë¡œë“œ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
        return

    print(f"âœ… ì´ {len(df)}ê°œì˜ 'ì²˜ë¦¬ëœ ë¦¬ë·°' ë¡œë“œ ì™„ë£Œ.")

    # 2. 'ê°€ê²Œ ê³ ìœ  ì •ë³´' ì¶”ì¶œ (master_df ìƒì„±)
    print("2/3. 'ê°€ê²Œ ê³ ìœ  ì •ë³´' ì¶”ì¶œ ì¤‘ (drop_duplicates)...")
    master_df = df[COLUMN_NAMES["unique_info"]].drop_duplicates(subset=[COLUMN_NAMES["place_id"]]).reset_index(drop=True)
    print(f"âœ… {len(master_df)}ê°œì˜ ê³ ìœ í•œ ê°€ê²Œ ë§ˆìŠ¤í„° ìƒì„±.")

    # 3. 'ì§‘ê³„ í”¼ì²˜' ìƒì„± (features_df ìƒì„±)
    print("3/3. 'place_id' ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ ë° íƒœê·¸ ì§‘ê³„ ì¤‘...")
    
    # (í•µì‹¬) NLP ê³„ì‚° ì—†ì´, ë‹¨ìˆœ í‰ê· /ì‚¬ì´ì¦ˆ/ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì§‘ê³„
    features_df = df.groupby(COLUMN_NAMES["place_id"]).agg(
        # 1. (ì‹ ê·œ) í’ˆì§ˆ ì ìˆ˜ í‰ê· 
        avg_quality_score = (COLUMN_NAMES["q_score"], 'mean'),
        # 2. (ì‹ ê·œ) ì¹œí™”ë„ ì ìˆ˜ í‰ê· 
        avg_friendliness_score = (COLUMN_NAMES["f_score"], 'mean'),
        # 3. íƒœê·¸ í•©ì‚° (ë‹¤ì´ë‹ë§ˆ íŒŒì¼ì˜ 'experience_details' ì»¬ëŸ¼ ê¸°ì¤€)
        tag_counts_json = (COLUMN_NAMES["tags"], aggregate_tags_from_json_list),
        # 4. ë¦¬ë·° ê°œìˆ˜ (review_text ê¸°ì¤€)
        review_count = (COLUMN_NAMES["text"], 'size')
    ).reset_index()
    
    print("âœ… í”¼ì²˜ ì§‘ê³„ ì™„ë£Œ.")

    # 4. (ë³‘í•©) ê³ ìœ  ì •ë³´ + ì§‘ê³„ í”¼ì²˜
    final_df = pd.merge(
        master_df,
        features_df,
        on=COLUMN_NAMES["place_id"],
        how='inner'
    )

    # 5. ìµœì¢… íŒŒì¼ ì €ì¥
    final_df.to_csv(OUTPUT_FINAL_FILE, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ìµœì¢… íŒŒì¼ '{OUTPUT_FINAL_FILE}' ì €ì¥ ì„±ê³µ!")
    print(f"ìµœì¢… {len(final_df)}ê°œ ë§›ì§‘ ë°ì´í„° ìƒì„± ì™„ë£Œ.")
    print("\n--- ìµœì¢… ë°ì´í„° ìƒ˜í”Œ ---")
    print(final_df.head())

if __name__ == "__main__":
    main()