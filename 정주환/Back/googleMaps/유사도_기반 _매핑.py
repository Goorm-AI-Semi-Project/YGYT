import pandas as pd
from rapidfuzz import process, fuzz
import sys
import re

# tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •
try:
    from tqdm import tqdm
    tqdm.pandas(desc="[place_id ê¸°ë°˜] ë§¤í•‘ ì§„í–‰ ì¤‘")
    USE_TQDM = True
except ImportError:
    USE_TQDM = False

# --- 1. ì‚¬ìš©ìž ì„¤ì • ---
REVIEW_FILE = 'all_reviews_processed.csv'
BLUERIBBON_FILE = '20251016_ì„œìš¸ì‹œ_ìŒì‹ì _ëª©ë¡_GPS.csv'
REVIEW_ID_COL = 'place_id'
REVIEW_NAME_COL = 'place_name'
BLUERIBBON_NAME_COL = 'ê°€ê²Œ'
BLUERIBBON_ID_COL = 'id'
SCORE_CUTOFF = 90

# ê²°ê³¼ íŒŒì¼ëª… ì„¤ì •
OUTPUT_FILE_ALL = 'final_mapped_all_reviews.csv'
OUTPUT_FILE_SUCCESS = 'mapped_reviews_success.csv'
OUTPUT_FILE_FAILED = 'mapped_reviews_failed.csv'

# -----------------------

def clean_name(name):
    if pd.isna(name): return None
    return re.sub(r'\s+', ' ', str(name)).strip().lower()

print("ë§¤í•‘ ìž‘ì—…ì„ ì‹œìž‘í•©ë‹ˆë‹¤...")

# 1. ë°ì´í„° ë¡œë“œ
try:
    df_reviews = pd.read_csv(REVIEW_FILE)
    df_blueribbon = pd.read_csv(BLUERIBBON_FILE)
except Exception as e:
    print(f"[ì˜¤ë¥˜] íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit()

# 2. ë¸”ë£¨ë¦¬ë³¸ ì°¸ì¡° ë°ì´í„° ì¤€ë¹„
df_blueribbon['clean_name'] = df_blueribbon[BLUERIBBON_NAME_COL].apply(clean_name)
blueribbon_names = list(df_blueribbon['clean_name'].dropna().unique())
print(f"ë¡œë“œ ì™„ë£Œ: ë¦¬ë·° {len(df_reviews)}ê±´, ë¸”ë£¨ë¦¬ë³¸ ê°€ê²Œ {len(blueribbon_names)}ê°œ")

# 3. ê³ ìœ  ê°€ê²Œ ëª©ë¡ ì¶”ì¶œ
unique_shops = df_reviews.groupby(REVIEW_ID_COL)[REVIEW_NAME_COL].first().reset_index()
unique_shops['clean_name'] = unique_shops[REVIEW_NAME_COL].apply(clean_name)
total_unique_shops = len(unique_shops)
print(f"ê³ ìœ í•œ place_id {total_unique_shops}ê°œì— ëŒ€í•´ ë§¤í•‘ì„ ì‹œìž‘í•©ë‹ˆë‹¤...")

# 4. ë§¤í•‘ í•¨ìˆ˜
def find_match(target_clean_name):
    if pd.isna(target_clean_name): return None, 0, None
    match = process.extractOne(
        target_clean_name, 
        blueribbon_names, 
        scorer=fuzz.token_set_ratio,
        score_cutoff=SCORE_CUTOFF
    )
    if match:
        matched_clean, score, _ = match
        info = df_blueribbon[df_blueribbon['clean_name'] == matched_clean].iloc[0]
        return info[BLUERIBBON_NAME_COL], score, info[BLUERIBBON_ID_COL]
    return None, 0, None

# 5. ë§¤í•‘ ì‹¤í–‰
if USE_TQDM:
    results = unique_shops['clean_name'].progress_apply(find_match)
else:
    results = unique_shops['clean_name'].apply(find_match)

unique_shops[['matched_name', 'match_score', 'matched_id']] = pd.DataFrame(results.tolist(), index=unique_shops.index)

# 6. ì›ë³¸ ë¦¬ë·° ë°ì´í„°ì— ë³‘í•©
df_merged = pd.merge(
    df_reviews,
    unique_shops[[REVIEW_ID_COL, 'matched_name', 'match_score', 'matched_id']],
    on=REVIEW_ID_COL,
    how='left'
)

# 7. ìµœì¢… ë³‘í•© (ë¸”ë£¨ë¦¬ë³¸ ìƒì„¸ ì •ë³´ ì¶”ê°€)
final_df = pd.merge(
    df_merged,
    df_blueribbon.drop(columns=['clean_name']),
    left_on='matched_id',
    right_on=BLUERIBBON_ID_COL,
    how='left',
    suffixes=('', '_blueribbon')
)

# --- 8. ê²°ê³¼ ë¶„ë¦¬ ë° ì €ìž¥ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„) ---
print("\nê²°ê³¼ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì €ìž¥í•©ë‹ˆë‹¤...")

# ì„±ê³µí•œ ë¦¬ë·°ë§Œ í•„í„°ë§
df_success = final_df[final_df['matched_id'].notna()]
df_success.to_csv(OUTPUT_FILE_SUCCESS, index=False, encoding='utf-8-sig')

# ì‹¤íŒ¨í•œ ë¦¬ë·°ë§Œ í•„í„°ë§
df_failed = final_df[final_df['matched_id'].isna()]
df_failed.to_csv(OUTPUT_FILE_FAILED, index=False, encoding='utf-8-sig')

# ì „ì²´ ê²°ê³¼ ì €ìž¥
final_df.to_csv(OUTPUT_FILE_ALL, index=False, encoding='utf-8-sig')

# --- 9. ìµœì¢… í†µê³„ ì¶œë ¥ ---
total_reviews = len(final_df)
success_count = len(df_success)
failed_count = len(df_failed)

print("\n--- [ìµœì¢… ê²°ê³¼ ìš”ì•½] ---")
print(f"ì´ ë¦¬ë·° ìˆ˜: {total_reviews}ê±´")
print(f"âœ… ë§¤í•‘ ì„±ê³µ: {success_count}ê±´ ({(success_count/total_reviews)*100:.2f}%) -> '{OUTPUT_FILE_SUCCESS}'")
print(f"âŒ ë§¤í•‘ ì‹¤íŒ¨: {failed_count}ê±´ ({(failed_count/total_reviews)*100:.2f}%) -> '{OUTPUT_FILE_FAILED}'")
print(f"ðŸ“„ ì „ì²´ ê²°ê³¼: '{OUTPUT_FILE_ALL}'")