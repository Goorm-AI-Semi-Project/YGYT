import pandas as pd
# (ìˆ˜ì •) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig
import numpy as np
from scipy.special import softmax
import re
import json
import warnings
from collections import Counter
from tqdm import tqdm

# -----------------------------------------------------------------
# 0. ì„¤ì •: íŒŒì¼ ì´ë¦„ ë° NLP ëª¨ë¸ (Full classification ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •)
# -----------------------------------------------------------------
INPUT_REVIEWS_FILE = 'all_reviews.csv'
OUTPUT_PROCESSED_FILE = 'all_reviews_processed.csv'
MODEL_NAME = "cardiffnlp/twitter-xlm-roberta-base-sentiment"

print(f"Loading model '{MODEL_NAME}' (Full classification)...")
# (ìˆ˜ì •) pipeline ëŒ€ì‹  Tokenizerì™€ Modelì„ ì§ì ‘ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
config = AutoConfig.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
print("âœ… NLP Model loaded.")

# -----------------------------------------------------------------
# 1. NLP ë¶„ì„ í•¨ìˆ˜ (ê°€ì¤‘ í‰ê·  ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •)
# -----------------------------------------------------------------
# (ìˆ˜ì •) 'ì™¸êµ­ì¸ ì¹œí™”ë„' í‚¤ì›Œë“œëŠ” í­ë„“ì€ ë²„ì „ ìœ ì§€
FOREIGNER_KEYWORDS = [
    # 1. ì–¸ì–´ & ë©”ë‰´
    'menu', 'english', 'speaks', 'language', 'translation',
    'ì˜ì–´', 'ë©”ë‰´', 'ë©”ë‰´íŒ', 'ì™¸êµ­ì–´', 'ë²ˆì—­',
    'è‹±èª', 'ãƒ¡ãƒ‹ãƒ¥ãƒ¼', 'æ—¥æœ¬èª', 'å¤–å›½èª', 'ç¿»è¨³',
    'è‹±è¯­', 'èœå•', 'ä¸­æ–‡', 'å¤–è¯­', 'ç¿»è¯‘',
    # 2. ì£¼ë¬¸ í¸ì˜ì„±
    'order', 'ordering', 'easy', 'kiosk', 'tablet', 'picture menu', 'vending machine',
    'ì£¼ë¬¸', 'í‚¤ì˜¤ìŠ¤í¬', 'íƒœë¸”ë¦¿', 'ê·¸ë¦¼ ë©”ë‰´', 'ì‚¬ì§„ ë©”ë‰´', 'ì‰½ê²Œ', 'í¸í•˜ê²Œ',
    'æ³¨æ–‡', 'åˆ¸å£²æ©Ÿ', 'ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ', 'ç°¡å˜', 'ã‚„ã™ã„',
    'ç‚¹é¤', 'è‡ªåŠ©ç‚¹é¤æœº', 'å¹³æ¿', 'æ–¹ä¾¿', 'å›¾ç‰‡èœå•',
    # 3. ì§ì› íƒœë„
    'staff', 'friendly', 'kind', 'helpful', 'welcoming', 'rude', 'unhelpful', 'patient',
    'ì§ì›', 'ì¹œì ˆ', 'ë¶ˆì¹œì ˆ', 'ë„ì›€', 'ì„¤ëª…', 'í™˜ëŒ€',
    'åº—å“¡', 'è¦ªåˆ‡', 'ä¸å¯§', 'ä¸è¦ªåˆ‡', 'åŠ©ã‹ã‚Š',
    'æœåŠ¡å‘˜', 'å‹å¥½', 'çƒ­æƒ…', 'ä¸å‹å¥½', 'è€å¿ƒ', 'æ€åº¦',
    # 4. ëŒ€ìƒ
    'foreigner', 'tourist', 'traveler',
    'ì™¸êµ­ì¸', 'ê´€ê´‘ê°', 'ì—¬í–‰ê°',
    'å¤–å›½äºº', 'è¦³å…‰å®¢',
    'å¤–å›½äºº', 'æ¸¸å®¢'
]
keyword_pattern = re.compile("|".join(FOREIGNER_KEYWORDS), re.IGNORECASE)

# (ìˆ˜ì •) ëª¨ë¸ configì—ì„œ ë¼ë²¨ ìˆœì„œ í™•ì¸ í›„ ê°€ì¤‘ì¹˜(-1, 0, 1) ì„¤ì •
# config.id2label -> {0: 'Negative', 1: 'Neutral', 2: 'Positive'}
# ë”°ë¼ì„œ ì ìˆ˜ ìˆœì„œëŠ” [Negative, Neutral, Positive]
WEIGHTS = np.array([-1, 0, 1]) # Negative(-1), Neutral(0), Positive(1) ê°€ì¤‘ì¹˜

def process_review_text(text: str):
    """
    (ìˆ˜ì •ë¨) ë¦¬ë·° í…ìŠ¤íŠ¸ 1ê°œë¥¼ ë°›ì•„ 3ê°œ í™•ë¥ ì˜ 'ê°€ì¤‘ í‰ê· 'ìœ¼ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    quality_score = None
    friendliness_score = None
    
    if pd.isna(text):
        return pd.Series([None, None], index=['quality_score', 'friendliness_score'])

    try:
        # 1. í† í¬ë‚˜ì´ì§• ë° ëª¨ë¸ ì¶”ë¡ 
        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
        output = model(**encoded_input)
        
        # 2. 3ê°€ì§€ 0~1 í™•ë¥  ì¶”ì¶œ
        scores = output[0][0].detach().numpy()
        scores = softmax(scores) # [Neg_prob, Neu_prob, Pos_prob]

        # 3. 'ì „ë°˜ì  í’ˆì§ˆ' ì ìˆ˜ (ë„“ì€ í•„í„°): ê°€ì¤‘ í‰ê·  ê³„ì‚°
        # (Neg_prob * -1) + (Neu_prob * 0) + (Pos_prob * 1)
        score = np.dot(scores, WEIGHTS)
        quality_score = score
        
        # 4. 'ì™¸êµ­ì¸ ì¹œí™”ë„' ì ìˆ˜ (ì¢ì€ í•„í„°) - í‚¤ì›Œë“œ ê²€ì‚¬
        if keyword_pattern.search(text):
            friendliness_score = score # ì´ë¯¸ ê³„ì‚°ëœ ì ìˆ˜ ì¬ì‚¬ìš©
            
    except Exception as e:
        pass # ì˜¤ë¥˜ ì‹œ None ë°˜í™˜

    return pd.Series([quality_score, friendliness_score], index=['quality_score', 'friendliness_score'])

# -----------------------------------------------------------------
# 2. 'í•˜ë“œ í•„í„°' íƒœê·¸ ì¶”ì¶œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼)
# -----------------------------------------------------------------
# (!!! ê²½ê³  !!!)
# ì´ ë§µí•‘ì€ 'ì¶”ì¸¡'ì…ë‹ˆë‹¤. 'all_reviews.csv'ë¥¼ ì—´ì–´ë³´ê³ 
# ì‹¤ì œ ìŠ¤í¬ë˜í•‘ëœ íƒœê·¸ 'name'ê³¼ 'value'ì— ë§ê²Œ ë°˜ë“œì‹œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
TAG_MAPPING = {
    # ì˜ˆì‚° (1ì¸ë‹¹ ê°€ê²©)
    'â‚©10,000 ë¯¸ë§Œ': '$',
    'â‚©10,000â€“20,000': '$',
    'â‚©20,000â€“30,000': '$$',
    'â‚©30,000â€“40,000': '$$',
    'â‚©40,000-50,000': '$$',
    'â‚©50,000â€“100,000': '$$$',
    'â‚©100,000 ì´ìƒ': '$$$',
    
    # ì±„ì‹
    'ì±„ì‹ì£¼ì˜ì ì˜µì…˜': 'is_vegetarian',
    
    # ì„œë¹„ìŠ¤ ì˜µì…˜
    'ê·¸ë£¹ ì´ìš©ì— ì í•©': 'good_for_groups',
    'ê°€ì¡± ë‹¨ìœ„ì— ì í•©': 'good_for_family',
}

def extract_hard_filter_tags(details_str: str):
    """
    ë¦¬ë·° 1ê°œì˜ 'experience_details' ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬
    'í•˜ë“œ í•„í„°' íƒœê·¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    tags = {
        'price_range': None,
        'is_vegetarian': False
    }
    
    if pd.isna(details_str):
        return pd.Series(tags)

    try:
        details_list = json.loads(details_str)
        for item in details_list:
            tag_name = item.get('name')
            tag_value = item.get('value')
            
            if tag_name == '1ì¸ë‹¹ ê°€ê²©':
                mapped_price = TAG_MAPPING.get(tag_value)
                if mapped_price:
                    tags['price_range'] = mapped_price
            
            mapped_tag = TAG_MAPPING.get(tag_name) or TAG_MAPPING.get(tag_value)
            if mapped_tag == 'is_vegetarian':
                tags['is_vegetarian'] = True

    except:
        pass 

    return pd.Series(tags)

# -----------------------------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ì²˜ë¦¬) - (ì´ì „ê³¼ ë™ì¼)
# -----------------------------------------------------------------
def main():
    warnings.filterwarnings('ignore')
    tqdm.pandas(desc="Processing Reviews") # pandas.apply() ì§„í–‰ë¥  í‘œì‹œ
    
    print(f"Loading all reviews from '{INPUT_REVIEWS_FILE}'...")
    try:
        df = pd.read_csv(
            INPUT_REVIEWS_FILE, 
            usecols=['place_id', 'place_name', 'review_text', 'experience_details'],
            encoding='utf-8'
        )
    except UnicodeDecodeError:
        df = pd.read_csv(
            INPUT_REVIEWS_FILE,
            usecols=['place_id', 'place_name', 'review_text', 'experience_details'],
            encoding='cp437'
        )
    except FileNotFoundError:
        print(f"âŒ Error: '{INPUT_REVIEWS_FILE}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except ValueError:
        print(f"âŒ Error: '{INPUT_REVIEWS_FILE}'ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"Loaded {len(df)} reviews.")
    
    print("Running NLP analysis for all reviews...")
    nlp_scores = df['review_text'].progress_apply(process_review_text)
    df = pd.concat([df, nlp_scores], axis=1)
    
    print("Extracting hard filter tags from 'experience_details'...")
    tags = df['experience_details'].progress_apply(extract_hard_filter_tags)
    df = pd.concat([df, tags], axis=1)

    df.to_csv(OUTPUT_PROCESSED_FILE, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ‰ Success! 'ë°ì´í„°ë‹¹ ì‘ì—…' ì™„ë£Œ.")
    print(f"'{OUTPUT_PROCESSED_FILE}' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\n--- Processed File (Head) ---")
    print(df.head())

# -----------------------------------------------------------------
# 4. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# -----------------------------------------------------------------
if __name__ == "__main__":
    main()